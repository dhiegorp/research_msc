[2017-10-10 15:17:02,406 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:146]: >> Initializing execution of experiment AE_UNIGRAMA_2L_UNDER_96_76_66_9
[2017-10-10 15:17:02,406 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:147]: >> Printing header log
[2017-10-10 15:17:02,406 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_UNDER_96_76_66_9
	layers = 96,76,66,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'autoencoder_configs': {'loss_function': 'mse', 'output_layer_activation': 'relu', 'discard_decoder_function': True, 'optimizer': <keras.optimizers.SGD object at 0x0000018CB4C21550>, 'hidden_layer_activation': 'relu'}, 'fullds_reports_dir': 'C:/Users/dhieg/research/research_msc/reports/2layers/unigram/fullds/', 'store_history': True, 'log_dir': 'C:/Users/dhieg/research/research_msc/logs/2layers/unigram/', 'mlp_configs': {'loss_function': 'categorical_crossentropy', 'activation': 'sigmoid', 'classifier_dim': 9, 'use_last_dim_as_classifier': False, 'optimizer': <keras.optimizers.SGD object at 0x0000018CB4C233C8>}, 'tensorflow_dir': 'C:/Users/dhieg/research/research_msc/tensorflow/2layers/unigram/', 'reports_dir': 'C:/Users/dhieg/research/research_msc/reports/2layers/unigram/', 'epochs': 200, 'batch': 32, 'fullds_data_dir': 'C:/Users/dhieg/research/malware_dataset/malware_selected_1gram.pkl', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'data_dir': 'C:/Users/dhieg/research/malware_dataset/malware_selected_1gram_mini.pkl', 'checkpoints_dir': 'C:/Users/dhieg/research/research_msc/checkpoints/2layers/unigram/', 'shuffle_batches': True, 'executed_path': 'C:/Users/dhieg/research/research_msc/executed/2layers/unigram/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9]}
	=======================================
	
[2017-10-10 15:17:02,453 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:149]: >> Loading dataset... 
[2017-10-10 15:17:02,453 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:54]: 
	=======================================
	loading malware dataset on = C:/Users/dhieg/research/malware_dataset/malware_selected_1gram_mini.pkl	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-10 15:17:02,453 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:151]: >> Executing autoencoder part ... 
[2017-10-10 15:17:02,453 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:59]: =======================================
[2017-10-10 15:17:02,453 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:64]: setting configurations for autoencoder: 
	 {'loss_function': 'mse', 'output_layer_activation': 'relu', 'discard_decoder_function': True, 'optimizer': <keras.optimizers.SGD object at 0x0000018CB4C21550>, 'hidden_layer_activation': 'relu'}
[2017-10-10 15:17:02,554 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:75]: training and evaluate autoencoder
[2017-10-10 15:17:04,225 summary.py:89]: Summary name enc0_76/kernel:0 is illegal; using enc0_76/kernel_0 instead.
[2017-10-10 15:17:04,225 summary.py:89]: Summary name enc0_76/bias:0 is illegal; using enc0_76/bias_0 instead.
[2017-10-10 15:17:04,241 summary.py:89]: Summary name enc1_66/kernel:0 is illegal; using enc1_66/kernel_0 instead.
[2017-10-10 15:17:04,241 summary.py:89]: Summary name enc1_66/bias:0 is illegal; using enc1_66/bias_0 instead.
[2017-10-10 15:17:04,241 summary.py:89]: Summary name enc2_9/kernel:0 is illegal; using enc2_9/kernel_0 instead.
[2017-10-10 15:17:04,241 summary.py:89]: Summary name enc2_9/bias:0 is illegal; using enc2_9/bias_0 instead.
[2017-10-10 15:17:04,241 summary.py:89]: Summary name dec0_66/kernel:0 is illegal; using dec0_66/kernel_0 instead.
[2017-10-10 15:17:04,241 summary.py:89]: Summary name dec0_66/bias:0 is illegal; using dec0_66/bias_0 instead.
[2017-10-10 15:17:04,256 summary.py:89]: Summary name dec1_76/kernel:0 is illegal; using dec1_76/kernel_0 instead.
[2017-10-10 15:17:04,256 summary.py:89]: Summary name dec1_76/bias:0 is illegal; using dec1_76/bias_0 instead.
[2017-10-10 15:17:04,256 summary.py:89]: Summary name dec2_96/kernel:0 is illegal; using dec2_96/kernel_0 instead.
[2017-10-10 15:17:04,256 summary.py:89]: Summary name dec2_96/bias:0 is illegal; using dec2_96/bias_0 instead.
[2017-10-10 15:17:49,127 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:86]: trained and evaluated!
[2017-10-10 15:17:49,127 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:89]: Training history: 
{'loss': [0.0097609091196358029, 0.0096253181928476813, 0.0094891528392321654, 0.0093545350437891136, 0.0092237552796211719, 0.0090967407329872341, 0.0089724844203690635, 0.0088508637901338321, 0.0087323270614482768, 0.0086177637297992112, 0.008507668582771773, 0.0084021930813505449, 0.0083012223969538227, 0.0082046214946772909, 0.0081121652789491773, 0.0080238079340795316, 0.0079393309392790604, 0.0078584515600114355, 0.0077810436326921093, 0.00770679280904855, 0.0076356590284720367, 0.007567492104178385, 0.0075022101948368598, 0.0074397071657362314, 0.0073797107693071226, 0.0073220785667166138, 0.0072667361966940475, 0.0072136614311397182, 0.0071627310887620206, 0.0071138418419830407, 0.0070669422625634446, 0.00702188613457627, 0.0069784514351845812, 0.0069365737142330968, 0.0068962643413558906, 0.0068574948511106442, 0.0068201767981908735, 0.0067842366484685878, 0.0067495573206146986, 0.0067161514183944841, 0.006683934470506977, 0.0066528679054864686, 0.0066230124745291288, 0.0065943311674368111, 0.0065667656700790257, 0.0065403081454936535, 0.0065148736160768276, 0.0064903946596838319, 0.0064668460507529713, 0.0064441903311697416, 0.0064223812006931405, 0.0064013785148553494, 0.0063811319172680011, 0.0063616040256618536, 0.0063427571400761894, 0.0063245797194380225, 0.006306997959724712, 0.006289986456494227, 0.0062735150536704296, 0.0062575355975258437, 0.006242031154818673, 0.0062269717721084219, 0.0062123651008940796, 0.0061981942502927143, 0.0061843950723852563, 0.0061709205021814985, 0.0061577999421705042, 0.0061451208714187406, 0.0061328947439917994, 0.0061211094727308089, 0.0061097043751296484, 0.0060986879155195484, 0.0060880214900932358, 0.0060776663324769902, 0.0060676334611270127, 0.0060579240512155502, 0.0060485291624465783, 0.0060394399226417041, 0.006030661442340538, 0.0060221791014386673, 0.0060139563702820776, 0.0060059796891689813, 0.0059982557945896789, 0.0059907790141772036, 0.0059834937307440984, 0.0059763812889318084, 0.005969428207173476, 0.0059626200428139816, 0.00595598974332131, 0.0059495264556677927, 0.0059432052224691325, 0.0059370045414504713, 0.0059308538427456214, 0.0059247510799635529, 0.0059186880337675435, 0.0059127177969857678, 0.0059068200608329603, 0.0059010008740403132, 0.0058952803450471134, 0.0058896811919420793, 0.0058841936326898825, 0.005878832250187825], 'val_loss': [0.0097007239479779319, 0.0095668132330349823, 0.0094320151200137179, 0.0093009293868750002, 0.0091737368521471012, 0.0090496445933294558, 0.0089280909294310994, 0.0088091839215680128, 0.0086938341400935749, 0.0085827304936640769, 0.008476197941152579, 0.0083742277267420152, 0.0082766557022319852, 0.0081832857982542875, 0.0080941138896384861, 0.0080089853179803796, 0.007927491769305392, 0.0078495413508113867, 0.0077748409036173033, 0.0077033025995035375, 0.0076347435218694039, 0.0075690970171007526, 0.0075063036969381641, 0.0074460975147202114, 0.0073883691525647634, 0.0073329439822958304, 0.0072797375963135277, 0.0072287440570036714, 0.007179820451359213, 0.0071329236719549589, 0.0070879177335774366, 0.007044639498978632, 0.007002881184552682, 0.0069627074323954635, 0.0069240817322385358, 0.0068869283422827721, 0.0068511732396943194, 0.0068167473300322062, 0.0067835726539801711, 0.006751593204083607, 0.0067207665705437108, 0.0066911249843921135, 0.0066626303271844038, 0.0066352641092246346, 0.0066090060456839416, 0.006583778973544176, 0.0065595293694546229, 0.0065362233336197844, 0.0065138051944151247, 0.0064922431137648213, 0.0064714982063547605, 0.0064515160590576416, 0.006432269211706176, 0.0064137022956153276, 0.0063958035567325284, 0.0063785142784585072, 0.0063618002597893479, 0.0063456419689172259, 0.0063299641816367894, 0.0063147667456127455, 0.0062999954814139799, 0.0062856746103517628, 0.0062717834096332687, 0.0062582746951331883, 0.0062450947877033492, 0.0062322230891888909, 0.0062197575130981137, 0.0062077323400647443, 0.0061961493531041203, 0.0061849539123170882, 0.0061741602506668594, 0.0061637059193395327, 0.0061535594230136903, 0.0061437128090947087, 0.006134192743182847, 0.006124981197781279, 0.0061160668602635651, 0.0061074584362453685, 0.0060991497405676592, 0.0060911089749695196, 0.0060833116307799258, 0.0060757643415083676, 0.0060684539440008347, 0.0060613595787089554, 0.0060544412022241869, 0.0060476851978488125, 0.0060410674048594609, 0.0060346121657432012, 0.006028313077224564, 0.0060221488158249724, 0.0060161142661945971, 0.0060101509765898425, 0.0060042304620423724, 0.0059983264239414913, 0.0059924933221537384, 0.0059867280926624638, 0.0059810274948805678, 0.0059754060214336916, 0.0059699023741411677, 0.0059645138819421533, 0.0059592524616110063, 0.0059541090838195667]}
[2017-10-10 15:17:49,127 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:93]: done!
[2017-10-10 15:17:49,127 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:153]: >> Executing classifier part ... 
[2017-10-10 15:17:49,127 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:98]: =======================================
[2017-10-10 15:17:49,127 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:102]: setting configurations for classifier: 
	 {'loss_function': 'categorical_crossentropy', 'activation': 'sigmoid', 'classifier_dim': 9, 'use_last_dim_as_classifier': False, 'optimizer': <keras.optimizers.SGD object at 0x0000018CB4C233C8>}
[2017-10-10 15:17:49,174 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:111]: training ... 
[2017-10-10 15:17:49,558 summary.py:89]: Summary name enc0_76/kernel:0 is illegal; using enc0_76/kernel_0 instead.
[2017-10-10 15:17:49,558 summary.py:89]: Summary name enc0_76/bias:0 is illegal; using enc0_76/bias_0 instead.
[2017-10-10 15:17:49,574 summary.py:89]: Summary name enc1_66/kernel:0 is illegal; using enc1_66/kernel_0 instead.
[2017-10-10 15:17:49,574 summary.py:89]: Summary name enc1_66/bias:0 is illegal; using enc1_66/bias_0 instead.
[2017-10-10 15:17:49,574 summary.py:89]: Summary name enc2_9/kernel:0 is illegal; using enc2_9/kernel_0 instead.
[2017-10-10 15:17:49,574 summary.py:89]: Summary name enc2_9/bias:0 is illegal; using enc2_9/bias_0 instead.
[2017-10-10 15:17:49,574 summary.py:89]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-10-10 15:17:49,574 summary.py:89]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-10-10 15:19:13,865 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:123]: trained!
[2017-10-10 15:19:13,865 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:126]: Training history: 
{'loss': [0.0097609091196358029, 0.0096253181928476813, 0.0094891528392321654, 0.0093545350437891136, 0.0092237552796211719, 0.0090967407329872341, 0.0089724844203690635, 0.0088508637901338321, 0.0087323270614482768, 0.0086177637297992112, 0.008507668582771773, 0.0084021930813505449, 0.0083012223969538227, 0.0082046214946772909, 0.0081121652789491773, 0.0080238079340795316, 0.0079393309392790604, 0.0078584515600114355, 0.0077810436326921093, 0.00770679280904855, 0.0076356590284720367, 0.007567492104178385, 0.0075022101948368598, 0.0074397071657362314, 0.0073797107693071226, 0.0073220785667166138, 0.0072667361966940475, 0.0072136614311397182, 0.0071627310887620206, 0.0071138418419830407, 0.0070669422625634446, 0.00702188613457627, 0.0069784514351845812, 0.0069365737142330968, 0.0068962643413558906, 0.0068574948511106442, 0.0068201767981908735, 0.0067842366484685878, 0.0067495573206146986, 0.0067161514183944841, 0.006683934470506977, 0.0066528679054864686, 0.0066230124745291288, 0.0065943311674368111, 0.0065667656700790257, 0.0065403081454936535, 0.0065148736160768276, 0.0064903946596838319, 0.0064668460507529713, 0.0064441903311697416, 0.0064223812006931405, 0.0064013785148553494, 0.0063811319172680011, 0.0063616040256618536, 0.0063427571400761894, 0.0063245797194380225, 0.006306997959724712, 0.006289986456494227, 0.0062735150536704296, 0.0062575355975258437, 0.006242031154818673, 0.0062269717721084219, 0.0062123651008940796, 0.0061981942502927143, 0.0061843950723852563, 0.0061709205021814985, 0.0061577999421705042, 0.0061451208714187406, 0.0061328947439917994, 0.0061211094727308089, 0.0061097043751296484, 0.0060986879155195484, 0.0060880214900932358, 0.0060776663324769902, 0.0060676334611270127, 0.0060579240512155502, 0.0060485291624465783, 0.0060394399226417041, 0.006030661442340538, 0.0060221791014386673, 0.0060139563702820776, 0.0060059796891689813, 0.0059982557945896789, 0.0059907790141772036, 0.0059834937307440984, 0.0059763812889318084, 0.005969428207173476, 0.0059626200428139816, 0.00595598974332131, 0.0059495264556677927, 0.0059432052224691325, 0.0059370045414504713, 0.0059308538427456214, 0.0059247510799635529, 0.0059186880337675435, 0.0059127177969857678, 0.0059068200608329603, 0.0059010008740403132, 0.0058952803450471134, 0.0058896811919420793, 0.0058841936326898825, 0.005878832250187825], 'val_loss': [0.0097007239479779319, 0.0095668132330349823, 0.0094320151200137179, 0.0093009293868750002, 0.0091737368521471012, 0.0090496445933294558, 0.0089280909294310994, 0.0088091839215680128, 0.0086938341400935749, 0.0085827304936640769, 0.008476197941152579, 0.0083742277267420152, 0.0082766557022319852, 0.0081832857982542875, 0.0080941138896384861, 0.0080089853179803796, 0.007927491769305392, 0.0078495413508113867, 0.0077748409036173033, 0.0077033025995035375, 0.0076347435218694039, 0.0075690970171007526, 0.0075063036969381641, 0.0074460975147202114, 0.0073883691525647634, 0.0073329439822958304, 0.0072797375963135277, 0.0072287440570036714, 0.007179820451359213, 0.0071329236719549589, 0.0070879177335774366, 0.007044639498978632, 0.007002881184552682, 0.0069627074323954635, 0.0069240817322385358, 0.0068869283422827721, 0.0068511732396943194, 0.0068167473300322062, 0.0067835726539801711, 0.006751593204083607, 0.0067207665705437108, 0.0066911249843921135, 0.0066626303271844038, 0.0066352641092246346, 0.0066090060456839416, 0.006583778973544176, 0.0065595293694546229, 0.0065362233336197844, 0.0065138051944151247, 0.0064922431137648213, 0.0064714982063547605, 0.0064515160590576416, 0.006432269211706176, 0.0064137022956153276, 0.0063958035567325284, 0.0063785142784585072, 0.0063618002597893479, 0.0063456419689172259, 0.0063299641816367894, 0.0063147667456127455, 0.0062999954814139799, 0.0062856746103517628, 0.0062717834096332687, 0.0062582746951331883, 0.0062450947877033492, 0.0062322230891888909, 0.0062197575130981137, 0.0062077323400647443, 0.0061961493531041203, 0.0061849539123170882, 0.0061741602506668594, 0.0061637059193395327, 0.0061535594230136903, 0.0061437128090947087, 0.006134192743182847, 0.006124981197781279, 0.0061160668602635651, 0.0061074584362453685, 0.0060991497405676592, 0.0060911089749695196, 0.0060833116307799258, 0.0060757643415083676, 0.0060684539440008347, 0.0060613595787089554, 0.0060544412022241869, 0.0060476851978488125, 0.0060410674048594609, 0.0060346121657432012, 0.006028313077224564, 0.0060221488158249724, 0.0060161142661945971, 0.0060101509765898425, 0.0060042304620423724, 0.0059983264239414913, 0.0059924933221537384, 0.0059867280926624638, 0.0059810274948805678, 0.0059754060214336916, 0.0059699023741411677, 0.0059645138819421533, 0.0059592524616110063, 0.0059541090838195667]}
[2017-10-10 15:19:13,865 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:130]: evaluating model ... 
[2017-10-10 15:19:13,931 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:134]: evaluated! 
[2017-10-10 15:19:13,931 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:136]: generating reports ... 
[2017-10-10 15:19:14,301 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:139]: done!
[2017-10-10 15:19:14,301 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:155]: >> experiment AE_UNIGRAMA_2L_UNDER_96_76_66_9 finished!
[2017-10-10 15:32:40,149 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:144]: The experiment AE_UNIGRAMA_2L_UNDER_96_76_66_9 was already executed!
[2017-10-10 15:51:42,496 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:146]: >> Initializing execution of experiment AE_UNIGRAMA_2L_UNDER_96_76_66_9
[2017-10-10 15:51:42,527 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:147]: >> Printing header log
[2017-10-10 15:51:42,527 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_UNDER_96_76_66_9
	layers = 96,76,66,9
	using GLOBAL obj = 
		{'shuffle_batches': True, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'numpy_seed': 666, 'store_history': True, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'fullds_data_dir': 'C:/Users/dhieg/research/malware_dataset/malware_selected_1gram.pkl', 'data_dir': 'C:/Users/dhieg/research/malware_dataset/malware_selected_1gram_mini.pkl', 'executed_path': 'C:/Users/dhieg/research/research_msc/executed/2layers/unigram/', 'mlp_configs': {'loss_function': 'categorical_crossentropy', 'use_last_dim_as_classifier': False, 'classifier_dim': 9, 'optimizer': <keras.optimizers.SGD object at 0x0000016008AA33C8>, 'activation': 'sigmoid'}, 'batch': 32, 'fullds_reports_dir': 'C:/Users/dhieg/research/research_msc/reports/2layers/unigram/fullds/', 'reports_dir': 'C:/Users/dhieg/research/research_msc/reports/2layers/unigram/', 'autoencoder_configs': {'loss_function': 'mse', 'output_layer_activation': 'relu', 'hidden_layer_activation': 'relu', 'discard_decoder_function': True, 'optimizer': <keras.optimizers.SGD object at 0x0000016008AA1550>}, 'epochs': 200, 'tensorflow_dir': 'C:/Users/dhieg/research/research_msc/tensorflow/2layers/unigram/', 'log_dir': 'C:/Users/dhieg/research/research_msc/logs/2layers/unigram/', 'checkpoints_dir': 'C:/Users/dhieg/research/research_msc/checkpoints/2layers/unigram/'}
	=======================================
	
[2017-10-10 15:51:42,527 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:149]: >> Loading dataset... 
[2017-10-10 15:51:42,527 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:54]: 
	=======================================
	loading malware dataset on = C:/Users/dhieg/research/malware_dataset/malware_selected_1gram_mini.pkl	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-10 15:51:42,527 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:151]: >> Executing autoencoder part ... 
[2017-10-10 15:51:42,527 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:59]: =======================================
[2017-10-10 15:51:42,527 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:64]: setting configurations for autoencoder: 
	 {'loss_function': 'mse', 'output_layer_activation': 'relu', 'hidden_layer_activation': 'relu', 'discard_decoder_function': True, 'optimizer': <keras.optimizers.SGD object at 0x0000016008AA1550>}
[2017-10-10 15:51:42,634 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:75]: training and evaluate autoencoder
[2017-10-10 15:51:44,435 summary.py:89]: Summary name enc0_76/kernel:0 is illegal; using enc0_76/kernel_0 instead.
[2017-10-10 15:51:44,435 summary.py:89]: Summary name enc0_76/bias:0 is illegal; using enc0_76/bias_0 instead.
[2017-10-10 15:51:44,435 summary.py:89]: Summary name enc1_66/kernel:0 is illegal; using enc1_66/kernel_0 instead.
[2017-10-10 15:51:44,435 summary.py:89]: Summary name enc1_66/bias:0 is illegal; using enc1_66/bias_0 instead.
[2017-10-10 15:51:44,435 summary.py:89]: Summary name enc2_9/kernel:0 is illegal; using enc2_9/kernel_0 instead.
[2017-10-10 15:51:44,435 summary.py:89]: Summary name enc2_9/bias:0 is illegal; using enc2_9/bias_0 instead.
[2017-10-10 15:51:44,435 summary.py:89]: Summary name dec0_66/kernel:0 is illegal; using dec0_66/kernel_0 instead.
[2017-10-10 15:51:44,453 summary.py:89]: Summary name dec0_66/bias:0 is illegal; using dec0_66/bias_0 instead.
[2017-10-10 15:51:44,456 summary.py:89]: Summary name dec1_76/kernel:0 is illegal; using dec1_76/kernel_0 instead.
[2017-10-10 15:51:44,457 summary.py:89]: Summary name dec1_76/bias:0 is illegal; using dec1_76/bias_0 instead.
[2017-10-10 15:51:44,460 summary.py:89]: Summary name dec2_96/kernel:0 is illegal; using dec2_96/kernel_0 instead.
[2017-10-10 15:51:44,462 summary.py:89]: Summary name dec2_96/bias:0 is illegal; using dec2_96/bias_0 instead.
[2017-10-10 15:52:21,967 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:86]: trained and evaluated!
[2017-10-10 15:52:21,967 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:89]: Training history: 
{'val_loss': [0.0099262034271230936, 0.009876401634492174, 0.0098260538202457719, 0.0097771861129976999, 0.009730315099030622, 0.0096851460649510744, 0.0096406662857443873, 0.0095943193917325444, 0.0095469246836566123, 0.0095012454890739517, 0.0094574380347498283, 0.0094153846866800884, 0.0093750192482564536, 0.0093365846492599377, 0.0092999474889837678, 0.0092649814433878683, 0.0092316402475519244, 0.0091997118992211656, 0.0091691804170386942, 0.0091398663257965373, 0.0091118358221029712, 0.0090850219199759361, 0.0090592434754435906, 0.0090344388377212245, 0.0090106493658403484, 0.0089877940105018116, 0.0089658023789525032, 0.0089446034033169985, 0.0089241699436783343, 0.0089044195070142641, 0.0088853692933640073, 0.0088670057206515045, 0.0088493039132161652, 0.0088322319672010201, 0.0088157832941047325, 0.0087999342334868745, 0.0087846718333855437, 0.0087699183093238493, 0.0087556955837350351, 0.0087419335062175873, 0.0087286391015057221, 0.0087157715264306185, 0.0087033305247920158, 0.0086912688553388677, 0.0086795558000059593, 0.0086682100769921756, 0.0086571939677332413, 0.0086465245147398419, 0.0086361566025306737, 0.0086260424082108596, 0.0086161102649503045, 0.008606357266260899, 0.0085968686125784781, 0.0085876585957230696, 0.0085787202048091191, 0.0085700386061876681, 0.0085616126746548595, 0.008553425715647666, 0.0085454762923673176, 0.0085377399169157871, 0.008530240415917453, 0.0085229572500742715, 0.0085158641034647209, 0.008508957579704244, 0.008502232317629246, 0.0084956808095333972, 0.0084893017917262135, 0.0084830871177317933, 0.0084770168195094312, 0.0084710685695524989, 0.0084652331342650617, 0.0084594972985606205, 0.0084538813472680441, 0.0084483647670555283, 0.0084429564556889377, 0.0084376603877344986, 0.0084324718407981902, 0.0084273758860214931, 0.008422373008107607, 0.0084174446463861873, 0.0084126094688547152, 0.0084078554444873641, 0.0084031954594648902, 0.0083986325120227936, 0.0083941721658613595, 0.0083898137112366229, 0.0083855484009869256, 0.008381375291672117, 0.0083772981016581611, 0.0083733143710763257, 0.0083694210341788804, 0.0083656153922076568, 0.0083618939276022975, 0.0083582537165638685, 0.0083546956661797803, 0.0083512138873061727, 0.008347814431808695, 0.0083444867106535394, 0.0083412357976445483, 0.0083380523397410672, 0.0083349294039562725, 0.0083318686659783672], 'loss': [0.0099409936406931847, 0.0098916022135625975, 0.0098419653105228395, 0.0097927397601283543, 0.0097453978906380453, 0.0096999833665985091, 0.009655946987030253, 0.0096114084883590165, 0.0095651090012310331, 0.0095192985168412632, 0.0094753491801576675, 0.0094332252511755785, 0.0093927925467472834, 0.0093541097676710042, 0.009317288613696734, 0.0092821896360121264, 0.0092486647526105643, 0.0092166231346408802, 0.0091859650143869247, 0.0091566103427558124, 0.0091284925968700484, 0.0091016300568687973, 0.0090759081929720608, 0.009051127528706503, 0.0090273268768116238, 0.0090044818706375429, 0.0089825000528065274, 0.0089613310466094033, 0.008940910761941227, 0.0089212275970527999, 0.0089022245311900089, 0.0088838909391471786, 0.0088662073644680626, 0.008849164940984651, 0.0088327230041882129, 0.0088168884746011363, 0.0088016318733166836, 0.0087869309230072783, 0.0087727244918194003, 0.0087590244969040533, 0.0087457818323179639, 0.0087329705727195624, 0.0087205863568631872, 0.0087085997859804847, 0.0086969720725183046, 0.00868568041996679, 0.0086747447055087329, 0.0086641205050000843, 0.0086538417433109759, 0.0086438283518863439, 0.0086340396765209673, 0.0086244042406400136, 0.008615006233056631, 0.0086058632910856088, 0.0085969870943248677, 0.008588370976405196, 0.0085800087580843142, 0.0085718946104391854, 0.0085639978868322433, 0.0085563350322335214, 0.0085488770056353358, 0.0085416444186315853, 0.0085346207169205695, 0.0085277723488480905, 0.0085210988553356525, 0.008514610400220772, 0.0085082929982095677, 0.0085021339542362389, 0.0084961325069860798, 0.0084902523972721425, 0.0084844934911488309, 0.0084788420465995214, 0.0084732845574434206, 0.0084678417514750907, 0.0084625052067221641, 0.0084572680038070853, 0.0084521384931500881, 0.0084471013637393549, 0.0084421440040819765, 0.0084372753161220324, 0.0084324786502503885, 0.0084277644659579709, 0.0084231336696672168, 0.0084186026388029418, 0.0084141706973405866, 0.0084098423942786174, 0.0084056116368097251, 0.0084014765245092379, 0.0083974384689576506, 0.0083934982017039809, 0.0083896541594772091, 0.0083858799710228686, 0.0083821994202702629, 0.0083786015889361805, 0.0083750783652983048, 0.0083716321569428393, 0.008368259996459685, 0.0083649706269471862, 0.0083617513882569845, 0.0083586033851540224, 0.0083555120267271629, 0.0083524952742792605]}
[2017-10-10 15:52:21,967 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:93]: done!
[2017-10-10 15:52:21,967 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:153]: >> Executing classifier part ... 
[2017-10-10 15:52:21,967 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:98]: =======================================
[2017-10-10 15:52:21,968 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:102]: setting configurations for classifier: 
	 {'loss_function': 'categorical_crossentropy', 'use_last_dim_as_classifier': False, 'classifier_dim': 9, 'optimizer': <keras.optimizers.SGD object at 0x0000016008AA33C8>, 'activation': 'sigmoid'}
[2017-10-10 15:52:22,013 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:111]: training ... 
[2017-10-10 15:52:22,448 summary.py:89]: Summary name enc0_76/kernel:0 is illegal; using enc0_76/kernel_0 instead.
[2017-10-10 15:52:22,449 summary.py:89]: Summary name enc0_76/bias:0 is illegal; using enc0_76/bias_0 instead.
[2017-10-10 15:52:22,452 summary.py:89]: Summary name enc1_66/kernel:0 is illegal; using enc1_66/kernel_0 instead.
[2017-10-10 15:52:22,454 summary.py:89]: Summary name enc1_66/bias:0 is illegal; using enc1_66/bias_0 instead.
[2017-10-10 15:52:22,457 summary.py:89]: Summary name enc2_9/kernel:0 is illegal; using enc2_9/kernel_0 instead.
[2017-10-10 15:52:22,459 summary.py:89]: Summary name enc2_9/bias:0 is illegal; using enc2_9/bias_0 instead.
[2017-10-10 15:52:22,461 summary.py:89]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-10-10 15:52:22,464 summary.py:89]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-10-10 15:53:25,462 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:123]: trained!
[2017-10-10 15:53:25,462 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:126]: Training history: 
{'val_loss': [0.0099262034271230936, 0.009876401634492174, 0.0098260538202457719, 0.0097771861129976999, 0.009730315099030622, 0.0096851460649510744, 0.0096406662857443873, 0.0095943193917325444, 0.0095469246836566123, 0.0095012454890739517, 0.0094574380347498283, 0.0094153846866800884, 0.0093750192482564536, 0.0093365846492599377, 0.0092999474889837678, 0.0092649814433878683, 0.0092316402475519244, 0.0091997118992211656, 0.0091691804170386942, 0.0091398663257965373, 0.0091118358221029712, 0.0090850219199759361, 0.0090592434754435906, 0.0090344388377212245, 0.0090106493658403484, 0.0089877940105018116, 0.0089658023789525032, 0.0089446034033169985, 0.0089241699436783343, 0.0089044195070142641, 0.0088853692933640073, 0.0088670057206515045, 0.0088493039132161652, 0.0088322319672010201, 0.0088157832941047325, 0.0087999342334868745, 0.0087846718333855437, 0.0087699183093238493, 0.0087556955837350351, 0.0087419335062175873, 0.0087286391015057221, 0.0087157715264306185, 0.0087033305247920158, 0.0086912688553388677, 0.0086795558000059593, 0.0086682100769921756, 0.0086571939677332413, 0.0086465245147398419, 0.0086361566025306737, 0.0086260424082108596, 0.0086161102649503045, 0.008606357266260899, 0.0085968686125784781, 0.0085876585957230696, 0.0085787202048091191, 0.0085700386061876681, 0.0085616126746548595, 0.008553425715647666, 0.0085454762923673176, 0.0085377399169157871, 0.008530240415917453, 0.0085229572500742715, 0.0085158641034647209, 0.008508957579704244, 0.008502232317629246, 0.0084956808095333972, 0.0084893017917262135, 0.0084830871177317933, 0.0084770168195094312, 0.0084710685695524989, 0.0084652331342650617, 0.0084594972985606205, 0.0084538813472680441, 0.0084483647670555283, 0.0084429564556889377, 0.0084376603877344986, 0.0084324718407981902, 0.0084273758860214931, 0.008422373008107607, 0.0084174446463861873, 0.0084126094688547152, 0.0084078554444873641, 0.0084031954594648902, 0.0083986325120227936, 0.0083941721658613595, 0.0083898137112366229, 0.0083855484009869256, 0.008381375291672117, 0.0083772981016581611, 0.0083733143710763257, 0.0083694210341788804, 0.0083656153922076568, 0.0083618939276022975, 0.0083582537165638685, 0.0083546956661797803, 0.0083512138873061727, 0.008347814431808695, 0.0083444867106535394, 0.0083412357976445483, 0.0083380523397410672, 0.0083349294039562725, 0.0083318686659783672], 'loss': [0.0099409936406931847, 0.0098916022135625975, 0.0098419653105228395, 0.0097927397601283543, 0.0097453978906380453, 0.0096999833665985091, 0.009655946987030253, 0.0096114084883590165, 0.0095651090012310331, 0.0095192985168412632, 0.0094753491801576675, 0.0094332252511755785, 0.0093927925467472834, 0.0093541097676710042, 0.009317288613696734, 0.0092821896360121264, 0.0092486647526105643, 0.0092166231346408802, 0.0091859650143869247, 0.0091566103427558124, 0.0091284925968700484, 0.0091016300568687973, 0.0090759081929720608, 0.009051127528706503, 0.0090273268768116238, 0.0090044818706375429, 0.0089825000528065274, 0.0089613310466094033, 0.008940910761941227, 0.0089212275970527999, 0.0089022245311900089, 0.0088838909391471786, 0.0088662073644680626, 0.008849164940984651, 0.0088327230041882129, 0.0088168884746011363, 0.0088016318733166836, 0.0087869309230072783, 0.0087727244918194003, 0.0087590244969040533, 0.0087457818323179639, 0.0087329705727195624, 0.0087205863568631872, 0.0087085997859804847, 0.0086969720725183046, 0.00868568041996679, 0.0086747447055087329, 0.0086641205050000843, 0.0086538417433109759, 0.0086438283518863439, 0.0086340396765209673, 0.0086244042406400136, 0.008615006233056631, 0.0086058632910856088, 0.0085969870943248677, 0.008588370976405196, 0.0085800087580843142, 0.0085718946104391854, 0.0085639978868322433, 0.0085563350322335214, 0.0085488770056353358, 0.0085416444186315853, 0.0085346207169205695, 0.0085277723488480905, 0.0085210988553356525, 0.008514610400220772, 0.0085082929982095677, 0.0085021339542362389, 0.0084961325069860798, 0.0084902523972721425, 0.0084844934911488309, 0.0084788420465995214, 0.0084732845574434206, 0.0084678417514750907, 0.0084625052067221641, 0.0084572680038070853, 0.0084521384931500881, 0.0084471013637393549, 0.0084421440040819765, 0.0084372753161220324, 0.0084324786502503885, 0.0084277644659579709, 0.0084231336696672168, 0.0084186026388029418, 0.0084141706973405866, 0.0084098423942786174, 0.0084056116368097251, 0.0084014765245092379, 0.0083974384689576506, 0.0083934982017039809, 0.0083896541594772091, 0.0083858799710228686, 0.0083821994202702629, 0.0083786015889361805, 0.0083750783652983048, 0.0083716321569428393, 0.008368259996459685, 0.0083649706269471862, 0.0083617513882569845, 0.0083586033851540224, 0.0083555120267271629, 0.0083524952742792605]}
[2017-10-10 15:53:25,463 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:130]: evaluating model ... 
[2017-10-10 15:53:25,519 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:134]: evaluated! 
[2017-10-10 15:53:25,519 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:136]: generating reports ... 
[2017-10-10 15:53:25,908 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:139]: done!
[2017-10-10 15:53:25,909 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:155]: >> experiment AE_UNIGRAMA_2L_UNDER_96_76_66_9 finished!

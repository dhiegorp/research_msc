[2017-09-18 07:42:52,586 AE_UNIGRAMA_1L_OVER_F2_0.py:154]: >> Initializing execution of experiment AE_UNIGRAMA_1L_OVER_F2_0
[2017-09-18 07:42:52,586 AE_UNIGRAMA_1L_OVER_F2_0.py:155]: >> Printing header log
[2017-09-18 07:42:52,587 AE_UNIGRAMA_1L_OVER_F2_0.py:47]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_OVER_F2_0
	layers = 96,192
	using GLOBAL obj = 
		{'shuffle_batches': True, 'store_history': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x00000000019BB5C0>, 'discard_decoder_function': True, 'output_layer_activation': 'relu', 'loss_function': 'mse'}, 'batch': 32, 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram.pkl', 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'mlp_configs': {'classifier_dim': 9, 'use_last_dim_as_classifier': False, 'optimizer': <keras.optimizers.SGD object at 0x00000000019BE438>, 'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy'}, 'numpy_seed': 666, 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'executed_dir': 'E:/research/research_msc/executed/onelayer/unigram/', 'epochs': 1000, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9]}
	=======================================
	
[2017-09-18 07:42:52,587 AE_UNIGRAMA_1L_OVER_F2_0.py:157]: >> Loading dataset... 
[2017-09-18 07:42:52,608 AE_UNIGRAMA_1L_OVER_F2_0.py:63]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram.pkl	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-09-18 07:42:52,608 AE_UNIGRAMA_1L_OVER_F2_0.py:159]: >> Executing autoencoder part ... 
[2017-09-18 07:42:52,608 AE_UNIGRAMA_1L_OVER_F2_0.py:68]: =======================================
[2017-09-18 07:42:52,608 AE_UNIGRAMA_1L_OVER_F2_0.py:73]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x00000000019BB5C0>, 'discard_decoder_function': True, 'output_layer_activation': 'relu', 'loss_function': 'mse'}
[2017-09-18 07:42:52,696 AE_UNIGRAMA_1L_OVER_F2_0.py:84]: training and evaluate autoencoder
[2017-09-18 07:42:53,246 summary.py:93]: Summary name enc0_192/kernel:0 is illegal; using enc0_192/kernel_0 instead.
[2017-09-18 07:42:53,246 summary.py:93]: Summary name enc0_192/bias:0 is illegal; using enc0_192/bias_0 instead.
[2017-09-18 07:42:53,246 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-09-18 07:42:53,246 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-09-18 07:45:28,032 AE_UNIGRAMA_1L_OVER_F2_0.py:95]: trained and evaluated!
[2017-09-18 07:45:28,034 AE_UNIGRAMA_1L_OVER_F2_0.py:98]: Training history: 
{'loss': [0.0098103710052530879, 0.0092524135192874248, 0.0087242452370587479, 0.0082840572011397447, 0.0079232578574961812, 0.0076253387454690942, 0.0073768115954866171, 0.0071681497258578759, 0.006991187587864647, 0.0068395094771925378, 0.0067094527438170482, 0.0065974939359155146, 0.0065004270786367608, 0.0064157817247654635, 0.0063411263755062093, 0.0062748831780829704, 0.0062158035807841037, 0.0061627920040600364, 0.006114808761261973, 0.0060710499715414369, 0.0060308882543101327, 0.0059937970585091337, 0.005959376402069407, 0.005927291639138672, 0.0058972128024259614, 0.0058689075200328636, 0.0058421890165716705, 0.0058168657066313542, 0.0057927899016793289, 0.005769840611744596, 0.005747892105821815, 0.0057268314847977115, 0.0057065408953275876, 0.0056868985163719393, 0.0056677362701555069, 0.0056489547821475354, 0.0056305174193169768, 0.0056122781579546529, 0.0055942011227650855, 0.0055764301185502671, 0.0055590330493800241, 0.005542072548326487, 0.0055255934723979954, 0.0055096342899495143, 0.0054941335124285675, 0.0054789279267256821, 0.0054639723683828929, 0.0054492981911457303, 0.0054348949660189619, 0.0054206828593844703, 0.0054066265001321469, 0.0053927199562390339, 0.0053789846100575234, 0.0053654608438579096, 0.0053521515941012997, 0.0053390747636837379, 0.0053261693936731604, 0.0053133293172970778, 0.0053006291599347281, 0.0052880866681566828, 0.0052756454630528433, 0.0052632250761579184, 0.0052508327735484384, 0.0052385854811903866, 0.0052265167811674455, 0.0052146233584079308, 0.0052028740158918899, 0.0051912741142398147, 0.0051798943752667335, 0.0051687683514487978, 0.0051578791515186758, 0.0051472310079242224, 0.0051368125624052987, 0.0051265917828724264, 0.0051165483775934446, 0.0051066669635131739, 0.0050968923368203732, 0.0050871049962941031, 0.0050771596248334674, 0.0050669068603659681, 0.0050562027829460414, 0.0050453466348504604, 0.005034574283095109, 0.0050239918917660787, 0.0050136561763733604, 0.0050035337278487033, 0.0049935663503056157, 0.004983768842479243, 0.0049741242701770508, 0.0049645886864507216, 0.0049552314123590332, 0.0049460552825086159, 0.0049370427945624419, 0.0049281547929622017, 0.00491936357283323, 0.0049105816949659604, 0.0049017002087941974, 0.0048926449495129819, 0.0048834296546732851, 0.0048741637646230115, 0.0048648700583554692, 0.0048554227806877417], 'val_loss': [0.0095229876121230225, 0.0089593073045126388, 0.0084707519342080272, 0.0080709219482364199, 0.007742121667991016, 0.0074691102483701024, 0.0072405512556940237, 0.0070477012806366311, 0.0068830319075136332, 0.0067416528066656508, 0.0066202925206687423, 0.0065153632441365137, 0.0064240855959581894, 0.0063439155176647473, 0.0062728966149894769, 0.0062095842847702575, 0.0061529155571434001, 0.0061018451791084163, 0.0060554178251423837, 0.0060129496452899344, 0.0059738357594008775, 0.0059376367634262931, 0.0059039710060128916, 0.0058724941439873227, 0.0058429202834813032, 0.0058150623262904723, 0.0057887116397290503, 0.005763635097943638, 0.0057397542435960631, 0.0057169362480448578, 0.0056950525394875318, 0.0056740095323271353, 0.0056537028451034994, 0.0056339693313053113, 0.0056146544572725776, 0.0055957293009213649, 0.0055770592282100755, 0.0055584589738873862, 0.0055401048584348663, 0.00552208758697245, 0.0055045084301341227, 0.0054873747961443004, 0.0054707835446899424, 0.005454693291471838, 0.0054390089293221032, 0.0054235916046678299, 0.0054084556974752646, 0.0053936181318196951, 0.0053790256723135884, 0.005364611750271463, 0.0053503518039001259, 0.0053362540274520306, 0.005322346349737276, 0.0053086543460169489, 0.0052951940206810147, 0.0052819389738491609, 0.0052688105422209362, 0.0052557761487590391, 0.0052429265374312976, 0.0052302220321333295, 0.0052175817558766423, 0.0052049651440183023, 0.0051924403445303673, 0.0051800763504548861, 0.0051678885195013419, 0.0051558147746219394, 0.0051438730841215728, 0.0051321488352374708, 0.0051206884710515207, 0.0051094803206817013, 0.0050985116086909137, 0.0050877891340163272, 0.0050773077866627953, 0.0050670202463476456, 0.0050569146491901366, 0.0050469533879500192, 0.0050370572738534947, 0.0050270634103335033, 0.0050168894950090989, 0.0050062635471190041, 0.0049953490150585851, 0.004984445020189192, 0.0049736773960503862, 0.00496314970042436, 0.0049528515076580314, 0.004942734470566648, 0.0049327985881233933, 0.0049230275278276418, 0.004913403281585362, 0.0049039448489674948, 0.0048946456195004843, 0.004885508322890455, 0.004876516196400664, 0.0048676553715906222, 0.0048588556709426543, 0.0048500003484144493, 0.0048410025586465488, 0.004831753957522735, 0.0048223985938796177, 0.004813033861990502, 0.0048035826134515628, 0.0047938954513379673]}
[2017-09-18 07:45:28,034 AE_UNIGRAMA_1L_OVER_F2_0.py:102]: done!
[2017-09-18 07:45:28,034 AE_UNIGRAMA_1L_OVER_F2_0.py:161]: >> Executing classifier part ... 
[2017-09-18 07:45:28,034 AE_UNIGRAMA_1L_OVER_F2_0.py:107]: =======================================
[2017-09-18 07:45:28,035 AE_UNIGRAMA_1L_OVER_F2_0.py:111]: setting configurations for classifier: 
	 {'classifier_dim': 9, 'use_last_dim_as_classifier': False, 'optimizer': <keras.optimizers.SGD object at 0x00000000019BE438>, 'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy'}
[2017-09-18 07:45:28,250 AE_UNIGRAMA_1L_OVER_F2_0.py:120]: training ... 
[2017-09-18 07:45:30,946 summary.py:93]: Summary name enc0_192/kernel:0 is illegal; using enc0_192/kernel_0 instead.
[2017-09-18 07:45:30,946 summary.py:93]: Summary name enc0_192/bias:0 is illegal; using enc0_192/bias_0 instead.
[2017-09-18 07:45:30,961 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-09-18 07:45:30,977 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-09-18 07:50:16,089 AE_UNIGRAMA_1L_OVER_F2_0.py:132]: trained!
[2017-09-18 07:50:16,089 AE_UNIGRAMA_1L_OVER_F2_0.py:135]: Training history: 
{'loss': [0.0098103710052530879, 0.0092524135192874248, 0.0087242452370587479, 0.0082840572011397447, 0.0079232578574961812, 0.0076253387454690942, 0.0073768115954866171, 0.0071681497258578759, 0.006991187587864647, 0.0068395094771925378, 0.0067094527438170482, 0.0065974939359155146, 0.0065004270786367608, 0.0064157817247654635, 0.0063411263755062093, 0.0062748831780829704, 0.0062158035807841037, 0.0061627920040600364, 0.006114808761261973, 0.0060710499715414369, 0.0060308882543101327, 0.0059937970585091337, 0.005959376402069407, 0.005927291639138672, 0.0058972128024259614, 0.0058689075200328636, 0.0058421890165716705, 0.0058168657066313542, 0.0057927899016793289, 0.005769840611744596, 0.005747892105821815, 0.0057268314847977115, 0.0057065408953275876, 0.0056868985163719393, 0.0056677362701555069, 0.0056489547821475354, 0.0056305174193169768, 0.0056122781579546529, 0.0055942011227650855, 0.0055764301185502671, 0.0055590330493800241, 0.005542072548326487, 0.0055255934723979954, 0.0055096342899495143, 0.0054941335124285675, 0.0054789279267256821, 0.0054639723683828929, 0.0054492981911457303, 0.0054348949660189619, 0.0054206828593844703, 0.0054066265001321469, 0.0053927199562390339, 0.0053789846100575234, 0.0053654608438579096, 0.0053521515941012997, 0.0053390747636837379, 0.0053261693936731604, 0.0053133293172970778, 0.0053006291599347281, 0.0052880866681566828, 0.0052756454630528433, 0.0052632250761579184, 0.0052508327735484384, 0.0052385854811903866, 0.0052265167811674455, 0.0052146233584079308, 0.0052028740158918899, 0.0051912741142398147, 0.0051798943752667335, 0.0051687683514487978, 0.0051578791515186758, 0.0051472310079242224, 0.0051368125624052987, 0.0051265917828724264, 0.0051165483775934446, 0.0051066669635131739, 0.0050968923368203732, 0.0050871049962941031, 0.0050771596248334674, 0.0050669068603659681, 0.0050562027829460414, 0.0050453466348504604, 0.005034574283095109, 0.0050239918917660787, 0.0050136561763733604, 0.0050035337278487033, 0.0049935663503056157, 0.004983768842479243, 0.0049741242701770508, 0.0049645886864507216, 0.0049552314123590332, 0.0049460552825086159, 0.0049370427945624419, 0.0049281547929622017, 0.00491936357283323, 0.0049105816949659604, 0.0049017002087941974, 0.0048926449495129819, 0.0048834296546732851, 0.0048741637646230115, 0.0048648700583554692, 0.0048554227806877417], 'val_loss': [0.0095229876121230225, 0.0089593073045126388, 0.0084707519342080272, 0.0080709219482364199, 0.007742121667991016, 0.0074691102483701024, 0.0072405512556940237, 0.0070477012806366311, 0.0068830319075136332, 0.0067416528066656508, 0.0066202925206687423, 0.0065153632441365137, 0.0064240855959581894, 0.0063439155176647473, 0.0062728966149894769, 0.0062095842847702575, 0.0061529155571434001, 0.0061018451791084163, 0.0060554178251423837, 0.0060129496452899344, 0.0059738357594008775, 0.0059376367634262931, 0.0059039710060128916, 0.0058724941439873227, 0.0058429202834813032, 0.0058150623262904723, 0.0057887116397290503, 0.005763635097943638, 0.0057397542435960631, 0.0057169362480448578, 0.0056950525394875318, 0.0056740095323271353, 0.0056537028451034994, 0.0056339693313053113, 0.0056146544572725776, 0.0055957293009213649, 0.0055770592282100755, 0.0055584589738873862, 0.0055401048584348663, 0.00552208758697245, 0.0055045084301341227, 0.0054873747961443004, 0.0054707835446899424, 0.005454693291471838, 0.0054390089293221032, 0.0054235916046678299, 0.0054084556974752646, 0.0053936181318196951, 0.0053790256723135884, 0.005364611750271463, 0.0053503518039001259, 0.0053362540274520306, 0.005322346349737276, 0.0053086543460169489, 0.0052951940206810147, 0.0052819389738491609, 0.0052688105422209362, 0.0052557761487590391, 0.0052429265374312976, 0.0052302220321333295, 0.0052175817558766423, 0.0052049651440183023, 0.0051924403445303673, 0.0051800763504548861, 0.0051678885195013419, 0.0051558147746219394, 0.0051438730841215728, 0.0051321488352374708, 0.0051206884710515207, 0.0051094803206817013, 0.0050985116086909137, 0.0050877891340163272, 0.0050773077866627953, 0.0050670202463476456, 0.0050569146491901366, 0.0050469533879500192, 0.0050370572738534947, 0.0050270634103335033, 0.0050168894950090989, 0.0050062635471190041, 0.0049953490150585851, 0.004984445020189192, 0.0049736773960503862, 0.00496314970042436, 0.0049528515076580314, 0.004942734470566648, 0.0049327985881233933, 0.0049230275278276418, 0.004913403281585362, 0.0049039448489674948, 0.0048946456195004843, 0.004885508322890455, 0.004876516196400664, 0.0048676553715906222, 0.0048588556709426543, 0.0048500003484144493, 0.0048410025586465488, 0.004831753957522735, 0.0048223985938796177, 0.004813033861990502, 0.0048035826134515628, 0.0047938954513379673]}
[2017-09-18 07:50:16,089 AE_UNIGRAMA_1L_OVER_F2_0.py:139]: evaluating model ... 
[2017-09-18 07:50:16,151 AE_UNIGRAMA_1L_OVER_F2_0.py:143]: evaluated! 
[2017-09-18 07:50:16,151 AE_UNIGRAMA_1L_OVER_F2_0.py:145]: generating reports ... 
[2017-09-18 07:50:16,946 AE_UNIGRAMA_1L_OVER_F2_0.py:148]: done!
[2017-09-18 07:50:16,946 AE_UNIGRAMA_1L_OVER_F2_0.py:163]: >> experiment AE_UNIGRAMA_1L_OVER_F2_0 finished!

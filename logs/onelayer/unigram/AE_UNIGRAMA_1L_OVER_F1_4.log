[2017-10-02 10:10:43,232 AE_UNIGRAMA_1L_OVER_F1_4.py:157]: >> Initializing execution of experiment AE_UNIGRAMA_1L_OVER_F1_4
[2017-10-02 10:10:43,232 AE_UNIGRAMA_1L_OVER_F1_4.py:158]: >> Printing header log
[2017-10-02 10:10:43,233 AE_UNIGRAMA_1L_OVER_F1_4.py:48]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_OVER_F1_4
	layers = 96,134
	using GLOBAL obj = 
		{'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'epochs': 200, 'mlp_configs': {'use_last_dim_as_classifier': False, 'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x0000000001100390>, 'loss_function': 'categorical_crossentropy', 'classifier_dim': 9}, 'store_history': True, 'executed_path': 'E:/research/research_msc/executed/onelayer/unigram/', 'batch': 32, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x00000000010FD518>, 'discard_decoder_function': True}, 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'numpy_seed': 666, 'shuffle_batches': True, 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram_mini.pkl'}
	=======================================
	
[2017-10-02 10:10:43,233 AE_UNIGRAMA_1L_OVER_F1_4.py:160]: >> Loading dataset... 
[2017-10-02 10:10:43,238 AE_UNIGRAMA_1L_OVER_F1_4.py:64]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram_mini.pkl	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-02 10:10:43,238 AE_UNIGRAMA_1L_OVER_F1_4.py:162]: >> Executing autoencoder part ... 
[2017-10-02 10:10:43,238 AE_UNIGRAMA_1L_OVER_F1_4.py:69]: =======================================
[2017-10-02 10:10:43,238 AE_UNIGRAMA_1L_OVER_F1_4.py:74]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x00000000010FD518>, 'discard_decoder_function': True}
[2017-10-02 10:10:43,294 AE_UNIGRAMA_1L_OVER_F1_4.py:85]: training and evaluate autoencoder
[2017-10-02 10:10:43,647 summary.py:93]: Summary name enc0_134/kernel:0 is illegal; using enc0_134/kernel_0 instead.
[2017-10-02 10:10:43,649 summary.py:93]: Summary name enc0_134/bias:0 is illegal; using enc0_134/bias_0 instead.
[2017-10-02 10:10:43,652 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-10-02 10:10:43,654 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-10-02 10:10:54,942 AE_UNIGRAMA_1L_OVER_F1_4.py:96]: trained and evaluated!
[2017-10-02 10:10:54,942 AE_UNIGRAMA_1L_OVER_F1_4.py:99]: Training history: 
{'val_loss': [0.010140401179656441, 0.010096558006168741, 0.010045917455425492, 0.0099833803839953859, 0.0099071137967162853, 0.0098134865949698977, 0.0097079946205961658, 0.0095997176455077625, 0.0094923218885318936, 0.0093885805790198344, 0.0092886170427761549, 0.0091925732147460984, 0.0091002236802449465, 0.0090113433673423907, 0.0089259407323781671, 0.0088438973346635086, 0.0087650576415973739, 0.0086892150813318979, 0.0086161934469435302, 0.0085459192453097681, 0.0084783123099837158, 0.0084131872731513686, 0.0083504490533559735, 0.0082899627559662528, 0.0082316763982952304, 0.0081754795493745001, 0.0081212443081475107, 0.0080689884666838175, 0.0080184914504063624, 0.0079697471347440138, 0.0079226793658999269, 0.0078772367064782241, 0.0078333631767216229, 0.0077909652150641145, 0.0077499412969585686, 0.0077102571521577559, 0.0076719106081526963, 0.0076347840967203829, 0.0075988838601455813, 0.0075640772611290548, 0.0075303398238903531, 0.007497690614576012, 0.0074660033680027747, 0.0074353518629218119, 0.0074056114665609976, 0.0073767714237025677, 0.007348822869471236, 0.007321661457654823, 0.0072953235825392168, 0.0072697250200193164, 0.0072448806781806466, 0.0072207518863633665, 0.0071972991204837886, 0.0071745213834381897, 0.0071523540175509499, 0.0071307987989130735, 0.0071098539843241302, 0.0070894626921326701, 0.0070696113194896387, 0.0070502983845881148, 0.0070314710634348564, 0.0070131446813063549, 0.0069953135775616846, 0.0069779212150348829, 0.0069609770090855849, 0.0069444550454034904, 0.0069283368775697228, 0.0069125894367085515, 0.006897243215844423, 0.0068822631882469003, 0.0068676407590896223, 0.0068533672089082604, 0.0068394293260784838, 0.0068258146346861764, 0.0068125003242525909, 0.0067995174954122552, 0.0067868266327368951, 0.0067744055333578456, 0.0067622585578728123, 0.0067503695916315215, 0.0067387361020597603, 0.006727341842944959, 0.0067162020235810582, 0.0067052739035324315, 0.0066945690983650184, 0.0066840706123073752, 0.0066737867995653455, 0.0066637131852897566, 0.0066538284148425419, 0.0066441227751178151, 0.006634609112481424, 0.0066252719995229881, 0.006616079051144504, 0.0066070405413227009, 0.0065981561359585881, 0.0065894429346885827, 0.0065808622599285108, 0.0065724232240985097, 0.0065641160950507815, 0.0065559527895596836, 0.0065479148490887595, 0.0065399875767445919], 'loss': [0.010184146706575841, 0.01014036273603232, 0.010091688882355758, 0.010032644498802507, 0.0099615242255516184, 0.0098752307081074169, 0.009772595640365778, 0.0096632922142652483, 0.0095532677567391651, 0.0094458238801563461, 0.0093421293588580711, 0.009242371217529138, 0.0091464982385796936, 0.0090543748101090168, 0.0089656284586117178, 0.0088803386767912877, 0.0087982800376464713, 0.00871934547170896, 0.0086433885644230657, 0.0085702413897995721, 0.0084997566626364273, 0.0084319131880467406, 0.0083665699665403173, 0.008303628705519801, 0.0082429092384293245, 0.0081844047420574027, 0.0081279842817231999, 0.0080735454937991506, 0.0080210879054687552, 0.0079703828086361023, 0.0079214388467989671, 0.0078741685288701239, 0.0078285518734868709, 0.0077845125047566709, 0.0077419486540794991, 0.0077007255452835608, 0.0076608374169910331, 0.0076222691945983505, 0.0075849137533989582, 0.007548790934227164, 0.0075137559710884471, 0.0074797914255829443, 0.0074469037110715206, 0.0074149595465357676, 0.0073840794996109455, 0.0073541103419747615, 0.0073250522464971711, 0.0072968819407035253, 0.0072695135480089464, 0.007242953347256287, 0.0072171595325371792, 0.0071921180515849455, 0.0071677936206113249, 0.0071441463424326748, 0.007121173245631978, 0.0070988255471091883, 0.0070770882684268064, 0.0070559581805801344, 0.0070353967427277796, 0.0070153840545040553, 0.0069959134389500381, 0.0069769256088262187, 0.0069584521472444913, 0.0069404508673529281, 0.0069229047051124325, 0.0069057988681210537, 0.0068891201939344513, 0.0068728429715812535, 0.0068569494552736315, 0.0068414561612475449, 0.006826343546039353, 0.006811589155444611, 0.0067971688583630613, 0.0067830986200792332, 0.0067693393319139981, 0.0067558946593400705, 0.0067427732235309564, 0.0067299476400539786, 0.0067173874437277785, 0.0067051127349778087, 0.0066930830138652473, 0.0066813131088543209, 0.0066698055380077252, 0.006658539974795266, 0.0066475067917342269, 0.0066366892527804904, 0.0066260980913265578, 0.0066157184202354528, 0.0066055497125972612, 0.0065955627571102219, 0.0065857603257040015, 0.0065761475824392054, 0.0065667094621571498, 0.0065574407953592666, 0.0065483315925090385, 0.0065393804855296677, 0.0065305869529492001, 0.0065219378483509756, 0.0065134243859915775, 0.0065050602984427488, 0.0064968340191589443, 0.0064887319435036356]}
[2017-10-02 10:10:54,942 AE_UNIGRAMA_1L_OVER_F1_4.py:103]: done!
[2017-10-02 10:10:54,943 AE_UNIGRAMA_1L_OVER_F1_4.py:164]: >> Executing classifier part ... 
[2017-10-02 10:10:54,943 AE_UNIGRAMA_1L_OVER_F1_4.py:108]: =======================================
[2017-10-02 10:10:54,943 AE_UNIGRAMA_1L_OVER_F1_4.py:112]: setting configurations for classifier: 
	 {'use_last_dim_as_classifier': False, 'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x0000000001100390>, 'loss_function': 'categorical_crossentropy', 'classifier_dim': 9}
[2017-10-02 10:10:54,997 AE_UNIGRAMA_1L_OVER_F1_4.py:121]: training ... 
[2017-10-02 10:10:55,395 summary.py:93]: Summary name enc0_134/kernel:0 is illegal; using enc0_134/kernel_0 instead.
[2017-10-02 10:10:55,397 summary.py:93]: Summary name enc0_134/bias:0 is illegal; using enc0_134/bias_0 instead.
[2017-10-02 10:10:55,400 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-10-02 10:10:55,401 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-10-02 10:11:18,296 AE_UNIGRAMA_1L_OVER_F1_4.py:133]: trained!
[2017-10-02 10:11:18,296 AE_UNIGRAMA_1L_OVER_F1_4.py:136]: Training history: 
{'val_loss': [0.010140401179656441, 0.010096558006168741, 0.010045917455425492, 0.0099833803839953859, 0.0099071137967162853, 0.0098134865949698977, 0.0097079946205961658, 0.0095997176455077625, 0.0094923218885318936, 0.0093885805790198344, 0.0092886170427761549, 0.0091925732147460984, 0.0091002236802449465, 0.0090113433673423907, 0.0089259407323781671, 0.0088438973346635086, 0.0087650576415973739, 0.0086892150813318979, 0.0086161934469435302, 0.0085459192453097681, 0.0084783123099837158, 0.0084131872731513686, 0.0083504490533559735, 0.0082899627559662528, 0.0082316763982952304, 0.0081754795493745001, 0.0081212443081475107, 0.0080689884666838175, 0.0080184914504063624, 0.0079697471347440138, 0.0079226793658999269, 0.0078772367064782241, 0.0078333631767216229, 0.0077909652150641145, 0.0077499412969585686, 0.0077102571521577559, 0.0076719106081526963, 0.0076347840967203829, 0.0075988838601455813, 0.0075640772611290548, 0.0075303398238903531, 0.007497690614576012, 0.0074660033680027747, 0.0074353518629218119, 0.0074056114665609976, 0.0073767714237025677, 0.007348822869471236, 0.007321661457654823, 0.0072953235825392168, 0.0072697250200193164, 0.0072448806781806466, 0.0072207518863633665, 0.0071972991204837886, 0.0071745213834381897, 0.0071523540175509499, 0.0071307987989130735, 0.0071098539843241302, 0.0070894626921326701, 0.0070696113194896387, 0.0070502983845881148, 0.0070314710634348564, 0.0070131446813063549, 0.0069953135775616846, 0.0069779212150348829, 0.0069609770090855849, 0.0069444550454034904, 0.0069283368775697228, 0.0069125894367085515, 0.006897243215844423, 0.0068822631882469003, 0.0068676407590896223, 0.0068533672089082604, 0.0068394293260784838, 0.0068258146346861764, 0.0068125003242525909, 0.0067995174954122552, 0.0067868266327368951, 0.0067744055333578456, 0.0067622585578728123, 0.0067503695916315215, 0.0067387361020597603, 0.006727341842944959, 0.0067162020235810582, 0.0067052739035324315, 0.0066945690983650184, 0.0066840706123073752, 0.0066737867995653455, 0.0066637131852897566, 0.0066538284148425419, 0.0066441227751178151, 0.006634609112481424, 0.0066252719995229881, 0.006616079051144504, 0.0066070405413227009, 0.0065981561359585881, 0.0065894429346885827, 0.0065808622599285108, 0.0065724232240985097, 0.0065641160950507815, 0.0065559527895596836, 0.0065479148490887595, 0.0065399875767445919], 'loss': [0.010184146706575841, 0.01014036273603232, 0.010091688882355758, 0.010032644498802507, 0.0099615242255516184, 0.0098752307081074169, 0.009772595640365778, 0.0096632922142652483, 0.0095532677567391651, 0.0094458238801563461, 0.0093421293588580711, 0.009242371217529138, 0.0091464982385796936, 0.0090543748101090168, 0.0089656284586117178, 0.0088803386767912877, 0.0087982800376464713, 0.00871934547170896, 0.0086433885644230657, 0.0085702413897995721, 0.0084997566626364273, 0.0084319131880467406, 0.0083665699665403173, 0.008303628705519801, 0.0082429092384293245, 0.0081844047420574027, 0.0081279842817231999, 0.0080735454937991506, 0.0080210879054687552, 0.0079703828086361023, 0.0079214388467989671, 0.0078741685288701239, 0.0078285518734868709, 0.0077845125047566709, 0.0077419486540794991, 0.0077007255452835608, 0.0076608374169910331, 0.0076222691945983505, 0.0075849137533989582, 0.007548790934227164, 0.0075137559710884471, 0.0074797914255829443, 0.0074469037110715206, 0.0074149595465357676, 0.0073840794996109455, 0.0073541103419747615, 0.0073250522464971711, 0.0072968819407035253, 0.0072695135480089464, 0.007242953347256287, 0.0072171595325371792, 0.0071921180515849455, 0.0071677936206113249, 0.0071441463424326748, 0.007121173245631978, 0.0070988255471091883, 0.0070770882684268064, 0.0070559581805801344, 0.0070353967427277796, 0.0070153840545040553, 0.0069959134389500381, 0.0069769256088262187, 0.0069584521472444913, 0.0069404508673529281, 0.0069229047051124325, 0.0069057988681210537, 0.0068891201939344513, 0.0068728429715812535, 0.0068569494552736315, 0.0068414561612475449, 0.006826343546039353, 0.006811589155444611, 0.0067971688583630613, 0.0067830986200792332, 0.0067693393319139981, 0.0067558946593400705, 0.0067427732235309564, 0.0067299476400539786, 0.0067173874437277785, 0.0067051127349778087, 0.0066930830138652473, 0.0066813131088543209, 0.0066698055380077252, 0.006658539974795266, 0.0066475067917342269, 0.0066366892527804904, 0.0066260980913265578, 0.0066157184202354528, 0.0066055497125972612, 0.0065955627571102219, 0.0065857603257040015, 0.0065761475824392054, 0.0065667094621571498, 0.0065574407953592666, 0.0065483315925090385, 0.0065393804855296677, 0.0065305869529492001, 0.0065219378483509756, 0.0065134243859915775, 0.0065050602984427488, 0.0064968340191589443, 0.0064887319435036356]}
[2017-10-02 10:11:18,297 AE_UNIGRAMA_1L_OVER_F1_4.py:140]: evaluating model ... 
[2017-10-02 10:11:18,319 AE_UNIGRAMA_1L_OVER_F1_4.py:144]: evaluated! 
[2017-10-02 10:11:18,319 AE_UNIGRAMA_1L_OVER_F1_4.py:146]: generating reports ... 
[2017-10-02 10:11:18,789 AE_UNIGRAMA_1L_OVER_F1_4.py:149]: done!
[2017-10-02 10:11:18,789 AE_UNIGRAMA_1L_OVER_F1_4.py:166]: >> experiment AE_UNIGRAMA_1L_OVER_F1_4 finished!

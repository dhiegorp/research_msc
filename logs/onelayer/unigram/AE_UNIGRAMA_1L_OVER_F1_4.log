[2017-09-18 07:42:51,840 AE_UNIGRAMA_1L_OVER_F1_4.py:155]: >> Initializing execution of experiment AE_UNIGRAMA_1L_OVER_F1_4
[2017-09-18 07:42:51,840 AE_UNIGRAMA_1L_OVER_F1_4.py:156]: >> Printing header log
[2017-09-18 07:42:51,840 AE_UNIGRAMA_1L_OVER_F1_4.py:47]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_OVER_F1_4
	layers = 96,134
	using GLOBAL obj = 
		{'mlp_configs': {'classifier_dim': 9, 'loss_function': 'categorical_crossentropy', 'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x00000000019EE438>, 'use_last_dim_as_classifier': False}, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'executed_dir': 'E:/research/research_msc/executed/onelayer/unigram/', 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'epochs': 1000, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'batch': 32, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x00000000019EB5C0>, 'loss_function': 'mse', 'discard_decoder_function': True}, 'numpy_seed': 666, 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'store_history': True, 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram.pkl'}
	=======================================
	
[2017-09-18 07:42:51,840 AE_UNIGRAMA_1L_OVER_F1_4.py:158]: >> Loading dataset... 
[2017-09-18 07:42:51,856 AE_UNIGRAMA_1L_OVER_F1_4.py:63]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram.pkl	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-09-18 07:42:51,856 AE_UNIGRAMA_1L_OVER_F1_4.py:160]: >> Executing autoencoder part ... 
[2017-09-18 07:42:51,856 AE_UNIGRAMA_1L_OVER_F1_4.py:68]: =======================================
[2017-09-18 07:42:51,856 AE_UNIGRAMA_1L_OVER_F1_4.py:73]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x00000000019EB5C0>, 'loss_function': 'mse', 'discard_decoder_function': True}
[2017-09-18 07:42:51,918 AE_UNIGRAMA_1L_OVER_F1_4.py:84]: training and evaluate autoencoder
[2017-09-18 07:42:52,265 summary.py:93]: Summary name enc0_134/kernel:0 is illegal; using enc0_134/kernel_0 instead.
[2017-09-18 07:42:52,268 summary.py:93]: Summary name enc0_134/bias:0 is illegal; using enc0_134/bias_0 instead.
[2017-09-18 07:42:52,271 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-09-18 07:42:52,273 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-09-18 07:44:33,925 AE_UNIGRAMA_1L_OVER_F1_4.py:95]: trained and evaluated!
[2017-09-18 07:44:33,925 AE_UNIGRAMA_1L_OVER_F1_4.py:98]: Training history: 
{'val_loss': [0.010072303217456145, 0.0099614290496589774, 0.009862610315565172, 0.0097706394936808629, 0.0096810971722499674, 0.0095926792939624462, 0.0095032467368205698, 0.0094074676879837386, 0.0092828044577480152, 0.0089192982285240044, 0.0083528521942376581, 0.0078663927691522122, 0.0074723675740606885, 0.0071531629907935915, 0.0068939161931535244, 0.006682160480043076, 0.0065082426341055441, 0.0063646619961326969, 0.0062450924391958566, 0.0061450330401061921, 0.0060602160057211096, 0.005987651466701052, 0.0059251372423639072, 0.0058705051504356186, 0.0058218380816223341, 0.0057773404293144258, 0.0057366813430497583, 0.0056995565581002992, 0.0056656363191037208, 0.0056344482151655228, 0.0056055747363606837, 0.00557868628887934, 0.0055534496719191499, 0.0055295972629987285, 0.0055069576890095905, 0.0054853687662520375, 0.0054647177418875991, 0.0054448238157337615, 0.0054256071115202876, 0.0054069991008823858, 0.0053889046733578043, 0.0053712864587725558, 0.0053540652563733157, 0.0053372070389155956, 0.0053206410348683713, 0.0053042314367526943, 0.0052879229650460661, 0.0052717273306763512, 0.0052557457753127524, 0.0052399885240796435, 0.0052244093315573174, 0.0052089677457531685, 0.0051937837600595062, 0.0051788123741999918, 0.0051639845263358724, 0.0051491611502576555, 0.0051341981208448198, 0.0051193088210930238, 0.005104567802073732, 0.0050899495008476531, 0.0050754596909473194, 0.005061199532495589, 0.0050471238486892523, 0.0050333209466466387, 0.0050197904732284361, 0.005006527190643627, 0.0049935920420778766, 0.0049809730250729971, 0.0049686445047269767, 0.0049565417243431992, 0.0049445963891576296, 0.0049328645892788335, 0.0049213350304525283, 0.0049100333825780581, 0.0048989136585656338, 0.0048880003997149035, 0.0048772720735552983, 0.0048667306361722708, 0.0048563860288182142, 0.0048462293673055476, 0.0048361669559540341, 0.0048230928345335232, 0.0048090089864663314, 0.0047954105946551272, 0.0047822085405826208, 0.0047692584927381725, 0.0047566283250194026, 0.0047443369255020934, 0.0047322997590783641, 0.0047204925675504387, 0.0047086429116406838, 0.0046966433368410363, 0.0046849196829543182, 0.0046735437595802646, 0.0046624880525287281, 0.0046517428284776575, 0.0046412814321689167, 0.0046310634808772299, 0.0046210705546695756, 0.0046112791554063139, 0.0046016704438710141, 0.0045922373781988358], 'loss': [0.010146125355111033, 0.010027955936084382, 0.009922878003717054, 0.0098274478671002991, 0.0097366783079077708, 0.0096477331884906783, 0.0095592774423343407, 0.0094664977513399095, 0.009362270751501851, 0.0091521064067819347, 0.0086528221551089753, 0.0081245965361265923, 0.0076887184331963822, 0.007335926462614154, 0.0070498320526690686, 0.0068169100816739192, 0.0066262105245719783, 0.0064692854889517289, 0.0063393795707897384, 0.0062308800326162095, 0.0061396985740380392, 0.0060621129365564051, 0.0059955145254213561, 0.0059378061453741289, 0.005886965398064538, 0.0058411045918019145, 0.0057991025762476334, 0.0057607736759508728, 0.0057257988674325406, 0.0056937499863132278, 0.0056642175825730896, 0.0056367940478035099, 0.005611150146728262, 0.0055869909280476006, 0.0055640994551601521, 0.0055423383667884, 0.0055215552950953978, 0.0055016210271045338, 0.0054823901494904367, 0.0054637729426350009, 0.0054457060021270674, 0.0054281281310883424, 0.0054109682592151679, 0.0053941594945236893, 0.0053776851994110876, 0.0053614354909597602, 0.0053453384215572108, 0.0053293552254585564, 0.0053135467388217795, 0.0052979560695818129, 0.0052825611450964208, 0.0052672226497624767, 0.0052520430722741776, 0.0052370200797524956, 0.0052221985672725969, 0.0052074410830196521, 0.005192580821827773, 0.0051777103224892006, 0.005162988285594328, 0.0051484191837092184, 0.0051339795510944768, 0.0051197159412470503, 0.0051056935405741624, 0.0050918646202513787, 0.0050783061389370653, 0.0050650155636441591, 0.0050520482144420379, 0.0050394115445405391, 0.0050270764435075268, 0.005014989683977282, 0.0050030918804464773, 0.0049913513451989326, 0.0049798238737963855, 0.0049685074073723542, 0.0049574088025849568, 0.0049465116820689896, 0.0049358204167646701, 0.0049253059950649988, 0.0049149598995180434, 0.0049048039283819712, 0.004894816178629113, 0.0048836781060325636, 0.0048693367584714924, 0.0048552182766197242, 0.0048415156046338528, 0.0048281356028831122, 0.0048150669823249668, 0.0048023231067867685, 0.0047899038762716567, 0.0047777176656769076, 0.0047656754064928667, 0.0047534471329146585, 0.004741271884879412, 0.0047294399907397058, 0.0047179611503624765, 0.0047068051182554849, 0.0046959753796479735, 0.0046854272729527314, 0.0046751314129820313, 0.0046650623131682407, 0.004655206802561632, 0.0046455349817865641]}
[2017-09-18 07:44:33,925 AE_UNIGRAMA_1L_OVER_F1_4.py:102]: done!
[2017-09-18 07:44:33,925 AE_UNIGRAMA_1L_OVER_F1_4.py:162]: >> Executing classifier part ... 
[2017-09-18 07:44:33,925 AE_UNIGRAMA_1L_OVER_F1_4.py:107]: =======================================
[2017-09-18 07:44:33,925 AE_UNIGRAMA_1L_OVER_F1_4.py:111]: setting configurations for classifier: 
	 {'classifier_dim': 9, 'loss_function': 'categorical_crossentropy', 'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x00000000019EE438>, 'use_last_dim_as_classifier': False}
[2017-09-18 07:44:34,152 AE_UNIGRAMA_1L_OVER_F1_4.py:120]: training ... 
[2017-09-18 07:44:35,719 summary.py:93]: Summary name enc0_134/kernel:0 is illegal; using enc0_134/kernel_0 instead.
[2017-09-18 07:44:35,719 summary.py:93]: Summary name enc0_134/bias:0 is illegal; using enc0_134/bias_0 instead.
[2017-09-18 07:44:35,735 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-09-18 07:44:35,735 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-09-18 07:48:54,163 AE_UNIGRAMA_1L_OVER_F1_4.py:132]: trained!
[2017-09-18 07:48:54,163 AE_UNIGRAMA_1L_OVER_F1_4.py:135]: Training history: 
{'val_loss': [0.010072303217456145, 0.0099614290496589774, 0.009862610315565172, 0.0097706394936808629, 0.0096810971722499674, 0.0095926792939624462, 0.0095032467368205698, 0.0094074676879837386, 0.0092828044577480152, 0.0089192982285240044, 0.0083528521942376581, 0.0078663927691522122, 0.0074723675740606885, 0.0071531629907935915, 0.0068939161931535244, 0.006682160480043076, 0.0065082426341055441, 0.0063646619961326969, 0.0062450924391958566, 0.0061450330401061921, 0.0060602160057211096, 0.005987651466701052, 0.0059251372423639072, 0.0058705051504356186, 0.0058218380816223341, 0.0057773404293144258, 0.0057366813430497583, 0.0056995565581002992, 0.0056656363191037208, 0.0056344482151655228, 0.0056055747363606837, 0.00557868628887934, 0.0055534496719191499, 0.0055295972629987285, 0.0055069576890095905, 0.0054853687662520375, 0.0054647177418875991, 0.0054448238157337615, 0.0054256071115202876, 0.0054069991008823858, 0.0053889046733578043, 0.0053712864587725558, 0.0053540652563733157, 0.0053372070389155956, 0.0053206410348683713, 0.0053042314367526943, 0.0052879229650460661, 0.0052717273306763512, 0.0052557457753127524, 0.0052399885240796435, 0.0052244093315573174, 0.0052089677457531685, 0.0051937837600595062, 0.0051788123741999918, 0.0051639845263358724, 0.0051491611502576555, 0.0051341981208448198, 0.0051193088210930238, 0.005104567802073732, 0.0050899495008476531, 0.0050754596909473194, 0.005061199532495589, 0.0050471238486892523, 0.0050333209466466387, 0.0050197904732284361, 0.005006527190643627, 0.0049935920420778766, 0.0049809730250729971, 0.0049686445047269767, 0.0049565417243431992, 0.0049445963891576296, 0.0049328645892788335, 0.0049213350304525283, 0.0049100333825780581, 0.0048989136585656338, 0.0048880003997149035, 0.0048772720735552983, 0.0048667306361722708, 0.0048563860288182142, 0.0048462293673055476, 0.0048361669559540341, 0.0048230928345335232, 0.0048090089864663314, 0.0047954105946551272, 0.0047822085405826208, 0.0047692584927381725, 0.0047566283250194026, 0.0047443369255020934, 0.0047322997590783641, 0.0047204925675504387, 0.0047086429116406838, 0.0046966433368410363, 0.0046849196829543182, 0.0046735437595802646, 0.0046624880525287281, 0.0046517428284776575, 0.0046412814321689167, 0.0046310634808772299, 0.0046210705546695756, 0.0046112791554063139, 0.0046016704438710141, 0.0045922373781988358], 'loss': [0.010146125355111033, 0.010027955936084382, 0.009922878003717054, 0.0098274478671002991, 0.0097366783079077708, 0.0096477331884906783, 0.0095592774423343407, 0.0094664977513399095, 0.009362270751501851, 0.0091521064067819347, 0.0086528221551089753, 0.0081245965361265923, 0.0076887184331963822, 0.007335926462614154, 0.0070498320526690686, 0.0068169100816739192, 0.0066262105245719783, 0.0064692854889517289, 0.0063393795707897384, 0.0062308800326162095, 0.0061396985740380392, 0.0060621129365564051, 0.0059955145254213561, 0.0059378061453741289, 0.005886965398064538, 0.0058411045918019145, 0.0057991025762476334, 0.0057607736759508728, 0.0057257988674325406, 0.0056937499863132278, 0.0056642175825730896, 0.0056367940478035099, 0.005611150146728262, 0.0055869909280476006, 0.0055640994551601521, 0.0055423383667884, 0.0055215552950953978, 0.0055016210271045338, 0.0054823901494904367, 0.0054637729426350009, 0.0054457060021270674, 0.0054281281310883424, 0.0054109682592151679, 0.0053941594945236893, 0.0053776851994110876, 0.0053614354909597602, 0.0053453384215572108, 0.0053293552254585564, 0.0053135467388217795, 0.0052979560695818129, 0.0052825611450964208, 0.0052672226497624767, 0.0052520430722741776, 0.0052370200797524956, 0.0052221985672725969, 0.0052074410830196521, 0.005192580821827773, 0.0051777103224892006, 0.005162988285594328, 0.0051484191837092184, 0.0051339795510944768, 0.0051197159412470503, 0.0051056935405741624, 0.0050918646202513787, 0.0050783061389370653, 0.0050650155636441591, 0.0050520482144420379, 0.0050394115445405391, 0.0050270764435075268, 0.005014989683977282, 0.0050030918804464773, 0.0049913513451989326, 0.0049798238737963855, 0.0049685074073723542, 0.0049574088025849568, 0.0049465116820689896, 0.0049358204167646701, 0.0049253059950649988, 0.0049149598995180434, 0.0049048039283819712, 0.004894816178629113, 0.0048836781060325636, 0.0048693367584714924, 0.0048552182766197242, 0.0048415156046338528, 0.0048281356028831122, 0.0048150669823249668, 0.0048023231067867685, 0.0047899038762716567, 0.0047777176656769076, 0.0047656754064928667, 0.0047534471329146585, 0.004741271884879412, 0.0047294399907397058, 0.0047179611503624765, 0.0047068051182554849, 0.0046959753796479735, 0.0046854272729527314, 0.0046751314129820313, 0.0046650623131682407, 0.004655206802561632, 0.0046455349817865641]}
[2017-09-18 07:48:54,163 AE_UNIGRAMA_1L_OVER_F1_4.py:139]: evaluating model ... 
[2017-09-18 07:48:54,255 AE_UNIGRAMA_1L_OVER_F1_4.py:143]: evaluated! 
[2017-09-18 07:48:54,255 AE_UNIGRAMA_1L_OVER_F1_4.py:145]: generating reports ... 
[2017-09-18 07:48:55,039 AE_UNIGRAMA_1L_OVER_F1_4.py:148]: done!
[2017-09-18 07:48:55,039 AE_UNIGRAMA_1L_OVER_F1_4.py:164]: >> experiment AE_UNIGRAMA_1L_OVER_F1_4 finished!

[2017-10-02 10:22:50,263 AE_UNIGRAMA_1L_UNDER_F0_8.py:146]: >> Initializing execution of experiment AE_UNIGRAMA_1L_UNDER_F0_8
[2017-10-02 10:22:50,263 AE_UNIGRAMA_1L_UNDER_F0_8.py:147]: >> Printing header log
[2017-10-02 10:22:50,263 AE_UNIGRAMA_1L_UNDER_F0_8.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_UNDER_F0_8
	layers = 96,76
	using GLOBAL obj = 
		{'epochs': 200, 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'mlp_configs': {'optimizer': <keras.optimizers.SGD object at 0x0000000001951240>, 'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy', 'activation': 'sigmoid', 'classifier_dim': 9}, 'shuffle_batches': True, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'autoencoder_configs': {'optimizer': <keras.optimizers.SGD object at 0x000000000194A3C8>, 'output_layer_activation': 'relu', 'hidden_layer_activation': 'relu', 'loss_function': 'mse', 'discard_decoder_function': True}, 'store_history': True, 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram_mini.pkl', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'executed_path': 'E:/research/research_msc/executed/onelayer/unigram/', 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'numpy_seed': 666, 'batch': 32}
	=======================================
	
[2017-10-02 10:22:50,264 AE_UNIGRAMA_1L_UNDER_F0_8.py:149]: >> Loading dataset... 
[2017-10-02 10:22:50,269 AE_UNIGRAMA_1L_UNDER_F0_8.py:54]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram_mini.pkl	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-02 10:22:50,269 AE_UNIGRAMA_1L_UNDER_F0_8.py:151]: >> Executing autoencoder part ... 
[2017-10-02 10:22:50,269 AE_UNIGRAMA_1L_UNDER_F0_8.py:59]: =======================================
[2017-10-02 10:22:50,269 AE_UNIGRAMA_1L_UNDER_F0_8.py:64]: setting configurations for autoencoder: 
	 {'optimizer': <keras.optimizers.SGD object at 0x000000000194A3C8>, 'output_layer_activation': 'relu', 'hidden_layer_activation': 'relu', 'loss_function': 'mse', 'discard_decoder_function': True}
[2017-10-02 10:22:50,325 AE_UNIGRAMA_1L_UNDER_F0_8.py:75]: training and evaluate autoencoder
[2017-10-02 10:22:50,682 summary.py:93]: Summary name enc0_76/kernel:0 is illegal; using enc0_76/kernel_0 instead.
[2017-10-02 10:22:50,684 summary.py:93]: Summary name enc0_76/bias:0 is illegal; using enc0_76/bias_0 instead.
[2017-10-02 10:22:50,687 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-10-02 10:22:50,689 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-10-02 10:23:02,012 AE_UNIGRAMA_1L_UNDER_F0_8.py:86]: trained and evaluated!
[2017-10-02 10:23:02,012 AE_UNIGRAMA_1L_UNDER_F0_8.py:89]: Training history: 
{'loss': [0.010089945886112388, 0.0099503923346046363, 0.0098145794565317156, 0.00968375633978448, 0.0095573624460909296, 0.0094356628291688959, 0.0093187262094050153, 0.0092062806669386821, 0.0090982649685985555, 0.008994501501953741, 0.0088948613020105455, 0.0087992641101714356, 0.0087073327310626027, 0.0086189549051101551, 0.0085339631619688622, 0.0084523683340593792, 0.0083738650735089883, 0.0082984024197431012, 0.0082257933881461215, 0.0081558626485140184, 0.0080884688195544067, 0.0080236488238856259, 0.0079611834772869931, 0.0079009946640042818, 0.0078428930327635125, 0.0077869091154326303, 0.0077328955183365482, 0.0076807843522382208, 0.007630427070328372, 0.0075817682855312046, 0.0075346906251573427, 0.0074891747386476963, 0.0074451527190202938, 0.0074025682387180904, 0.007361408198262624, 0.0073216008320084432, 0.0072831136166486149, 0.0072458135029936427, 0.0072097292612979362, 0.007174794494329546, 0.0071409461706689005, 0.0071081707861386676, 0.00707643787985062, 0.0070457061098404255, 0.0070159273469945407, 0.0069870139551180118, 0.0069589744838322136, 0.0069317842854304812, 0.0069054091562755684, 0.0068797696606194818, 0.0068548952639171622, 0.0068307465815844529, 0.0068072795941761721, 0.0067844564068235899, 0.006762262497305614, 0.0067406846281912658, 0.0067197066925227932, 0.0066992927920222099, 0.0066794277745234358, 0.006660115430572316, 0.0066413238416205504, 0.006623055607586476, 0.0066052730233576232, 0.0065879615818819496, 0.0065710955132291258, 0.0065546340922142147, 0.0065384187283980093, 0.0065222364039227284, 0.0065058677322182576, 0.0064898171893148678, 0.0064741986690371881, 0.0064589441753923893, 0.0064440540947619945, 0.0064295012925733759, 0.0064152760563398808, 0.0064014045973254004, 0.0063878792906483404, 0.0063746724107154465, 0.0063617709341797276, 0.0063491621622546691, 0.0063368501957361692, 0.0063248219998288937, 0.0063130570055840197, 0.0063015575318631032, 0.0062903139726490642, 0.0062793053090732633, 0.006268559679155454, 0.0062580280619562957, 0.0062476979435799893, 0.0062375788424638015, 0.0062276524641581418, 0.0062179244106226744, 0.0062083850950162946, 0.0061990089463236035, 0.0061898264185638241, 0.0061808044134370743, 0.0061719567187533434, 0.0061632883571862218, 0.0061547580660511435, 0.0061464045519042431, 0.0061381818593858059, 0.0061301136304657009], 'val_loss': [0.01003358643294267, 0.0098967895112571664, 0.0097644765338545398, 0.0096369023195928358, 0.0095138872859369429, 0.0093956779356228811, 0.0092818799245147007, 0.0091726256008208013, 0.0090676752822715992, 0.0089668593296718859, 0.0088700922275287506, 0.0087771935693116438, 0.008687874239949045, 0.0086020188991215822, 0.0085195555822529089, 0.0084402342084587498, 0.0083639937743793854, 0.0082906538648288494, 0.0082200418458385979, 0.0081520059672236227, 0.0080865554227649503, 0.0080235124804550386, 0.0079627854431041107, 0.0079041626546739654, 0.0078477107964760751, 0.0077932483488936189, 0.0077406961062306805, 0.0076899201951948683, 0.0076409174392491471, 0.0075935365209792187, 0.007547761874488074, 0.0075034467160674054, 0.0074605784140056395, 0.0074191367077090708, 0.007379055037042022, 0.0073403475397581502, 0.007302837565776695, 0.0072665517287654286, 0.0072314008000587222, 0.0071973229297973406, 0.0071643059830904894, 0.0071323549852716876, 0.0071014168405676859, 0.0070714274608291213, 0.0070423366100316152, 0.0070141137570668994, 0.006986752168022678, 0.0069602209707673593, 0.0069344562502598678, 0.006909473617405364, 0.0068852365965570662, 0.0068617032279977121, 0.006838803299006809, 0.0068165389872865828, 0.0067949044261972477, 0.006773866093319366, 0.0067533970668524172, 0.0067334868633586453, 0.006714124578747164, 0.0066952912784337335, 0.00667698099537576, 0.006659158960774153, 0.0066418095585305007, 0.0066249068016290226, 0.006608438939479315, 0.0065923181317441969, 0.0065763981919389454, 0.0065603667513560848, 0.0065444940077937228, 0.006529064179089987, 0.0065139979245245018, 0.0064993158110926361, 0.0064849851732609659, 0.006470955946382315, 0.0064572809475255946, 0.0064439325589949756, 0.0064308874631044365, 0.0064181491047088542, 0.0064057039502024874, 0.0063935331619417359, 0.0063816506284043251, 0.0063700268692492776, 0.0063586649225269992, 0.0063475547358393669, 0.0063366782868828032, 0.0063260619071585757, 0.0063156601297755669, 0.0063054760204815071, 0.0062955056081723327, 0.006285741007765651, 0.0062761718760414196, 0.0062667986994339184, 0.0062575956830775653, 0.0062485710876997299, 0.0062397148505157918, 0.0062310371450996754, 0.0062225221043459549, 0.0062141546314810735, 0.0062059568185843942, 0.0061978908051428519, 0.0061899700710986187, 0.0061821774025638083]}
[2017-10-02 10:23:02,012 AE_UNIGRAMA_1L_UNDER_F0_8.py:93]: done!
[2017-10-02 10:23:02,012 AE_UNIGRAMA_1L_UNDER_F0_8.py:153]: >> Executing classifier part ... 
[2017-10-02 10:23:02,012 AE_UNIGRAMA_1L_UNDER_F0_8.py:98]: =======================================
[2017-10-02 10:23:02,012 AE_UNIGRAMA_1L_UNDER_F0_8.py:102]: setting configurations for classifier: 
	 {'optimizer': <keras.optimizers.SGD object at 0x0000000001951240>, 'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy', 'activation': 'sigmoid', 'classifier_dim': 9}
[2017-10-02 10:23:02,067 AE_UNIGRAMA_1L_UNDER_F0_8.py:111]: training ... 
[2017-10-02 10:23:02,465 summary.py:93]: Summary name enc0_76/kernel:0 is illegal; using enc0_76/kernel_0 instead.
[2017-10-02 10:23:02,467 summary.py:93]: Summary name enc0_76/bias:0 is illegal; using enc0_76/bias_0 instead.
[2017-10-02 10:23:02,470 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-10-02 10:23:02,471 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-10-02 10:23:23,154 AE_UNIGRAMA_1L_UNDER_F0_8.py:123]: trained!
[2017-10-02 10:23:23,154 AE_UNIGRAMA_1L_UNDER_F0_8.py:126]: Training history: 
{'loss': [0.010089945886112388, 0.0099503923346046363, 0.0098145794565317156, 0.00968375633978448, 0.0095573624460909296, 0.0094356628291688959, 0.0093187262094050153, 0.0092062806669386821, 0.0090982649685985555, 0.008994501501953741, 0.0088948613020105455, 0.0087992641101714356, 0.0087073327310626027, 0.0086189549051101551, 0.0085339631619688622, 0.0084523683340593792, 0.0083738650735089883, 0.0082984024197431012, 0.0082257933881461215, 0.0081558626485140184, 0.0080884688195544067, 0.0080236488238856259, 0.0079611834772869931, 0.0079009946640042818, 0.0078428930327635125, 0.0077869091154326303, 0.0077328955183365482, 0.0076807843522382208, 0.007630427070328372, 0.0075817682855312046, 0.0075346906251573427, 0.0074891747386476963, 0.0074451527190202938, 0.0074025682387180904, 0.007361408198262624, 0.0073216008320084432, 0.0072831136166486149, 0.0072458135029936427, 0.0072097292612979362, 0.007174794494329546, 0.0071409461706689005, 0.0071081707861386676, 0.00707643787985062, 0.0070457061098404255, 0.0070159273469945407, 0.0069870139551180118, 0.0069589744838322136, 0.0069317842854304812, 0.0069054091562755684, 0.0068797696606194818, 0.0068548952639171622, 0.0068307465815844529, 0.0068072795941761721, 0.0067844564068235899, 0.006762262497305614, 0.0067406846281912658, 0.0067197066925227932, 0.0066992927920222099, 0.0066794277745234358, 0.006660115430572316, 0.0066413238416205504, 0.006623055607586476, 0.0066052730233576232, 0.0065879615818819496, 0.0065710955132291258, 0.0065546340922142147, 0.0065384187283980093, 0.0065222364039227284, 0.0065058677322182576, 0.0064898171893148678, 0.0064741986690371881, 0.0064589441753923893, 0.0064440540947619945, 0.0064295012925733759, 0.0064152760563398808, 0.0064014045973254004, 0.0063878792906483404, 0.0063746724107154465, 0.0063617709341797276, 0.0063491621622546691, 0.0063368501957361692, 0.0063248219998288937, 0.0063130570055840197, 0.0063015575318631032, 0.0062903139726490642, 0.0062793053090732633, 0.006268559679155454, 0.0062580280619562957, 0.0062476979435799893, 0.0062375788424638015, 0.0062276524641581418, 0.0062179244106226744, 0.0062083850950162946, 0.0061990089463236035, 0.0061898264185638241, 0.0061808044134370743, 0.0061719567187533434, 0.0061632883571862218, 0.0061547580660511435, 0.0061464045519042431, 0.0061381818593858059, 0.0061301136304657009], 'val_loss': [0.01003358643294267, 0.0098967895112571664, 0.0097644765338545398, 0.0096369023195928358, 0.0095138872859369429, 0.0093956779356228811, 0.0092818799245147007, 0.0091726256008208013, 0.0090676752822715992, 0.0089668593296718859, 0.0088700922275287506, 0.0087771935693116438, 0.008687874239949045, 0.0086020188991215822, 0.0085195555822529089, 0.0084402342084587498, 0.0083639937743793854, 0.0082906538648288494, 0.0082200418458385979, 0.0081520059672236227, 0.0080865554227649503, 0.0080235124804550386, 0.0079627854431041107, 0.0079041626546739654, 0.0078477107964760751, 0.0077932483488936189, 0.0077406961062306805, 0.0076899201951948683, 0.0076409174392491471, 0.0075935365209792187, 0.007547761874488074, 0.0075034467160674054, 0.0074605784140056395, 0.0074191367077090708, 0.007379055037042022, 0.0073403475397581502, 0.007302837565776695, 0.0072665517287654286, 0.0072314008000587222, 0.0071973229297973406, 0.0071643059830904894, 0.0071323549852716876, 0.0071014168405676859, 0.0070714274608291213, 0.0070423366100316152, 0.0070141137570668994, 0.006986752168022678, 0.0069602209707673593, 0.0069344562502598678, 0.006909473617405364, 0.0068852365965570662, 0.0068617032279977121, 0.006838803299006809, 0.0068165389872865828, 0.0067949044261972477, 0.006773866093319366, 0.0067533970668524172, 0.0067334868633586453, 0.006714124578747164, 0.0066952912784337335, 0.00667698099537576, 0.006659158960774153, 0.0066418095585305007, 0.0066249068016290226, 0.006608438939479315, 0.0065923181317441969, 0.0065763981919389454, 0.0065603667513560848, 0.0065444940077937228, 0.006529064179089987, 0.0065139979245245018, 0.0064993158110926361, 0.0064849851732609659, 0.006470955946382315, 0.0064572809475255946, 0.0064439325589949756, 0.0064308874631044365, 0.0064181491047088542, 0.0064057039502024874, 0.0063935331619417359, 0.0063816506284043251, 0.0063700268692492776, 0.0063586649225269992, 0.0063475547358393669, 0.0063366782868828032, 0.0063260619071585757, 0.0063156601297755669, 0.0063054760204815071, 0.0062955056081723327, 0.006285741007765651, 0.0062761718760414196, 0.0062667986994339184, 0.0062575956830775653, 0.0062485710876997299, 0.0062397148505157918, 0.0062310371450996754, 0.0062225221043459549, 0.0062141546314810735, 0.0062059568185843942, 0.0061978908051428519, 0.0061899700710986187, 0.0061821774025638083]}
[2017-10-02 10:23:23,154 AE_UNIGRAMA_1L_UNDER_F0_8.py:130]: evaluating model ... 
[2017-10-02 10:23:23,176 AE_UNIGRAMA_1L_UNDER_F0_8.py:134]: evaluated! 
[2017-10-02 10:23:23,176 AE_UNIGRAMA_1L_UNDER_F0_8.py:136]: generating reports ... 
[2017-10-02 10:23:23,647 AE_UNIGRAMA_1L_UNDER_F0_8.py:139]: done!
[2017-10-02 10:23:23,648 AE_UNIGRAMA_1L_UNDER_F0_8.py:155]: >> experiment AE_UNIGRAMA_1L_UNDER_F0_8 finished!

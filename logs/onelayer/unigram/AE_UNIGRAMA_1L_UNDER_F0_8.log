[2017-09-18 07:42:53,071 AE_UNIGRAMA_1L_UNDER_F0_8.py:155]: >> Initializing execution of experiment AE_UNIGRAMA_1L_UNDER_F0_8
[2017-09-18 07:42:53,071 AE_UNIGRAMA_1L_UNDER_F0_8.py:156]: >> Printing header log
[2017-09-18 07:42:53,071 AE_UNIGRAMA_1L_UNDER_F0_8.py:47]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_UNDER_F0_8
	layers = 96,76
	using GLOBAL obj = 
		{'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'numpy_seed': 666, 'store_history': True, 'executed_dir': 'E:/research/research_msc/executed/onelayer/unigram/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'autoencoder_configs': {'discard_decoder_function': True, 'loss_function': 'mse', 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x00000000017BC588>}, 'mlp_configs': {'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x00000000017BE400>, 'classifier_dim': 9, 'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy'}, 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram.pkl', 'batch': 32, 'shuffle_batches': True, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'epochs': 1000}
	=======================================
	
[2017-09-18 07:42:53,071 AE_UNIGRAMA_1L_UNDER_F0_8.py:158]: >> Loading dataset... 
[2017-09-18 07:42:53,096 AE_UNIGRAMA_1L_UNDER_F0_8.py:63]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram.pkl	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-09-18 07:42:53,096 AE_UNIGRAMA_1L_UNDER_F0_8.py:160]: >> Executing autoencoder part ... 
[2017-09-18 07:42:53,097 AE_UNIGRAMA_1L_UNDER_F0_8.py:68]: =======================================
[2017-09-18 07:42:53,097 AE_UNIGRAMA_1L_UNDER_F0_8.py:73]: setting configurations for autoencoder: 
	 {'discard_decoder_function': True, 'loss_function': 'mse', 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x00000000017BC588>}
[2017-09-18 07:42:53,198 AE_UNIGRAMA_1L_UNDER_F0_8.py:84]: training and evaluate autoencoder
[2017-09-18 07:42:53,777 summary.py:93]: Summary name enc0_76/kernel:0 is illegal; using enc0_76/kernel_0 instead.
[2017-09-18 07:42:53,780 summary.py:93]: Summary name enc0_76/bias:0 is illegal; using enc0_76/bias_0 instead.
[2017-09-18 07:42:53,785 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-09-18 07:42:53,789 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-09-18 07:44:30,255 AE_UNIGRAMA_1L_UNDER_F0_8.py:95]: trained and evaluated!
[2017-09-18 07:44:30,255 AE_UNIGRAMA_1L_UNDER_F0_8.py:98]: Training history: 
{'val_loss': [0.009122998405416324, 0.0086697656089677524, 0.0082818200308261373, 0.0079526452957565229, 0.0076713570902238364, 0.0074273680750238181, 0.007213253349042506, 0.0070224687210990967, 0.0068518662965900649, 0.0067028239051421549, 0.0065738224213582131, 0.0064618542801707889, 0.0063645228223641733, 0.006279414707917319, 0.0062044999873329286, 0.006138017707090525, 0.006078649211886453, 0.006024931385056915, 0.005975744878949898, 0.0059306235868964328, 0.0058891016238487815, 0.0058506931071653986, 0.0058148901500403392, 0.0057813540469507322, 0.0057497990596765639, 0.0057200396014018091, 0.0056918616839936112, 0.0056650135228023596, 0.0056391989560513724, 0.0056141523817346698, 0.0055890029469297534, 0.0055643540066220238, 0.0055405198530017099, 0.0055175227968235121, 0.0054951934088281647, 0.0054732209112760789, 0.0054513962255864079, 0.0054298135848494791, 0.0054089721955923042, 0.0053889712557341736, 0.0053698077366797908, 0.0053514194528810821, 0.0053337029386270694, 0.0053165114523404137, 0.0052996971212342543, 0.0052830972203054558, 0.0052667897787952757, 0.0052509705964078838, 0.0052357183194156904, 0.0052210089704552336, 0.0052067724348585651, 0.0051929765772906183, 0.0051795601930270073, 0.0051664957231682823, 0.0051537418712080431, 0.0051412612161448844, 0.0051290130982269934, 0.0051169899090435199, 0.0051051718616263939, 0.0050935386251798531, 0.0050820810540631624, 0.0050707704904692872, 0.0050595813631160525, 0.0050484342983599037, 0.0050372554945342929, 0.0050261503499044388, 0.0050151595224252263, 0.0050043226435772994, 0.0049936259779784775, 0.004983074430175035, 0.0049726552032522972, 0.004962368383976257, 0.0049521834293475529, 0.0049420970731912173, 0.0049320942397872505, 0.0049221456646511945, 0.0049122118086731064, 0.0049023035505032855, 0.0048924276952398002, 0.0048825883692731479, 0.0048727934815291449, 0.0048630236214963268, 0.0048532783062286604, 0.0048435471880683336, 0.0048338416245044128, 0.0048241564767053215, 0.0048144884113251792, 0.0048048516953804179, 0.0047952738592335429, 0.0047857745969257307, 0.0047763596470349664, 0.0047670130065831573, 0.0047577459107398523, 0.0047485589719583167, 0.0047394450432105819, 0.0047304097012226846, 0.0047214387125636493, 0.004712540244275293, 0.0047037032434479971, 0.0046949420446113785, 0.004686260049437398, 0.0046776463290901004], 'loss': [0.0093776493032517883, 0.0088983616003236472, 0.0084804833211746412, 0.0081249814022369467, 0.0078224762173341403, 0.0075623858127913564, 0.0073358443721363419, 0.0071360103403494387, 0.0069573993781588154, 0.0067990085885579841, 0.0066617235812384051, 0.0065425725190678382, 0.0064391277862384201, 0.0063489722880752369, 0.0062699026548879468, 0.0062000263817045924, 0.0061377784118606836, 0.0060818630872641593, 0.0060309441497829941, 0.0059842375664737081, 0.0059413025866701472, 0.0059016794373825555, 0.0058648761204540241, 0.0058304995950665796, 0.0057982166147524149, 0.00576776268344308, 0.005738974342366622, 0.0057115976123578915, 0.0056853928881359789, 0.0056601447802930027, 0.0056352718599845739, 0.0056104092266352516, 0.0055862174996868649, 0.0055628843755613656, 0.0055403627163846132, 0.0055183575706853885, 0.0054965607993527872, 0.0054748514411659807, 0.0054536343616074148, 0.0054332319943377677, 0.0054136805952636029, 0.0053949633145567001, 0.0053769674903069685, 0.0053595784274586633, 0.0053426798452956186, 0.0053261186171593301, 0.0053098235498005861, 0.0052939569305505531, 0.0052786418259655049, 0.00526386728811823, 0.0052495948661725068, 0.005235766064079792, 0.0052223351534672752, 0.0052092458127251454, 0.0051964765368984001, 0.0051839972379919986, 0.0051717738227922633, 0.0051597801984916642, 0.0051479928828894773, 0.0051363934309517764, 0.0051249729220669551, 0.0051137179188175163, 0.0051025815426524145, 0.0050915235551093584, 0.0050804584564434667, 0.0050694131146308448, 0.0050584773598319989, 0.005047671223655791, 0.0050370052703890026, 0.0050264786925119749, 0.0050160824825910173, 0.0050058138209947362, 0.0049956676561526683, 0.004985622950828765, 0.0049756672966100911, 0.0049657789718579653, 0.0049559198820839359, 0.0049460793468573969, 0.0049362727035076152, 0.0049264975181012903, 0.0049167610048160377, 0.0049070572425459619, 0.0048973806831943186, 0.0048877217654722726, 0.004878085068144326, 0.0048684718422143574, 0.0048588824809823938, 0.0048493250902813933, 0.0048398187884593812, 0.0048303784163193433, 0.004821001761127092, 0.0048117001775418514, 0.0048024669936381995, 0.0047933031727468529, 0.0047842093878389651, 0.0047751880455266021, 0.0047662466904142744, 0.0047573769627758788, 0.0047485780848707578, 0.0047398487414501223, 0.0047312028870915681, 0.0047226261939225609]}
[2017-09-18 07:44:30,255 AE_UNIGRAMA_1L_UNDER_F0_8.py:102]: done!
[2017-09-18 07:44:30,255 AE_UNIGRAMA_1L_UNDER_F0_8.py:162]: >> Executing classifier part ... 
[2017-09-18 07:44:30,255 AE_UNIGRAMA_1L_UNDER_F0_8.py:107]: =======================================
[2017-09-18 07:44:30,255 AE_UNIGRAMA_1L_UNDER_F0_8.py:111]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x00000000017BE400>, 'classifier_dim': 9, 'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy'}
[2017-09-18 07:44:30,514 AE_UNIGRAMA_1L_UNDER_F0_8.py:120]: training ... 
[2017-09-18 07:44:32,905 summary.py:93]: Summary name enc0_76/kernel:0 is illegal; using enc0_76/kernel_0 instead.
[2017-09-18 07:44:32,906 summary.py:93]: Summary name enc0_76/bias:0 is illegal; using enc0_76/bias_0 instead.
[2017-09-18 07:44:32,906 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-09-18 07:44:32,913 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-09-18 07:49:12,694 AE_UNIGRAMA_1L_UNDER_F0_8.py:132]: trained!
[2017-09-18 07:49:12,694 AE_UNIGRAMA_1L_UNDER_F0_8.py:135]: Training history: 
{'val_loss': [0.009122998405416324, 0.0086697656089677524, 0.0082818200308261373, 0.0079526452957565229, 0.0076713570902238364, 0.0074273680750238181, 0.007213253349042506, 0.0070224687210990967, 0.0068518662965900649, 0.0067028239051421549, 0.0065738224213582131, 0.0064618542801707889, 0.0063645228223641733, 0.006279414707917319, 0.0062044999873329286, 0.006138017707090525, 0.006078649211886453, 0.006024931385056915, 0.005975744878949898, 0.0059306235868964328, 0.0058891016238487815, 0.0058506931071653986, 0.0058148901500403392, 0.0057813540469507322, 0.0057497990596765639, 0.0057200396014018091, 0.0056918616839936112, 0.0056650135228023596, 0.0056391989560513724, 0.0056141523817346698, 0.0055890029469297534, 0.0055643540066220238, 0.0055405198530017099, 0.0055175227968235121, 0.0054951934088281647, 0.0054732209112760789, 0.0054513962255864079, 0.0054298135848494791, 0.0054089721955923042, 0.0053889712557341736, 0.0053698077366797908, 0.0053514194528810821, 0.0053337029386270694, 0.0053165114523404137, 0.0052996971212342543, 0.0052830972203054558, 0.0052667897787952757, 0.0052509705964078838, 0.0052357183194156904, 0.0052210089704552336, 0.0052067724348585651, 0.0051929765772906183, 0.0051795601930270073, 0.0051664957231682823, 0.0051537418712080431, 0.0051412612161448844, 0.0051290130982269934, 0.0051169899090435199, 0.0051051718616263939, 0.0050935386251798531, 0.0050820810540631624, 0.0050707704904692872, 0.0050595813631160525, 0.0050484342983599037, 0.0050372554945342929, 0.0050261503499044388, 0.0050151595224252263, 0.0050043226435772994, 0.0049936259779784775, 0.004983074430175035, 0.0049726552032522972, 0.004962368383976257, 0.0049521834293475529, 0.0049420970731912173, 0.0049320942397872505, 0.0049221456646511945, 0.0049122118086731064, 0.0049023035505032855, 0.0048924276952398002, 0.0048825883692731479, 0.0048727934815291449, 0.0048630236214963268, 0.0048532783062286604, 0.0048435471880683336, 0.0048338416245044128, 0.0048241564767053215, 0.0048144884113251792, 0.0048048516953804179, 0.0047952738592335429, 0.0047857745969257307, 0.0047763596470349664, 0.0047670130065831573, 0.0047577459107398523, 0.0047485589719583167, 0.0047394450432105819, 0.0047304097012226846, 0.0047214387125636493, 0.004712540244275293, 0.0047037032434479971, 0.0046949420446113785, 0.004686260049437398, 0.0046776463290901004], 'loss': [0.0093776493032517883, 0.0088983616003236472, 0.0084804833211746412, 0.0081249814022369467, 0.0078224762173341403, 0.0075623858127913564, 0.0073358443721363419, 0.0071360103403494387, 0.0069573993781588154, 0.0067990085885579841, 0.0066617235812384051, 0.0065425725190678382, 0.0064391277862384201, 0.0063489722880752369, 0.0062699026548879468, 0.0062000263817045924, 0.0061377784118606836, 0.0060818630872641593, 0.0060309441497829941, 0.0059842375664737081, 0.0059413025866701472, 0.0059016794373825555, 0.0058648761204540241, 0.0058304995950665796, 0.0057982166147524149, 0.00576776268344308, 0.005738974342366622, 0.0057115976123578915, 0.0056853928881359789, 0.0056601447802930027, 0.0056352718599845739, 0.0056104092266352516, 0.0055862174996868649, 0.0055628843755613656, 0.0055403627163846132, 0.0055183575706853885, 0.0054965607993527872, 0.0054748514411659807, 0.0054536343616074148, 0.0054332319943377677, 0.0054136805952636029, 0.0053949633145567001, 0.0053769674903069685, 0.0053595784274586633, 0.0053426798452956186, 0.0053261186171593301, 0.0053098235498005861, 0.0052939569305505531, 0.0052786418259655049, 0.00526386728811823, 0.0052495948661725068, 0.005235766064079792, 0.0052223351534672752, 0.0052092458127251454, 0.0051964765368984001, 0.0051839972379919986, 0.0051717738227922633, 0.0051597801984916642, 0.0051479928828894773, 0.0051363934309517764, 0.0051249729220669551, 0.0051137179188175163, 0.0051025815426524145, 0.0050915235551093584, 0.0050804584564434667, 0.0050694131146308448, 0.0050584773598319989, 0.005047671223655791, 0.0050370052703890026, 0.0050264786925119749, 0.0050160824825910173, 0.0050058138209947362, 0.0049956676561526683, 0.004985622950828765, 0.0049756672966100911, 0.0049657789718579653, 0.0049559198820839359, 0.0049460793468573969, 0.0049362727035076152, 0.0049264975181012903, 0.0049167610048160377, 0.0049070572425459619, 0.0048973806831943186, 0.0048877217654722726, 0.004878085068144326, 0.0048684718422143574, 0.0048588824809823938, 0.0048493250902813933, 0.0048398187884593812, 0.0048303784163193433, 0.004821001761127092, 0.0048117001775418514, 0.0048024669936381995, 0.0047933031727468529, 0.0047842093878389651, 0.0047751880455266021, 0.0047662466904142744, 0.0047573769627758788, 0.0047485780848707578, 0.0047398487414501223, 0.0047312028870915681, 0.0047226261939225609]}
[2017-09-18 07:49:12,694 AE_UNIGRAMA_1L_UNDER_F0_8.py:139]: evaluating model ... 
[2017-09-18 07:49:12,758 AE_UNIGRAMA_1L_UNDER_F0_8.py:143]: evaluated! 
[2017-09-18 07:49:12,758 AE_UNIGRAMA_1L_UNDER_F0_8.py:145]: generating reports ... 
[2017-09-18 07:49:13,447 AE_UNIGRAMA_1L_UNDER_F0_8.py:148]: done!
[2017-09-18 07:49:13,447 AE_UNIGRAMA_1L_UNDER_F0_8.py:164]: >> experiment AE_UNIGRAMA_1L_UNDER_F0_8 finished!

[2017-09-18 07:42:53,062 AE_UNIGRAMA_1L_OVER_F1_5.py:154]: >> Initializing execution of experiment AE_UNIGRAMA_1L_OVER_F1_5
[2017-09-18 07:42:53,062 AE_UNIGRAMA_1L_OVER_F1_5.py:155]: >> Printing header log
[2017-09-18 07:42:53,062 AE_UNIGRAMA_1L_OVER_F1_5.py:47]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_OVER_F1_5
	layers = 96,144
	using GLOBAL obj = 
		{'store_history': True, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'autoencoder_configs': {'loss_function': 'mse', 'hidden_layer_activation': 'relu', 'discard_decoder_function': True, 'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x000000000179B5C0>}, 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'mlp_configs': {'loss_function': 'categorical_crossentropy', 'use_last_dim_as_classifier': False, 'activation': 'sigmoid', 'classifier_dim': 9, 'optimizer': <keras.optimizers.SGD object at 0x000000000179E438>}, 'executed_dir': 'E:/research/research_msc/executed/onelayer/unigram/', 'shuffle_batches': True, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram.pkl', 'batch': 32, 'numpy_seed': 666}
	=======================================
	
[2017-09-18 07:42:53,062 AE_UNIGRAMA_1L_OVER_F1_5.py:157]: >> Loading dataset... 
[2017-09-18 07:42:53,088 AE_UNIGRAMA_1L_OVER_F1_5.py:63]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram.pkl	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-09-18 07:42:53,089 AE_UNIGRAMA_1L_OVER_F1_5.py:159]: >> Executing autoencoder part ... 
[2017-09-18 07:42:53,089 AE_UNIGRAMA_1L_OVER_F1_5.py:68]: =======================================
[2017-09-18 07:42:53,089 AE_UNIGRAMA_1L_OVER_F1_5.py:73]: setting configurations for autoencoder: 
	 {'loss_function': 'mse', 'hidden_layer_activation': 'relu', 'discard_decoder_function': True, 'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x000000000179B5C0>}
[2017-09-18 07:42:53,181 AE_UNIGRAMA_1L_OVER_F1_5.py:84]: training and evaluate autoencoder
[2017-09-18 07:42:53,782 summary.py:93]: Summary name enc0_144/kernel:0 is illegal; using enc0_144/kernel_0 instead.
[2017-09-18 07:42:53,787 summary.py:93]: Summary name enc0_144/bias:0 is illegal; using enc0_144/bias_0 instead.
[2017-09-18 07:42:53,794 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-09-18 07:42:53,797 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-09-18 07:44:04,656 AE_UNIGRAMA_1L_OVER_F1_5.py:95]: trained and evaluated!
[2017-09-18 07:44:04,656 AE_UNIGRAMA_1L_OVER_F1_5.py:98]: Training history: 
{'val_loss': [0.0088629672270937685, 0.0082597133197993833, 0.0077730982967586324, 0.0073831682767717659, 0.0070672417665362487, 0.006810822541072817, 0.0066015366760918716, 0.0064290964853419667, 0.0062849831223852027, 0.0061628424132277714, 0.0060584085794266355, 0.0059688673325592172, 0.0058915537830102659, 0.0058239773344536038, 0.0057640944254844393, 0.0057105561741448057, 0.0056621605459873138, 0.0056179522604122619, 0.0055766835092036044, 0.0055368344638515804, 0.0054962685857432286, 0.0054547388057126223, 0.0054127995828553372, 0.0053718849178540527, 0.0053344535560424832, 0.0053003723482412755, 0.005269241091175411, 0.0052406439842270858, 0.0052141573768518436, 0.0051893528581838898, 0.00516593025150842, 0.0051435684941494092, 0.0051218605082953067, 0.0051006123865792001, 0.0050800766976678915, 0.0050603224919768012, 0.0050413790560669396, 0.0050231703392441159, 0.0050056518695290857, 0.0049887856079052582, 0.0049725142995974423, 0.0049567801430078686, 0.0049415167687390273, 0.0049266566433685396, 0.004912158306227714, 0.0048979366913445375, 0.0048839619278566188, 0.0048702470605264704, 0.0048567793553747109, 0.0048435517206075456, 0.0048305654893750763, 0.0048178201096350766, 0.004805306455983655, 0.0047930090324761528, 0.0047809416034167518, 0.0047690898745783835, 0.0047574386807368741, 0.0047459835159646751, 0.0047347108270111814, 0.004723604633488262, 0.0047126543616673377, 0.0047018644954849725, 0.004691226767228546, 0.004680733775433518, 0.0046703720837352313, 0.0046601134224632914, 0.0046499038095634262, 0.0046396431965700039, 0.0046291956521871194, 0.0046183968865004931, 0.00460739180616636, 0.0045963713983710455, 0.0045853989573249659, 0.004574541614280698, 0.0045637843911085947, 0.004553144696412984, 0.0045425924907624314, 0.0045320980600552004, 0.004521645994941495, 0.004511253600060469, 0.0045009511956350876, 0.0044907667687045013, 0.0044806841974366057, 0.0044706932269293473, 0.004460845059430783, 0.0044511314656483459, 0.0044415640918632439, 0.0044321274520139299, 0.0044228028730571118, 0.0044136226514952638, 0.0044045840613444725, 0.0043957076317472235, 0.0043869814221538092, 0.0043784230985572286, 0.0043700290962783994, 0.0043617793341663227, 0.0043536653714470134, 0.0043456775787208083, 0.0043378298585270616, 0.004330111244936069, 0.0043225250043367192, 0.0043150681877119935], 'loss': [0.0092113290322281272, 0.0085635526156974551, 0.0080248358151545646, 0.0075926709259657079, 0.0072441390410661914, 0.006961358086793254, 0.006731316635420136, 0.0065428008910918311, 0.0063865681443963807, 0.006255242109689205, 0.0061434743919298812, 0.0060478499190310502, 0.0059657195756515728, 0.0058944568059592249, 0.0058318251240127425, 0.0057761087868240576, 0.0057260417030778775, 0.0056805215515671869, 0.0056385826268014446, 0.0055988241321204574, 0.0055591132328585494, 0.0055180233766623068, 0.0054763181891707979, 0.0054346354845401417, 0.0053954547230779352, 0.0053597567833336352, 0.0053270855443320079, 0.0052971560775509378, 0.0052695272491982605, 0.0052438140686176605, 0.0052196252722431684, 0.0051966847896340899, 0.0051746332381326235, 0.0051530651489028762, 0.0051320658372428184, 0.0051118209923210469, 0.0050923635455986296, 0.0050736989989891377, 0.0050557467223290133, 0.0050384720785233983, 0.0050218249280776176, 0.005005742108070501, 0.0049901641069666674, 0.0049750446041855502, 0.0049603218382481195, 0.0049459362083391443, 0.0049318085791895446, 0.0049179427743431788, 0.0049043419987294329, 0.0048909810106143696, 0.0048778578839081335, 0.0048649666192563555, 0.0048523093415994657, 0.0048398834507047267, 0.0048276725297969102, 0.0048156868175657066, 0.0048039059337135715, 0.0047923208776085458, 0.0047809315764892682, 0.0047697232542549218, 0.0047586850284806704, 0.0047478059557547409, 0.0047370940986991008, 0.0047265232114387214, 0.0047160968500780144, 0.0047057876816654779, 0.0046955586808417101, 0.0046853347466208018, 0.0046749849786827157, 0.0046643292897978637, 0.0046533922750214294, 0.0046423534869327382, 0.0046313510274548168, 0.0046204491604173951, 0.0046096632011155651, 0.0045989831730977619, 0.0045883844907111931, 0.0045778839965250904, 0.00456743173586321, 0.0045570116459832241, 0.0045466469616800773, 0.0045363713053334148, 0.0045261951190275112, 0.0045161242141260665, 0.0045061755037305359, 0.0044963622971115388, 0.0044866625000213435, 0.0044771107787622347, 0.0044676742113898514, 0.0044583794645433761, 0.0044492401722903202, 0.0044402615218070646, 0.0044314480655085527, 0.004422797329279836, 0.0044143057634181311, 0.0044059699504257043, 0.0043977725093678321, 0.0043896975912422588, 0.0043817621367003038, 0.0043739633058768566, 0.004366291290163039, 0.0043587437533646935]}
[2017-09-18 07:44:04,656 AE_UNIGRAMA_1L_OVER_F1_5.py:102]: done!
[2017-09-18 07:44:04,656 AE_UNIGRAMA_1L_OVER_F1_5.py:161]: >> Executing classifier part ... 
[2017-09-18 07:44:04,656 AE_UNIGRAMA_1L_OVER_F1_5.py:107]: =======================================
[2017-09-18 07:44:04,656 AE_UNIGRAMA_1L_OVER_F1_5.py:111]: setting configurations for classifier: 
	 {'loss_function': 'categorical_crossentropy', 'use_last_dim_as_classifier': False, 'activation': 'sigmoid', 'classifier_dim': 9, 'optimizer': <keras.optimizers.SGD object at 0x000000000179E438>}
[2017-09-18 07:44:04,749 AE_UNIGRAMA_1L_OVER_F1_5.py:120]: training ... 
[2017-09-18 07:44:05,534 summary.py:93]: Summary name enc0_144/kernel:0 is illegal; using enc0_144/kernel_0 instead.
[2017-09-18 07:44:05,534 summary.py:93]: Summary name enc0_144/bias:0 is illegal; using enc0_144/bias_0 instead.
[2017-09-18 07:44:05,550 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-09-18 07:44:05,550 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-09-18 07:47:32,061 AE_UNIGRAMA_1L_OVER_F1_5.py:132]: trained!
[2017-09-18 07:47:32,061 AE_UNIGRAMA_1L_OVER_F1_5.py:135]: Training history: 
{'val_loss': [0.0088629672270937685, 0.0082597133197993833, 0.0077730982967586324, 0.0073831682767717659, 0.0070672417665362487, 0.006810822541072817, 0.0066015366760918716, 0.0064290964853419667, 0.0062849831223852027, 0.0061628424132277714, 0.0060584085794266355, 0.0059688673325592172, 0.0058915537830102659, 0.0058239773344536038, 0.0057640944254844393, 0.0057105561741448057, 0.0056621605459873138, 0.0056179522604122619, 0.0055766835092036044, 0.0055368344638515804, 0.0054962685857432286, 0.0054547388057126223, 0.0054127995828553372, 0.0053718849178540527, 0.0053344535560424832, 0.0053003723482412755, 0.005269241091175411, 0.0052406439842270858, 0.0052141573768518436, 0.0051893528581838898, 0.00516593025150842, 0.0051435684941494092, 0.0051218605082953067, 0.0051006123865792001, 0.0050800766976678915, 0.0050603224919768012, 0.0050413790560669396, 0.0050231703392441159, 0.0050056518695290857, 0.0049887856079052582, 0.0049725142995974423, 0.0049567801430078686, 0.0049415167687390273, 0.0049266566433685396, 0.004912158306227714, 0.0048979366913445375, 0.0048839619278566188, 0.0048702470605264704, 0.0048567793553747109, 0.0048435517206075456, 0.0048305654893750763, 0.0048178201096350766, 0.004805306455983655, 0.0047930090324761528, 0.0047809416034167518, 0.0047690898745783835, 0.0047574386807368741, 0.0047459835159646751, 0.0047347108270111814, 0.004723604633488262, 0.0047126543616673377, 0.0047018644954849725, 0.004691226767228546, 0.004680733775433518, 0.0046703720837352313, 0.0046601134224632914, 0.0046499038095634262, 0.0046396431965700039, 0.0046291956521871194, 0.0046183968865004931, 0.00460739180616636, 0.0045963713983710455, 0.0045853989573249659, 0.004574541614280698, 0.0045637843911085947, 0.004553144696412984, 0.0045425924907624314, 0.0045320980600552004, 0.004521645994941495, 0.004511253600060469, 0.0045009511956350876, 0.0044907667687045013, 0.0044806841974366057, 0.0044706932269293473, 0.004460845059430783, 0.0044511314656483459, 0.0044415640918632439, 0.0044321274520139299, 0.0044228028730571118, 0.0044136226514952638, 0.0044045840613444725, 0.0043957076317472235, 0.0043869814221538092, 0.0043784230985572286, 0.0043700290962783994, 0.0043617793341663227, 0.0043536653714470134, 0.0043456775787208083, 0.0043378298585270616, 0.004330111244936069, 0.0043225250043367192, 0.0043150681877119935], 'loss': [0.0092113290322281272, 0.0085635526156974551, 0.0080248358151545646, 0.0075926709259657079, 0.0072441390410661914, 0.006961358086793254, 0.006731316635420136, 0.0065428008910918311, 0.0063865681443963807, 0.006255242109689205, 0.0061434743919298812, 0.0060478499190310502, 0.0059657195756515728, 0.0058944568059592249, 0.0058318251240127425, 0.0057761087868240576, 0.0057260417030778775, 0.0056805215515671869, 0.0056385826268014446, 0.0055988241321204574, 0.0055591132328585494, 0.0055180233766623068, 0.0054763181891707979, 0.0054346354845401417, 0.0053954547230779352, 0.0053597567833336352, 0.0053270855443320079, 0.0052971560775509378, 0.0052695272491982605, 0.0052438140686176605, 0.0052196252722431684, 0.0051966847896340899, 0.0051746332381326235, 0.0051530651489028762, 0.0051320658372428184, 0.0051118209923210469, 0.0050923635455986296, 0.0050736989989891377, 0.0050557467223290133, 0.0050384720785233983, 0.0050218249280776176, 0.005005742108070501, 0.0049901641069666674, 0.0049750446041855502, 0.0049603218382481195, 0.0049459362083391443, 0.0049318085791895446, 0.0049179427743431788, 0.0049043419987294329, 0.0048909810106143696, 0.0048778578839081335, 0.0048649666192563555, 0.0048523093415994657, 0.0048398834507047267, 0.0048276725297969102, 0.0048156868175657066, 0.0048039059337135715, 0.0047923208776085458, 0.0047809315764892682, 0.0047697232542549218, 0.0047586850284806704, 0.0047478059557547409, 0.0047370940986991008, 0.0047265232114387214, 0.0047160968500780144, 0.0047057876816654779, 0.0046955586808417101, 0.0046853347466208018, 0.0046749849786827157, 0.0046643292897978637, 0.0046533922750214294, 0.0046423534869327382, 0.0046313510274548168, 0.0046204491604173951, 0.0046096632011155651, 0.0045989831730977619, 0.0045883844907111931, 0.0045778839965250904, 0.00456743173586321, 0.0045570116459832241, 0.0045466469616800773, 0.0045363713053334148, 0.0045261951190275112, 0.0045161242141260665, 0.0045061755037305359, 0.0044963622971115388, 0.0044866625000213435, 0.0044771107787622347, 0.0044676742113898514, 0.0044583794645433761, 0.0044492401722903202, 0.0044402615218070646, 0.0044314480655085527, 0.004422797329279836, 0.0044143057634181311, 0.0044059699504257043, 0.0043977725093678321, 0.0043896975912422588, 0.0043817621367003038, 0.0043739633058768566, 0.004366291290163039, 0.0043587437533646935]}
[2017-09-18 07:47:32,061 AE_UNIGRAMA_1L_OVER_F1_5.py:139]: evaluating model ... 
[2017-09-18 07:47:32,154 AE_UNIGRAMA_1L_OVER_F1_5.py:143]: evaluated! 
[2017-09-18 07:47:32,154 AE_UNIGRAMA_1L_OVER_F1_5.py:145]: generating reports ... 
[2017-09-18 07:47:33,801 AE_UNIGRAMA_1L_OVER_F1_5.py:148]: done!
[2017-09-18 07:47:33,801 AE_UNIGRAMA_1L_OVER_F1_5.py:163]: >> experiment AE_UNIGRAMA_1L_OVER_F1_5 finished!

[2017-10-02 10:11:29,877 AE_UNIGRAMA_1L_OVER_F1_5.py:156]: >> Initializing execution of experiment AE_UNIGRAMA_1L_OVER_F1_5
[2017-10-02 10:11:29,877 AE_UNIGRAMA_1L_OVER_F1_5.py:157]: >> Printing header log
[2017-10-02 10:11:29,877 AE_UNIGRAMA_1L_OVER_F1_5.py:48]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_OVER_F1_5
	layers = 96,144
	using GLOBAL obj = 
		{'mlp_configs': {'activation': 'sigmoid', 'classifier_dim': 9, 'optimizer': <keras.optimizers.SGD object at 0x0000000001960390>, 'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy'}, 'batch': 32, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'store_history': True, 'autoencoder_configs': {'optimizer': <keras.optimizers.SGD object at 0x000000000195D518>, 'discard_decoder_function': True, 'loss_function': 'mse', 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu'}, 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram_mini.pkl', 'executed_path': 'E:/research/research_msc/executed/onelayer/unigram/', 'shuffle_batches': True, 'numpy_seed': 666, 'epochs': 200, 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9]}
	=======================================
	
[2017-10-02 10:11:29,878 AE_UNIGRAMA_1L_OVER_F1_5.py:159]: >> Loading dataset... 
[2017-10-02 10:11:29,887 AE_UNIGRAMA_1L_OVER_F1_5.py:64]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram_mini.pkl	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-02 10:11:29,887 AE_UNIGRAMA_1L_OVER_F1_5.py:161]: >> Executing autoencoder part ... 
[2017-10-02 10:11:29,888 AE_UNIGRAMA_1L_OVER_F1_5.py:69]: =======================================
[2017-10-02 10:11:29,888 AE_UNIGRAMA_1L_OVER_F1_5.py:74]: setting configurations for autoencoder: 
	 {'optimizer': <keras.optimizers.SGD object at 0x000000000195D518>, 'discard_decoder_function': True, 'loss_function': 'mse', 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu'}
[2017-10-02 10:11:30,005 AE_UNIGRAMA_1L_OVER_F1_5.py:85]: training and evaluate autoencoder
[2017-10-02 10:11:30,827 summary.py:93]: Summary name enc0_144/kernel:0 is illegal; using enc0_144/kernel_0 instead.
[2017-10-02 10:11:30,831 summary.py:93]: Summary name enc0_144/bias:0 is illegal; using enc0_144/bias_0 instead.
[2017-10-02 10:11:30,839 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-10-02 10:11:30,844 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-10-02 10:11:54,330 AE_UNIGRAMA_1L_OVER_F1_5.py:96]: trained and evaluated!
[2017-10-02 10:11:54,332 AE_UNIGRAMA_1L_OVER_F1_5.py:99]: Training history: 
{'val_loss': [0.009737972076636044, 0.0097032844064736459, 0.0096689138083708333, 0.0096349113977420731, 0.0096011080685656745, 0.0095674903010845632, 0.0095339926776777419, 0.0095002836094248248, 0.0094664727050298644, 0.0094323254166150186, 0.0093972312570393748, 0.0093604355122630916, 0.0093205492341108479, 0.0092758653533115271, 0.0092229818558271937, 0.0091597452330434183, 0.0090806439698961142, 0.0089894067392196353, 0.0088872851866217788, 0.0087661621434316321, 0.008644654155885419, 0.0085276819239318586, 0.0084153265470715034, 0.0083078848627364775, 0.0082049794256216311, 0.0081066082882587567, 0.0080123865149472062, 0.0079220733380284455, 0.0078356344855241618, 0.0077529338164234246, 0.0076736824285779078, 0.0075977275521947989, 0.0075249904489705557, 0.0074552006787554706, 0.0073883125478865714, 0.0073242112197895917, 0.0072627224038497003, 0.0072036708383145832, 0.007146970708213996, 0.0070926237428997089, 0.0070403579563650277, 0.006990119110322021, 0.0069418615491915366, 0.0068953899652818319, 0.0068506683226411671, 0.0068076611617683925, 0.0067661969462014925, 0.0067262567240454008, 0.0066878257153147212, 0.0066508391013431287, 0.0066151953541213251, 0.0065807727335166315, 0.0065476238332882689, 0.0065155919385056068, 0.0064847261824932459, 0.0064549432430402497, 0.0064261727083515944, 0.0063983459773449209, 0.006371424561124087, 0.0063453947789413115, 0.0063202366558315582, 0.00629589302451471, 0.0062723032191922008, 0.0062494213298157023, 0.0062272602287173047, 0.0062058051532224434, 0.0061850186928995923, 0.006164834306654988, 0.0061452675759653842, 0.0061262954254963581, 0.0061078983182468382, 0.0060900368478467694, 0.0060726944599508352, 0.0060558506706556419, 0.0060394762125434041, 0.0060235531412092726, 0.0060081030501807492, 0.0059930487435491111, 0.0059784083872978129, 0.0059641566470293086, 0.0059502697809422772, 0.0059367462847257193, 0.0059235679733542707, 0.0059106803488775698, 0.0058981507313766663, 0.0058858945245636443, 0.0058739311442637752, 0.0058622318648882069, 0.00585079168014533, 0.0058396084192572474, 0.0058286668521570226, 0.0058179596269357821, 0.0058074874083293418, 0.0057972396401944661, 0.0057871891618412, 0.0057773499171419216, 0.0057677145282215127, 0.0057582707113160523, 0.0057489978301868564, 0.0057399016251046637, 0.0057309673212773294, 0.0057221773395584865], 'loss': [0.0097785884498423348, 0.009743039791037791, 0.0097080394247868497, 0.0096733544695007338, 0.0096391067715944443, 0.0096050416209266173, 0.0095709954653468762, 0.0095369037734167154, 0.009502856584051745, 0.0094685295869189317, 0.0094336180838389336, 0.0093976015834104591, 0.0093592315569941287, 0.0093159449327400515, 0.0092646762569559161, 0.0092017153992369708, 0.0091253815747719645, 0.0090345311829775621, 0.0089354651139221392, 0.0088209345136536135, 0.0086959956612234178, 0.0085746275974276174, 0.008457852170310946, 0.0083459680533630766, 0.0082389792260274836, 0.0081365325956959701, 0.0080385217420211874, 0.0079446190727168273, 0.0078545911878704581, 0.0077683622035820132, 0.0076858048120052192, 0.0076066184163290475, 0.0075307819009463733, 0.0074581219883407815, 0.0073884292820510901, 0.0073216084199691379, 0.0072575223004787736, 0.0071960223544464573, 0.0071369411369995167, 0.0070801903711220898, 0.007025774281824577, 0.0069734345553139456, 0.0069231212733870976, 0.0068747474933323607, 0.0068281726381033388, 0.0067833560088462787, 0.0067402390189601662, 0.0066986421604549769, 0.0066586072589874673, 0.0066200803622452299, 0.0065829758472241507, 0.0065472299386486734, 0.006512729795369163, 0.0064794835697495464, 0.00644735960185656, 0.0064164233518754074, 0.0063865706939925685, 0.0063577336725706181, 0.0063298200188432472, 0.0063028403176607238, 0.0062767340570972167, 0.006251489565282437, 0.006227070048678101, 0.0062033789451036558, 0.0061803917754292672, 0.0061581502121901251, 0.0061366063581015998, 0.006115734741176446, 0.0060954779605756123, 0.0060758146196351909, 0.0060567621759310157, 0.0060382785822809216, 0.0060203440310507925, 0.006002920220669567, 0.0059859796173037123, 0.0059695269900460549, 0.0059535423457993458, 0.0059380133037547538, 0.0059228835317759005, 0.0059081737218812779, 0.0058938446775257365, 0.0058798840181866563, 0.0058662872867385118, 0.0058530274333264028, 0.0058400707591849382, 0.0058274585161227606, 0.0058151302299935649, 0.005803084140328648, 0.0057912959646234394, 0.0057797869893515593, 0.0057685168845820591, 0.0057574956673274724, 0.0057467085718032433, 0.0057361597380158388, 0.0057258266779882053, 0.0057156965375225934, 0.0057057808465298581, 0.0056960802638620486, 0.005686553930388632, 0.0056772068590521078, 0.0056680299401209991, 0.0056590256298369584]}
[2017-10-02 10:11:54,332 AE_UNIGRAMA_1L_OVER_F1_5.py:103]: done!
[2017-10-02 10:11:54,332 AE_UNIGRAMA_1L_OVER_F1_5.py:163]: >> Executing classifier part ... 
[2017-10-02 10:11:54,332 AE_UNIGRAMA_1L_OVER_F1_5.py:108]: =======================================
[2017-10-02 10:11:54,333 AE_UNIGRAMA_1L_OVER_F1_5.py:112]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'classifier_dim': 9, 'optimizer': <keras.optimizers.SGD object at 0x0000000001960390>, 'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy'}
[2017-10-02 10:11:54,470 AE_UNIGRAMA_1L_OVER_F1_5.py:121]: training ... 
[2017-10-02 10:11:55,218 summary.py:93]: Summary name enc0_144/kernel:0 is illegal; using enc0_144/kernel_0 instead.
[2017-10-02 10:11:55,222 summary.py:93]: Summary name enc0_144/bias:0 is illegal; using enc0_144/bias_0 instead.
[2017-10-02 10:11:55,229 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-10-02 10:11:55,233 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-10-02 10:12:40,052 AE_UNIGRAMA_1L_OVER_F1_5.py:133]: trained!
[2017-10-02 10:12:40,053 AE_UNIGRAMA_1L_OVER_F1_5.py:136]: Training history: 
{'val_loss': [0.009737972076636044, 0.0097032844064736459, 0.0096689138083708333, 0.0096349113977420731, 0.0096011080685656745, 0.0095674903010845632, 0.0095339926776777419, 0.0095002836094248248, 0.0094664727050298644, 0.0094323254166150186, 0.0093972312570393748, 0.0093604355122630916, 0.0093205492341108479, 0.0092758653533115271, 0.0092229818558271937, 0.0091597452330434183, 0.0090806439698961142, 0.0089894067392196353, 0.0088872851866217788, 0.0087661621434316321, 0.008644654155885419, 0.0085276819239318586, 0.0084153265470715034, 0.0083078848627364775, 0.0082049794256216311, 0.0081066082882587567, 0.0080123865149472062, 0.0079220733380284455, 0.0078356344855241618, 0.0077529338164234246, 0.0076736824285779078, 0.0075977275521947989, 0.0075249904489705557, 0.0074552006787554706, 0.0073883125478865714, 0.0073242112197895917, 0.0072627224038497003, 0.0072036708383145832, 0.007146970708213996, 0.0070926237428997089, 0.0070403579563650277, 0.006990119110322021, 0.0069418615491915366, 0.0068953899652818319, 0.0068506683226411671, 0.0068076611617683925, 0.0067661969462014925, 0.0067262567240454008, 0.0066878257153147212, 0.0066508391013431287, 0.0066151953541213251, 0.0065807727335166315, 0.0065476238332882689, 0.0065155919385056068, 0.0064847261824932459, 0.0064549432430402497, 0.0064261727083515944, 0.0063983459773449209, 0.006371424561124087, 0.0063453947789413115, 0.0063202366558315582, 0.00629589302451471, 0.0062723032191922008, 0.0062494213298157023, 0.0062272602287173047, 0.0062058051532224434, 0.0061850186928995923, 0.006164834306654988, 0.0061452675759653842, 0.0061262954254963581, 0.0061078983182468382, 0.0060900368478467694, 0.0060726944599508352, 0.0060558506706556419, 0.0060394762125434041, 0.0060235531412092726, 0.0060081030501807492, 0.0059930487435491111, 0.0059784083872978129, 0.0059641566470293086, 0.0059502697809422772, 0.0059367462847257193, 0.0059235679733542707, 0.0059106803488775698, 0.0058981507313766663, 0.0058858945245636443, 0.0058739311442637752, 0.0058622318648882069, 0.00585079168014533, 0.0058396084192572474, 0.0058286668521570226, 0.0058179596269357821, 0.0058074874083293418, 0.0057972396401944661, 0.0057871891618412, 0.0057773499171419216, 0.0057677145282215127, 0.0057582707113160523, 0.0057489978301868564, 0.0057399016251046637, 0.0057309673212773294, 0.0057221773395584865], 'loss': [0.0097785884498423348, 0.009743039791037791, 0.0097080394247868497, 0.0096733544695007338, 0.0096391067715944443, 0.0096050416209266173, 0.0095709954653468762, 0.0095369037734167154, 0.009502856584051745, 0.0094685295869189317, 0.0094336180838389336, 0.0093976015834104591, 0.0093592315569941287, 0.0093159449327400515, 0.0092646762569559161, 0.0092017153992369708, 0.0091253815747719645, 0.0090345311829775621, 0.0089354651139221392, 0.0088209345136536135, 0.0086959956612234178, 0.0085746275974276174, 0.008457852170310946, 0.0083459680533630766, 0.0082389792260274836, 0.0081365325956959701, 0.0080385217420211874, 0.0079446190727168273, 0.0078545911878704581, 0.0077683622035820132, 0.0076858048120052192, 0.0076066184163290475, 0.0075307819009463733, 0.0074581219883407815, 0.0073884292820510901, 0.0073216084199691379, 0.0072575223004787736, 0.0071960223544464573, 0.0071369411369995167, 0.0070801903711220898, 0.007025774281824577, 0.0069734345553139456, 0.0069231212733870976, 0.0068747474933323607, 0.0068281726381033388, 0.0067833560088462787, 0.0067402390189601662, 0.0066986421604549769, 0.0066586072589874673, 0.0066200803622452299, 0.0065829758472241507, 0.0065472299386486734, 0.006512729795369163, 0.0064794835697495464, 0.00644735960185656, 0.0064164233518754074, 0.0063865706939925685, 0.0063577336725706181, 0.0063298200188432472, 0.0063028403176607238, 0.0062767340570972167, 0.006251489565282437, 0.006227070048678101, 0.0062033789451036558, 0.0061803917754292672, 0.0061581502121901251, 0.0061366063581015998, 0.006115734741176446, 0.0060954779605756123, 0.0060758146196351909, 0.0060567621759310157, 0.0060382785822809216, 0.0060203440310507925, 0.006002920220669567, 0.0059859796173037123, 0.0059695269900460549, 0.0059535423457993458, 0.0059380133037547538, 0.0059228835317759005, 0.0059081737218812779, 0.0058938446775257365, 0.0058798840181866563, 0.0058662872867385118, 0.0058530274333264028, 0.0058400707591849382, 0.0058274585161227606, 0.0058151302299935649, 0.005803084140328648, 0.0057912959646234394, 0.0057797869893515593, 0.0057685168845820591, 0.0057574956673274724, 0.0057467085718032433, 0.0057361597380158388, 0.0057258266779882053, 0.0057156965375225934, 0.0057057808465298581, 0.0056960802638620486, 0.005686553930388632, 0.0056772068590521078, 0.0056680299401209991, 0.0056590256298369584]}
[2017-10-02 10:12:40,053 AE_UNIGRAMA_1L_OVER_F1_5.py:140]: evaluating model ... 
[2017-10-02 10:12:40,097 AE_UNIGRAMA_1L_OVER_F1_5.py:144]: evaluated! 
[2017-10-02 10:12:40,097 AE_UNIGRAMA_1L_OVER_F1_5.py:146]: generating reports ... 
[2017-10-02 10:12:40,982 AE_UNIGRAMA_1L_OVER_F1_5.py:149]: done!
[2017-10-02 10:12:40,982 AE_UNIGRAMA_1L_OVER_F1_5.py:165]: >> experiment AE_UNIGRAMA_1L_OVER_F1_5 finished!

[2017-09-18 07:42:52,988 AE_UNIGRAMA_1L_UNDER_F0_2.py:154]: >> Initializing execution of experiment AE_UNIGRAMA_1L_UNDER_F0_2
[2017-09-18 07:42:52,988 AE_UNIGRAMA_1L_UNDER_F0_2.py:155]: >> Printing header log
[2017-09-18 07:42:52,988 AE_UNIGRAMA_1L_UNDER_F0_2.py:47]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_UNDER_F0_2
	layers = 96,19
	using GLOBAL obj = 
		{'store_history': True, 'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'executed_dir': 'E:/research/research_msc/executed/onelayer/unigram/', 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'autoencoder_configs': {'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x00000000017BB5C0>, 'hidden_layer_activation': 'relu', 'discard_decoder_function': True, 'loss_function': 'mse'}, 'mlp_configs': {'loss_function': 'categorical_crossentropy', 'use_last_dim_as_classifier': False, 'classifier_dim': 9, 'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x00000000017BE438>}, 'epochs': 1000, 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'batch': 32, 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram.pkl', 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'shuffle_batches': True, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9]}
	=======================================
	
[2017-09-18 07:42:52,988 AE_UNIGRAMA_1L_UNDER_F0_2.py:157]: >> Loading dataset... 
[2017-09-18 07:42:53,013 AE_UNIGRAMA_1L_UNDER_F0_2.py:63]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram.pkl	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-09-18 07:42:53,013 AE_UNIGRAMA_1L_UNDER_F0_2.py:159]: >> Executing autoencoder part ... 
[2017-09-18 07:42:53,013 AE_UNIGRAMA_1L_UNDER_F0_2.py:68]: =======================================
[2017-09-18 07:42:53,013 AE_UNIGRAMA_1L_UNDER_F0_2.py:73]: setting configurations for autoencoder: 
	 {'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x00000000017BB5C0>, 'hidden_layer_activation': 'relu', 'discard_decoder_function': True, 'loss_function': 'mse'}
[2017-09-18 07:42:53,112 AE_UNIGRAMA_1L_UNDER_F0_2.py:84]: training and evaluate autoencoder
[2017-09-18 07:42:53,693 summary.py:93]: Summary name enc0_19/kernel:0 is illegal; using enc0_19/kernel_0 instead.
[2017-09-18 07:42:53,696 summary.py:93]: Summary name enc0_19/bias:0 is illegal; using enc0_19/bias_0 instead.
[2017-09-18 07:42:53,700 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-09-18 07:42:53,703 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-09-18 07:44:41,992 AE_UNIGRAMA_1L_UNDER_F0_2.py:95]: trained and evaluated!
[2017-09-18 07:44:41,992 AE_UNIGRAMA_1L_UNDER_F0_2.py:98]: Training history: 
{'val_loss': [0.0088663148926143177, 0.0085106383470386453, 0.0081950798966141138, 0.0079178384368987983, 0.0076742672976838865, 0.0074586214272470341, 0.0072672295644920417, 0.0070992638396344962, 0.0069517348198174268, 0.0068220144828445373, 0.0067075204387586464, 0.0066057855226729269, 0.00651495727237748, 0.0064337200737424475, 0.0063608699838963887, 0.0062953631466515407, 0.0062363905695604844, 0.0061828308849664285, 0.0061339483892792228, 0.0060889072317831311, 0.0060474584454986123, 0.00600914848240716, 0.005973829541342365, 0.0059413700966073424, 0.0059114303675167693, 0.0058836911619120288, 0.0058578131452595725, 0.005833657373284366, 0.005811033201328958, 0.0057898101478832875, 0.0057698068411275337, 0.0057509305261593015, 0.0057330940947113223, 0.0057162030393621234, 0.0057001769025349707, 0.0056849144482509382, 0.0056703437327823847, 0.0056563807912040822, 0.0056429354032246247, 0.0056299315629446877, 0.0056172887836088373, 0.0056049937878806218, 0.0055930531135007589, 0.0055814512201147791, 0.005570151634087861, 0.0055591590494261109, 0.0055484599677708239, 0.0055380299364280634, 0.005527874789940373, 0.005517993586203607, 0.0055083714194358964, 0.005498996745823762, 0.0054898373328268434, 0.0054808711749972146, 0.0054720853319653786, 0.0054634719117052062, 0.0054550101177596464, 0.0054466654633838259, 0.005438396417187066, 0.005430115507066781, 0.0054218468965824933, 0.0054136402026203536, 0.0054054905940942501, 0.0053973808955299872, 0.0053893154409489167, 0.0053812865916918863, 0.0053733035278407662, 0.0053653687696311129, 0.0053575067170469511, 0.0053497182982448366, 0.0053420182099639113, 0.005334420079599487, 0.00532692485370525, 0.0053195219164531441, 0.0053122160482729991, 0.0053050007450523365, 0.0052978787520706642, 0.005290860616359333, 0.0052839400303556563, 0.0052771045536642094, 0.0052703562921145161, 0.005263694967610439, 0.0052571128027014587, 0.0052506060449722079, 0.0052441692100245697, 0.0052377981528569971, 0.0052314894691449189, 0.0052252351765879231, 0.0052190293474598639, 0.005212866694682532, 0.0052067444720351706, 0.0052006565155382706, 0.0051946006218147375, 0.0051885788411604366, 0.0051825736598507012, 0.0051765791885794383, 0.0051705731977960204, 0.0051645020840847666, 0.005158365471630834, 0.0051522376312703464, 0.0051461600834412724, 0.005140127666935993], 'loss': [0.0090764660012821515, 0.0087021703771150323, 0.0083675859215926202, 0.0080728896178979149, 0.0078143935378060629, 0.0075865022442472216, 0.0073841591916632672, 0.0072058403170726457, 0.0070493040466115264, 0.0069117216449137171, 0.0067906203686370686, 0.0066834222182413838, 0.0065879860372302342, 0.0065027336752090416, 0.0064265043842827449, 0.0063580805262589803, 0.006296536595413944, 0.0062410272464107682, 0.0061905082272109852, 0.0061442398053950711, 0.0061015871640834815, 0.0060622181137057777, 0.0060258913141969881, 0.0059924848946192062, 0.0059617321682325485, 0.005933302419670077, 0.0059068711257111127, 0.0058821615335699915, 0.0058590478737744487, 0.005837362744206773, 0.0058169769945920127, 0.0057977459426478651, 0.0057795987150350515, 0.0057624342309602989, 0.0057461672600043669, 0.0057307064396170211, 0.005715946859059501, 0.0057018226817020711, 0.0056882409991156225, 0.0056751160159943933, 0.0056623917363256646, 0.0056499978570294764, 0.0056379635765603517, 0.0056262738853295191, 0.0056149087208059688, 0.005603843571498626, 0.0055930835714560756, 0.0055826293045982515, 0.005572442840878526, 0.0055625305263108599, 0.0055528785104584305, 0.0055434649217015533, 0.0055342754347969363, 0.0055252835440891927, 0.0055164777075571636, 0.0055078467438428426, 0.0054993770365117777, 0.0054910422631551867, 0.0054828067254940396, 0.0054746065606577233, 0.0054663952970558354, 0.0054582303205974389, 0.0054501270173099, 0.0054420573645234437, 0.0054340192066041201, 0.0054260336670956429, 0.0054180890530241737, 0.0054102072733331749, 0.0054023767639387304, 0.0053946206318032774, 0.0053869384996880158, 0.0053793316335149031, 0.0053718283300805752, 0.0053644341914955134, 0.0053571329827164236, 0.0053499182419284646, 0.0053427981017714152, 0.0053357714405314199, 0.0053288477566813394, 0.0053220198922864321, 0.005315280673979462, 0.0053086317191146223, 0.0053020621925648206, 0.0052955743523614785, 0.0052891588458116685, 0.0052828129083265681, 0.0052765271299701202, 0.0052702961523509711, 0.0052641225792170376, 0.0052579859453634687, 0.0052518940212236374, 0.0052458436715430217, 0.0052398322875438523, 0.0052338508082359634, 0.0052278936644886897, 0.0052219504855501846, 0.0052160103854518537, 0.0052100343835370126, 0.0052039847322625917, 0.0051978970939556201, 0.0051918287525563695, 0.0051858197876867365]}
[2017-09-18 07:44:41,992 AE_UNIGRAMA_1L_UNDER_F0_2.py:102]: done!
[2017-09-18 07:44:41,992 AE_UNIGRAMA_1L_UNDER_F0_2.py:161]: >> Executing classifier part ... 
[2017-09-18 07:44:41,992 AE_UNIGRAMA_1L_UNDER_F0_2.py:107]: =======================================
[2017-09-18 07:44:41,992 AE_UNIGRAMA_1L_UNDER_F0_2.py:111]: setting configurations for classifier: 
	 {'loss_function': 'categorical_crossentropy', 'use_last_dim_as_classifier': False, 'classifier_dim': 9, 'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x00000000017BE438>}
[2017-09-18 07:44:42,257 AE_UNIGRAMA_1L_UNDER_F0_2.py:120]: training ... 
[2017-09-18 07:44:44,715 summary.py:93]: Summary name enc0_19/kernel:0 is illegal; using enc0_19/kernel_0 instead.
[2017-09-18 07:44:44,731 summary.py:93]: Summary name enc0_19/bias:0 is illegal; using enc0_19/bias_0 instead.
[2017-09-18 07:44:44,746 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-09-18 07:44:44,746 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-09-18 07:50:05,853 AE_UNIGRAMA_1L_UNDER_F0_2.py:132]: trained!
[2017-09-18 07:50:05,853 AE_UNIGRAMA_1L_UNDER_F0_2.py:135]: Training history: 
{'val_loss': [0.0088663148926143177, 0.0085106383470386453, 0.0081950798966141138, 0.0079178384368987983, 0.0076742672976838865, 0.0074586214272470341, 0.0072672295644920417, 0.0070992638396344962, 0.0069517348198174268, 0.0068220144828445373, 0.0067075204387586464, 0.0066057855226729269, 0.00651495727237748, 0.0064337200737424475, 0.0063608699838963887, 0.0062953631466515407, 0.0062363905695604844, 0.0061828308849664285, 0.0061339483892792228, 0.0060889072317831311, 0.0060474584454986123, 0.00600914848240716, 0.005973829541342365, 0.0059413700966073424, 0.0059114303675167693, 0.0058836911619120288, 0.0058578131452595725, 0.005833657373284366, 0.005811033201328958, 0.0057898101478832875, 0.0057698068411275337, 0.0057509305261593015, 0.0057330940947113223, 0.0057162030393621234, 0.0057001769025349707, 0.0056849144482509382, 0.0056703437327823847, 0.0056563807912040822, 0.0056429354032246247, 0.0056299315629446877, 0.0056172887836088373, 0.0056049937878806218, 0.0055930531135007589, 0.0055814512201147791, 0.005570151634087861, 0.0055591590494261109, 0.0055484599677708239, 0.0055380299364280634, 0.005527874789940373, 0.005517993586203607, 0.0055083714194358964, 0.005498996745823762, 0.0054898373328268434, 0.0054808711749972146, 0.0054720853319653786, 0.0054634719117052062, 0.0054550101177596464, 0.0054466654633838259, 0.005438396417187066, 0.005430115507066781, 0.0054218468965824933, 0.0054136402026203536, 0.0054054905940942501, 0.0053973808955299872, 0.0053893154409489167, 0.0053812865916918863, 0.0053733035278407662, 0.0053653687696311129, 0.0053575067170469511, 0.0053497182982448366, 0.0053420182099639113, 0.005334420079599487, 0.00532692485370525, 0.0053195219164531441, 0.0053122160482729991, 0.0053050007450523365, 0.0052978787520706642, 0.005290860616359333, 0.0052839400303556563, 0.0052771045536642094, 0.0052703562921145161, 0.005263694967610439, 0.0052571128027014587, 0.0052506060449722079, 0.0052441692100245697, 0.0052377981528569971, 0.0052314894691449189, 0.0052252351765879231, 0.0052190293474598639, 0.005212866694682532, 0.0052067444720351706, 0.0052006565155382706, 0.0051946006218147375, 0.0051885788411604366, 0.0051825736598507012, 0.0051765791885794383, 0.0051705731977960204, 0.0051645020840847666, 0.005158365471630834, 0.0051522376312703464, 0.0051461600834412724, 0.005140127666935993], 'loss': [0.0090764660012821515, 0.0087021703771150323, 0.0083675859215926202, 0.0080728896178979149, 0.0078143935378060629, 0.0075865022442472216, 0.0073841591916632672, 0.0072058403170726457, 0.0070493040466115264, 0.0069117216449137171, 0.0067906203686370686, 0.0066834222182413838, 0.0065879860372302342, 0.0065027336752090416, 0.0064265043842827449, 0.0063580805262589803, 0.006296536595413944, 0.0062410272464107682, 0.0061905082272109852, 0.0061442398053950711, 0.0061015871640834815, 0.0060622181137057777, 0.0060258913141969881, 0.0059924848946192062, 0.0059617321682325485, 0.005933302419670077, 0.0059068711257111127, 0.0058821615335699915, 0.0058590478737744487, 0.005837362744206773, 0.0058169769945920127, 0.0057977459426478651, 0.0057795987150350515, 0.0057624342309602989, 0.0057461672600043669, 0.0057307064396170211, 0.005715946859059501, 0.0057018226817020711, 0.0056882409991156225, 0.0056751160159943933, 0.0056623917363256646, 0.0056499978570294764, 0.0056379635765603517, 0.0056262738853295191, 0.0056149087208059688, 0.005603843571498626, 0.0055930835714560756, 0.0055826293045982515, 0.005572442840878526, 0.0055625305263108599, 0.0055528785104584305, 0.0055434649217015533, 0.0055342754347969363, 0.0055252835440891927, 0.0055164777075571636, 0.0055078467438428426, 0.0054993770365117777, 0.0054910422631551867, 0.0054828067254940396, 0.0054746065606577233, 0.0054663952970558354, 0.0054582303205974389, 0.0054501270173099, 0.0054420573645234437, 0.0054340192066041201, 0.0054260336670956429, 0.0054180890530241737, 0.0054102072733331749, 0.0054023767639387304, 0.0053946206318032774, 0.0053869384996880158, 0.0053793316335149031, 0.0053718283300805752, 0.0053644341914955134, 0.0053571329827164236, 0.0053499182419284646, 0.0053427981017714152, 0.0053357714405314199, 0.0053288477566813394, 0.0053220198922864321, 0.005315280673979462, 0.0053086317191146223, 0.0053020621925648206, 0.0052955743523614785, 0.0052891588458116685, 0.0052828129083265681, 0.0052765271299701202, 0.0052702961523509711, 0.0052641225792170376, 0.0052579859453634687, 0.0052518940212236374, 0.0052458436715430217, 0.0052398322875438523, 0.0052338508082359634, 0.0052278936644886897, 0.0052219504855501846, 0.0052160103854518537, 0.0052100343835370126, 0.0052039847322625917, 0.0051978970939556201, 0.0051918287525563695, 0.0051858197876867365]}
[2017-09-18 07:50:05,853 AE_UNIGRAMA_1L_UNDER_F0_2.py:139]: evaluating model ... 
[2017-09-18 07:50:05,916 AE_UNIGRAMA_1L_UNDER_F0_2.py:143]: evaluated! 
[2017-09-18 07:50:05,916 AE_UNIGRAMA_1L_UNDER_F0_2.py:145]: generating reports ... 
[2017-09-18 07:50:06,589 AE_UNIGRAMA_1L_UNDER_F0_2.py:148]: done!
[2017-09-18 07:50:06,589 AE_UNIGRAMA_1L_UNDER_F0_2.py:163]: >> experiment AE_UNIGRAMA_1L_UNDER_F0_2 finished!

[2017-09-18 07:42:52,168 AE_UNIGRAMA_1L_OVER_F1_8.py:154]: >> Initializing execution of experiment AE_UNIGRAMA_1L_OVER_F1_8
[2017-09-18 07:42:52,168 AE_UNIGRAMA_1L_OVER_F1_8.py:155]: >> Printing header log
[2017-09-18 07:42:52,168 AE_UNIGRAMA_1L_OVER_F1_8.py:47]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_OVER_F1_8
	layers = 96,172
	using GLOBAL obj = 
		{'store_history': True, 'autoencoder_configs': {'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x00000000017DB5C0>, 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'discard_decoder_function': True}, 'shuffle_batches': True, 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram.pkl', 'executed_dir': 'E:/research/research_msc/executed/onelayer/unigram/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'numpy_seed': 666, 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'mlp_configs': {'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy', 'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x00000000017DE438>, 'classifier_dim': 9}, 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'epochs': 1000, 'batch': 32, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9]}
	=======================================
	
[2017-09-18 07:42:52,168 AE_UNIGRAMA_1L_OVER_F1_8.py:157]: >> Loading dataset... 
[2017-09-18 07:42:52,199 AE_UNIGRAMA_1L_OVER_F1_8.py:63]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram.pkl	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-09-18 07:42:52,199 AE_UNIGRAMA_1L_OVER_F1_8.py:159]: >> Executing autoencoder part ... 
[2017-09-18 07:42:52,199 AE_UNIGRAMA_1L_OVER_F1_8.py:68]: =======================================
[2017-09-18 07:42:52,199 AE_UNIGRAMA_1L_OVER_F1_8.py:73]: setting configurations for autoencoder: 
	 {'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x00000000017DB5C0>, 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'discard_decoder_function': True}
[2017-09-18 07:42:52,264 AE_UNIGRAMA_1L_OVER_F1_8.py:84]: training and evaluate autoencoder
[2017-09-18 07:42:52,696 summary.py:93]: Summary name enc0_172/kernel:0 is illegal; using enc0_172/kernel_0 instead.
[2017-09-18 07:42:52,696 summary.py:93]: Summary name enc0_172/bias:0 is illegal; using enc0_172/bias_0 instead.
[2017-09-18 07:42:52,696 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-09-18 07:42:52,696 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-09-18 07:44:35,610 AE_UNIGRAMA_1L_OVER_F1_8.py:95]: trained and evaluated!
[2017-09-18 07:44:35,610 AE_UNIGRAMA_1L_OVER_F1_8.py:98]: Training history: 
{'val_loss': [0.0092987583345024733, 0.0087126199603053366, 0.0082187959748070086, 0.0078117350198175159, 0.0074768530677912295, 0.007199833256516637, 0.0069679575460562153, 0.0067749009806510833, 0.0066134219878626653, 0.0064779736876189268, 0.0063636332946442392, 0.0062663103402474159, 0.0061827385606424241, 0.0061103967513864432, 0.0060471358878633162, 0.0059913822311294654, 0.0059417729073973184, 0.0058972868629077841, 0.0058570059475162774, 0.0058201575023353169, 0.0057861758013540319, 0.0057546089943094495, 0.0057250158018434267, 0.0056970879009068118, 0.0056705045379809174, 0.0056448191118031983, 0.0056193972157724459, 0.0055942645392119501, 0.0055696671870213658, 0.0055457055455745254, 0.0055223132634432065, 0.0054992156127041279, 0.0054762933809872896, 0.005453611084029697, 0.0054313938411685832, 0.0054097827305748256, 0.0053888906047736647, 0.0053687742104372559, 0.0053494066734671953, 0.005330741437917349, 0.0053126959638270998, 0.0052951841202017926, 0.0052780704091048743, 0.0052611504759104187, 0.005244451364227124, 0.0052281032553067909, 0.005212106934920753, 0.0051964386824096759, 0.0051811266708804192, 0.005166171342377489, 0.0051515496652354293, 0.0051372612288987721, 0.0051232710856675984, 0.0051095512970626214, 0.0050961017397802922, 0.0050829271148432982, 0.0050699909592272548, 0.0050572736366922008, 0.0050447759069112167, 0.0050324875467279923, 0.0050204005358499039, 0.005008504719232804, 0.004996788336062658, 0.0049852369932813084, 0.0049737808356203278, 0.0049622919629863605, 0.0049507165140616448, 0.0049392082205624794, 0.0049277989130305623, 0.004916507821856631, 0.0049053569507772473, 0.0048943352880410221, 0.0048834220389878322, 0.0048725710675111451, 0.0048616872221188337, 0.004850739906630994, 0.0048397790012266436, 0.0048288367757110288, 0.0048179296213272348, 0.0048070719490171396, 0.0047962914761522073, 0.0047856027654292407, 0.0047750639258919833, 0.0047647431776891378, 0.0047546497178450504, 0.0047447680542656231, 0.0047350741200404391, 0.0047255648658667358, 0.0047162404609125321, 0.0047070885203160601, 0.0046980902114496298, 0.0046892445823687682, 0.0046805350367237911, 0.0046719647352270527, 0.004663526233672775, 0.0046552140646908833, 0.0046470209258618446, 0.0046389399194174015, 0.0046309626793700383, 0.004623092188536149, 0.0046153161071055392, 0.0046076323250986333], 'loss': [0.0096004786499359496, 0.009017355540819668, 0.0084792341765121942, 0.0080319619821586884, 0.0076641977583591456, 0.0073609614855782105, 0.0071085566531112771, 0.0068975572163478957, 0.0067216230504812862, 0.006574326847102966, 0.0064504620086068363, 0.0063455064509626846, 0.0062558108804571643, 0.0061784379195220281, 0.0061111650213039517, 0.0060520989465870983, 0.0059998306489559977, 0.0059531228247596919, 0.0059110229135079075, 0.0058727221604268822, 0.0058375599580206827, 0.0058049942204223218, 0.0057746263078470028, 0.0057460545894063532, 0.0057189906539782519, 0.0056930741410562086, 0.0056676954326265695, 0.0056424872688281506, 0.005617695195309802, 0.0055934528527456489, 0.005569809478115118, 0.0055466112329786805, 0.0055236916632311608, 0.0055009377657328261, 0.0054784884042576058, 0.0054565877159818508, 0.0054353770530837855, 0.0054149343440112775, 0.0053952764745445478, 0.0053763415939818756, 0.0053580724669096145, 0.0053403615483190404, 0.0053231256227033574, 0.0053062066201468592, 0.005289457415117286, 0.0052730160269738105, 0.00525691625697014, 0.0052411624005701558, 0.005225747372343271, 0.005210697876395342, 0.0051960001517980248, 0.0051816295484535656, 0.0051675795473897293, 0.0051538138825830918, 0.0051403140712758507, 0.0051270830602745997, 0.0051141080936494493, 0.0051013632373189512, 0.005088831014666906, 0.005076508124110775, 0.005064382100080228, 0.0050524495343941883, 0.0050407003019632881, 0.0050291190220186415, 0.0050176656934726128, 0.0050062251690401573, 0.0049946979894261063, 0.0049831593978239656, 0.004971715577238924, 0.0049603838580785696, 0.0049491786290309031, 0.0049381124159673046, 0.004927167213508523, 0.0049163120012509507, 0.0049054843605770004, 0.0048946093663740625, 0.0048836984403469825, 0.0048728012457550322, 0.0048619554086246639, 0.0048511566635853634, 0.0048404039660286027, 0.00482973071696344, 0.0048191771307317475, 0.0048088074759930566, 0.0047986611789173584, 0.004788724259749225, 0.0047789812807052705, 0.0047694177548439354, 0.0047600348214835485, 0.0047508240425352217, 0.0047417730331920224, 0.0047328718972227879, 0.0047241231051415511, 0.0047155033856583683, 0.0047070214780244382, 0.0046986596753364205, 0.0046904252692773563, 0.0046823053178128814, 0.0046742938263326927, 0.0046663822030516668, 0.0046585748828119906, 0.0046508586308191277]}
[2017-09-18 07:44:35,610 AE_UNIGRAMA_1L_OVER_F1_8.py:102]: done!
[2017-09-18 07:44:35,610 AE_UNIGRAMA_1L_OVER_F1_8.py:161]: >> Executing classifier part ... 
[2017-09-18 07:44:35,610 AE_UNIGRAMA_1L_OVER_F1_8.py:107]: =======================================
[2017-09-18 07:44:35,610 AE_UNIGRAMA_1L_OVER_F1_8.py:111]: setting configurations for classifier: 
	 {'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy', 'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x00000000017DE438>, 'classifier_dim': 9}
[2017-09-18 07:44:35,782 AE_UNIGRAMA_1L_OVER_F1_8.py:120]: training ... 
[2017-09-18 07:44:37,069 summary.py:93]: Summary name enc0_172/kernel:0 is illegal; using enc0_172/kernel_0 instead.
[2017-09-18 07:44:37,069 summary.py:93]: Summary name enc0_172/bias:0 is illegal; using enc0_172/bias_0 instead.
[2017-09-18 07:44:37,085 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-09-18 07:44:37,100 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-09-18 07:49:48,162 AE_UNIGRAMA_1L_OVER_F1_8.py:132]: trained!
[2017-09-18 07:49:48,162 AE_UNIGRAMA_1L_OVER_F1_8.py:135]: Training history: 
{'val_loss': [0.0092987583345024733, 0.0087126199603053366, 0.0082187959748070086, 0.0078117350198175159, 0.0074768530677912295, 0.007199833256516637, 0.0069679575460562153, 0.0067749009806510833, 0.0066134219878626653, 0.0064779736876189268, 0.0063636332946442392, 0.0062663103402474159, 0.0061827385606424241, 0.0061103967513864432, 0.0060471358878633162, 0.0059913822311294654, 0.0059417729073973184, 0.0058972868629077841, 0.0058570059475162774, 0.0058201575023353169, 0.0057861758013540319, 0.0057546089943094495, 0.0057250158018434267, 0.0056970879009068118, 0.0056705045379809174, 0.0056448191118031983, 0.0056193972157724459, 0.0055942645392119501, 0.0055696671870213658, 0.0055457055455745254, 0.0055223132634432065, 0.0054992156127041279, 0.0054762933809872896, 0.005453611084029697, 0.0054313938411685832, 0.0054097827305748256, 0.0053888906047736647, 0.0053687742104372559, 0.0053494066734671953, 0.005330741437917349, 0.0053126959638270998, 0.0052951841202017926, 0.0052780704091048743, 0.0052611504759104187, 0.005244451364227124, 0.0052281032553067909, 0.005212106934920753, 0.0051964386824096759, 0.0051811266708804192, 0.005166171342377489, 0.0051515496652354293, 0.0051372612288987721, 0.0051232710856675984, 0.0051095512970626214, 0.0050961017397802922, 0.0050829271148432982, 0.0050699909592272548, 0.0050572736366922008, 0.0050447759069112167, 0.0050324875467279923, 0.0050204005358499039, 0.005008504719232804, 0.004996788336062658, 0.0049852369932813084, 0.0049737808356203278, 0.0049622919629863605, 0.0049507165140616448, 0.0049392082205624794, 0.0049277989130305623, 0.004916507821856631, 0.0049053569507772473, 0.0048943352880410221, 0.0048834220389878322, 0.0048725710675111451, 0.0048616872221188337, 0.004850739906630994, 0.0048397790012266436, 0.0048288367757110288, 0.0048179296213272348, 0.0048070719490171396, 0.0047962914761522073, 0.0047856027654292407, 0.0047750639258919833, 0.0047647431776891378, 0.0047546497178450504, 0.0047447680542656231, 0.0047350741200404391, 0.0047255648658667358, 0.0047162404609125321, 0.0047070885203160601, 0.0046980902114496298, 0.0046892445823687682, 0.0046805350367237911, 0.0046719647352270527, 0.004663526233672775, 0.0046552140646908833, 0.0046470209258618446, 0.0046389399194174015, 0.0046309626793700383, 0.004623092188536149, 0.0046153161071055392, 0.0046076323250986333], 'loss': [0.0096004786499359496, 0.009017355540819668, 0.0084792341765121942, 0.0080319619821586884, 0.0076641977583591456, 0.0073609614855782105, 0.0071085566531112771, 0.0068975572163478957, 0.0067216230504812862, 0.006574326847102966, 0.0064504620086068363, 0.0063455064509626846, 0.0062558108804571643, 0.0061784379195220281, 0.0061111650213039517, 0.0060520989465870983, 0.0059998306489559977, 0.0059531228247596919, 0.0059110229135079075, 0.0058727221604268822, 0.0058375599580206827, 0.0058049942204223218, 0.0057746263078470028, 0.0057460545894063532, 0.0057189906539782519, 0.0056930741410562086, 0.0056676954326265695, 0.0056424872688281506, 0.005617695195309802, 0.0055934528527456489, 0.005569809478115118, 0.0055466112329786805, 0.0055236916632311608, 0.0055009377657328261, 0.0054784884042576058, 0.0054565877159818508, 0.0054353770530837855, 0.0054149343440112775, 0.0053952764745445478, 0.0053763415939818756, 0.0053580724669096145, 0.0053403615483190404, 0.0053231256227033574, 0.0053062066201468592, 0.005289457415117286, 0.0052730160269738105, 0.00525691625697014, 0.0052411624005701558, 0.005225747372343271, 0.005210697876395342, 0.0051960001517980248, 0.0051816295484535656, 0.0051675795473897293, 0.0051538138825830918, 0.0051403140712758507, 0.0051270830602745997, 0.0051141080936494493, 0.0051013632373189512, 0.005088831014666906, 0.005076508124110775, 0.005064382100080228, 0.0050524495343941883, 0.0050407003019632881, 0.0050291190220186415, 0.0050176656934726128, 0.0050062251690401573, 0.0049946979894261063, 0.0049831593978239656, 0.004971715577238924, 0.0049603838580785696, 0.0049491786290309031, 0.0049381124159673046, 0.004927167213508523, 0.0049163120012509507, 0.0049054843605770004, 0.0048946093663740625, 0.0048836984403469825, 0.0048728012457550322, 0.0048619554086246639, 0.0048511566635853634, 0.0048404039660286027, 0.00482973071696344, 0.0048191771307317475, 0.0048088074759930566, 0.0047986611789173584, 0.004788724259749225, 0.0047789812807052705, 0.0047694177548439354, 0.0047600348214835485, 0.0047508240425352217, 0.0047417730331920224, 0.0047328718972227879, 0.0047241231051415511, 0.0047155033856583683, 0.0047070214780244382, 0.0046986596753364205, 0.0046904252692773563, 0.0046823053178128814, 0.0046742938263326927, 0.0046663822030516668, 0.0046585748828119906, 0.0046508586308191277]}
[2017-09-18 07:49:48,162 AE_UNIGRAMA_1L_OVER_F1_8.py:139]: evaluating model ... 
[2017-09-18 07:49:48,240 AE_UNIGRAMA_1L_OVER_F1_8.py:143]: evaluated! 
[2017-09-18 07:49:48,240 AE_UNIGRAMA_1L_OVER_F1_8.py:145]: generating reports ... 
[2017-09-18 07:49:48,923 AE_UNIGRAMA_1L_OVER_F1_8.py:148]: done!
[2017-09-18 07:49:48,923 AE_UNIGRAMA_1L_OVER_F1_8.py:163]: >> experiment AE_UNIGRAMA_1L_OVER_F1_8 finished!

[2017-10-02 10:12:45,422 AE_UNIGRAMA_1L_OVER_F1_6.py:158]: >> Initializing execution of experiment AE_UNIGRAMA_1L_OVER_F1_6
[2017-10-02 10:12:45,423 AE_UNIGRAMA_1L_OVER_F1_6.py:159]: >> Printing header log
[2017-10-02 10:12:45,423 AE_UNIGRAMA_1L_OVER_F1_6.py:49]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_OVER_F1_6
	layers = 96,153
	using GLOBAL obj = 
		{'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'epochs': 200, 'autoencoder_configs': {'discard_decoder_function': True, 'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x000000000195D518>, 'loss_function': 'mse', 'hidden_layer_activation': 'relu'}, 'store_history': True, 'mlp_configs': {'activation': 'sigmoid', 'use_last_dim_as_classifier': False, 'optimizer': <keras.optimizers.SGD object at 0x0000000001960390>, 'loss_function': 'categorical_crossentropy', 'classifier_dim': 9}, 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram_mini.pkl', 'shuffle_batches': True, 'numpy_seed': 666, 'executed_path': 'E:/research/research_msc/executed/onelayer/unigram/', 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'batch': 32, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9]}
	=======================================
	
[2017-10-02 10:12:45,423 AE_UNIGRAMA_1L_OVER_F1_6.py:161]: >> Loading dataset... 
[2017-10-02 10:12:45,428 AE_UNIGRAMA_1L_OVER_F1_6.py:65]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram_mini.pkl	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-02 10:12:45,428 AE_UNIGRAMA_1L_OVER_F1_6.py:163]: >> Executing autoencoder part ... 
[2017-10-02 10:12:45,428 AE_UNIGRAMA_1L_OVER_F1_6.py:70]: =======================================
[2017-10-02 10:12:45,428 AE_UNIGRAMA_1L_OVER_F1_6.py:75]: setting configurations for autoencoder: 
	 {'discard_decoder_function': True, 'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x000000000195D518>, 'loss_function': 'mse', 'hidden_layer_activation': 'relu'}
[2017-10-02 10:12:45,485 AE_UNIGRAMA_1L_OVER_F1_6.py:86]: training and evaluate autoencoder
[2017-10-02 10:12:45,843 summary.py:93]: Summary name enc0_153/kernel:0 is illegal; using enc0_153/kernel_0 instead.
[2017-10-02 10:12:45,845 summary.py:93]: Summary name enc0_153/bias:0 is illegal; using enc0_153/bias_0 instead.
[2017-10-02 10:12:45,848 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-10-02 10:12:45,850 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-10-02 10:12:56,928 AE_UNIGRAMA_1L_OVER_F1_6.py:97]: trained and evaluated!
[2017-10-02 10:12:56,928 AE_UNIGRAMA_1L_OVER_F1_6.py:100]: Training history: 
{'val_loss': [0.0095851184059363766, 0.0094542926225852798, 0.0093254443936631581, 0.0092012376410256537, 0.0090815612395401344, 0.0089663939765173267, 0.0088553893895729763, 0.0087486648876704699, 0.0086462779531470014, 0.0085480226009917969, 0.0084538796404203514, 0.0083637615651944754, 0.0082773457291677975, 0.0081944712939703325, 0.0081149723820499106, 0.0080387166780887045, 0.0079655909017559319, 0.0078952466310815515, 0.0078277763664777837, 0.0077628918843807787, 0.0077005474634302372, 0.0076406625338369585, 0.0075829930077254996, 0.0075275721582393667, 0.0074742087976640038, 0.007422828524058415, 0.0073733906327404057, 0.0073257742629673842, 0.00727990065912498, 0.0072356425658505422, 0.0071929343249025621, 0.0071517319754320005, 0.0071119374412087705, 0.0070735085097775137, 0.0070364395793541213, 0.0070006126004745527, 0.0069659541146379639, 0.0069325148650760098, 0.0069002010028629277, 0.0068689633825565356, 0.0068387638060826133, 0.0068095262892904334, 0.0067812461686427928, 0.0067538675059283975, 0.0067273521601987595, 0.006701654079456755, 0.0066767457239052842, 0.0066525752372264199, 0.0066291255249769938, 0.0066063489650677347, 0.0065842253955766617, 0.0065627259333863796, 0.0065418035484379553, 0.0065214246507997184, 0.0065016007712145503, 0.0064822898512934667, 0.0064634769483292859, 0.006445178987119056, 0.0064273303752024153, 0.0064099177451575774, 0.0063929256401457531, 0.0063763497913166267, 0.006360185323940888, 0.0063443961155126528, 0.006328984565312756, 0.0063139445176105735, 0.0062992335504897246, 0.006284850557788265, 0.0062707760509754422, 0.0062570164766037996, 0.0062435514269375885, 0.0062303646505709916, 0.0062174436854385536, 0.0062047995014123097, 0.0061924229635680478, 0.0061802749511643855, 0.0061683585489909669, 0.0061566670819923116, 0.0061451738118626816, 0.0061338800542250441, 0.0061227850179745363, 0.0061118871209014302, 0.0061011823728597519, 0.0060906301522592847, 0.0060802013544040317, 0.0060699007605448307, 0.0060597158653391556, 0.0060496363809616153, 0.0060396617084575409, 0.0060297943925187265, 0.0060200239912534068, 0.0060103734207363818, 0.0060008278075037837, 0.0059913731142047615, 0.0059820134227326809, 0.0059727494341760981, 0.0059635687816791154, 0.0059544716227702714, 0.0059454694327977951, 0.0059365747032555502, 0.0059277895737619426, 0.0059191052209876726], 'loss': [0.0096605915951725151, 0.0095268569236418629, 0.0093955278422937633, 0.0092678126502958418, 0.0091446097871516474, 0.0090257035683984771, 0.0089110421988776514, 0.0088004375250979143, 0.0086941521588458776, 0.0085920470308217083, 0.0084941459415548044, 0.0084003611114597358, 0.0083104837617133387, 0.008224209663518273, 0.0081414615125215053, 0.0080621102418391051, 0.0079860039405666682, 0.007912947004059926, 0.007842749586762756, 0.0077753791204334842, 0.0077105687093161407, 0.0076482618166352429, 0.0075883425711513889, 0.007530627850633167, 0.007475165488540705, 0.0074217476708598124, 0.0073703226121629058, 0.0073208042392398434, 0.0072730960291206431, 0.0072270863951076816, 0.0071827182240014843, 0.007139910253757392, 0.007098621298967143, 0.0070587277865196453, 0.0070202020932843001, 0.0069830043166395012, 0.0069470610741477808, 0.0069122733015935705, 0.0068787117674717815, 0.0068462555191966751, 0.0068148856386702596, 0.0067845312758281909, 0.006755147724897219, 0.0067267446843397782, 0.0066992374235499688, 0.0066726090264585059, 0.0066467822536816976, 0.0066217667281229251, 0.0065975212692394713, 0.0065739939837031339, 0.0065511410704458426, 0.0065289639381860103, 0.0065074177389047453, 0.006486447833961571, 0.0064660276944011209, 0.0064461502205344634, 0.0064268278323809979, 0.006408024199487849, 0.006389733666374354, 0.0063719163498810885, 0.0063545210936668279, 0.0063375581268246325, 0.0063210207288918793, 0.0063049045057089219, 0.006289151488885183, 0.0062737813778679539, 0.0062587952301977742, 0.0062441542205419658, 0.0062298414305415745, 0.0062158307702851277, 0.0062021513603462827, 0.0061887663095896422, 0.0061756730221037897, 0.0061628413907542472, 0.0061502874417879612, 0.0061380048414100405, 0.0061259367491777461, 0.0061141212763334606, 0.0061025146487127179, 0.0060911154896524621, 0.0060799189264523741, 0.0060688916836494893, 0.0060580613852330304, 0.0060474019802158859, 0.006036868677534662, 0.0060264754481728121, 0.0060162137173226113, 0.0060060501147860684, 0.0059960009286909397, 0.0059860578114790787, 0.005976229281002712, 0.0059665112685212971, 0.0059569228006058593, 0.0059474285568334459, 0.0059380111557596951, 0.0059287077612767353, 0.0059195230895288161, 0.0059104484211729034, 0.0059014478688069333, 0.0058925545573481845, 0.0058837653370717221, 0.0058750877129377654]}
[2017-10-02 10:12:56,929 AE_UNIGRAMA_1L_OVER_F1_6.py:104]: done!
[2017-10-02 10:12:56,929 AE_UNIGRAMA_1L_OVER_F1_6.py:165]: >> Executing classifier part ... 
[2017-10-02 10:12:56,929 AE_UNIGRAMA_1L_OVER_F1_6.py:109]: =======================================
[2017-10-02 10:12:56,929 AE_UNIGRAMA_1L_OVER_F1_6.py:113]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'use_last_dim_as_classifier': False, 'optimizer': <keras.optimizers.SGD object at 0x0000000001960390>, 'loss_function': 'categorical_crossentropy', 'classifier_dim': 9}
[2017-10-02 10:12:56,984 AE_UNIGRAMA_1L_OVER_F1_6.py:122]: training ... 
[2017-10-02 10:12:57,392 summary.py:93]: Summary name enc0_153/kernel:0 is illegal; using enc0_153/kernel_0 instead.
[2017-10-02 10:12:57,394 summary.py:93]: Summary name enc0_153/bias:0 is illegal; using enc0_153/bias_0 instead.
[2017-10-02 10:12:57,397 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-10-02 10:12:57,398 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-10-02 10:13:19,456 AE_UNIGRAMA_1L_OVER_F1_6.py:134]: trained!
[2017-10-02 10:13:19,456 AE_UNIGRAMA_1L_OVER_F1_6.py:137]: Training history: 
{'val_loss': [0.0095851184059363766, 0.0094542926225852798, 0.0093254443936631581, 0.0092012376410256537, 0.0090815612395401344, 0.0089663939765173267, 0.0088553893895729763, 0.0087486648876704699, 0.0086462779531470014, 0.0085480226009917969, 0.0084538796404203514, 0.0083637615651944754, 0.0082773457291677975, 0.0081944712939703325, 0.0081149723820499106, 0.0080387166780887045, 0.0079655909017559319, 0.0078952466310815515, 0.0078277763664777837, 0.0077628918843807787, 0.0077005474634302372, 0.0076406625338369585, 0.0075829930077254996, 0.0075275721582393667, 0.0074742087976640038, 0.007422828524058415, 0.0073733906327404057, 0.0073257742629673842, 0.00727990065912498, 0.0072356425658505422, 0.0071929343249025621, 0.0071517319754320005, 0.0071119374412087705, 0.0070735085097775137, 0.0070364395793541213, 0.0070006126004745527, 0.0069659541146379639, 0.0069325148650760098, 0.0069002010028629277, 0.0068689633825565356, 0.0068387638060826133, 0.0068095262892904334, 0.0067812461686427928, 0.0067538675059283975, 0.0067273521601987595, 0.006701654079456755, 0.0066767457239052842, 0.0066525752372264199, 0.0066291255249769938, 0.0066063489650677347, 0.0065842253955766617, 0.0065627259333863796, 0.0065418035484379553, 0.0065214246507997184, 0.0065016007712145503, 0.0064822898512934667, 0.0064634769483292859, 0.006445178987119056, 0.0064273303752024153, 0.0064099177451575774, 0.0063929256401457531, 0.0063763497913166267, 0.006360185323940888, 0.0063443961155126528, 0.006328984565312756, 0.0063139445176105735, 0.0062992335504897246, 0.006284850557788265, 0.0062707760509754422, 0.0062570164766037996, 0.0062435514269375885, 0.0062303646505709916, 0.0062174436854385536, 0.0062047995014123097, 0.0061924229635680478, 0.0061802749511643855, 0.0061683585489909669, 0.0061566670819923116, 0.0061451738118626816, 0.0061338800542250441, 0.0061227850179745363, 0.0061118871209014302, 0.0061011823728597519, 0.0060906301522592847, 0.0060802013544040317, 0.0060699007605448307, 0.0060597158653391556, 0.0060496363809616153, 0.0060396617084575409, 0.0060297943925187265, 0.0060200239912534068, 0.0060103734207363818, 0.0060008278075037837, 0.0059913731142047615, 0.0059820134227326809, 0.0059727494341760981, 0.0059635687816791154, 0.0059544716227702714, 0.0059454694327977951, 0.0059365747032555502, 0.0059277895737619426, 0.0059191052209876726], 'loss': [0.0096605915951725151, 0.0095268569236418629, 0.0093955278422937633, 0.0092678126502958418, 0.0091446097871516474, 0.0090257035683984771, 0.0089110421988776514, 0.0088004375250979143, 0.0086941521588458776, 0.0085920470308217083, 0.0084941459415548044, 0.0084003611114597358, 0.0083104837617133387, 0.008224209663518273, 0.0081414615125215053, 0.0080621102418391051, 0.0079860039405666682, 0.007912947004059926, 0.007842749586762756, 0.0077753791204334842, 0.0077105687093161407, 0.0076482618166352429, 0.0075883425711513889, 0.007530627850633167, 0.007475165488540705, 0.0074217476708598124, 0.0073703226121629058, 0.0073208042392398434, 0.0072730960291206431, 0.0072270863951076816, 0.0071827182240014843, 0.007139910253757392, 0.007098621298967143, 0.0070587277865196453, 0.0070202020932843001, 0.0069830043166395012, 0.0069470610741477808, 0.0069122733015935705, 0.0068787117674717815, 0.0068462555191966751, 0.0068148856386702596, 0.0067845312758281909, 0.006755147724897219, 0.0067267446843397782, 0.0066992374235499688, 0.0066726090264585059, 0.0066467822536816976, 0.0066217667281229251, 0.0065975212692394713, 0.0065739939837031339, 0.0065511410704458426, 0.0065289639381860103, 0.0065074177389047453, 0.006486447833961571, 0.0064660276944011209, 0.0064461502205344634, 0.0064268278323809979, 0.006408024199487849, 0.006389733666374354, 0.0063719163498810885, 0.0063545210936668279, 0.0063375581268246325, 0.0063210207288918793, 0.0063049045057089219, 0.006289151488885183, 0.0062737813778679539, 0.0062587952301977742, 0.0062441542205419658, 0.0062298414305415745, 0.0062158307702851277, 0.0062021513603462827, 0.0061887663095896422, 0.0061756730221037897, 0.0061628413907542472, 0.0061502874417879612, 0.0061380048414100405, 0.0061259367491777461, 0.0061141212763334606, 0.0061025146487127179, 0.0060911154896524621, 0.0060799189264523741, 0.0060688916836494893, 0.0060580613852330304, 0.0060474019802158859, 0.006036868677534662, 0.0060264754481728121, 0.0060162137173226113, 0.0060060501147860684, 0.0059960009286909397, 0.0059860578114790787, 0.005976229281002712, 0.0059665112685212971, 0.0059569228006058593, 0.0059474285568334459, 0.0059380111557596951, 0.0059287077612767353, 0.0059195230895288161, 0.0059104484211729034, 0.0059014478688069333, 0.0058925545573481845, 0.0058837653370717221, 0.0058750877129377654]}
[2017-10-02 10:13:19,456 AE_UNIGRAMA_1L_OVER_F1_6.py:141]: evaluating model ... 
[2017-10-02 10:13:19,479 AE_UNIGRAMA_1L_OVER_F1_6.py:145]: evaluated! 
[2017-10-02 10:13:19,480 AE_UNIGRAMA_1L_OVER_F1_6.py:147]: generating reports ... 
[2017-10-02 10:13:19,949 AE_UNIGRAMA_1L_OVER_F1_6.py:150]: done!
[2017-10-02 10:13:19,949 AE_UNIGRAMA_1L_OVER_F1_6.py:167]: >> experiment AE_UNIGRAMA_1L_OVER_F1_6 finished!

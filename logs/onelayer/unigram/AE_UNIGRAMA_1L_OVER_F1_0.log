[2017-09-17 00:00:52,220 AE_UNIGRAMA_1L_OVER_F1_0.py:157]: >> Initializing execution of experiment AE_UNIGRAMA_1L_OVER_F1_0
[2017-09-17 00:00:52,220 AE_UNIGRAMA_1L_OVER_F1_0.py:158]: >> Printing header log
[2017-09-17 00:00:52,220 AE_UNIGRAMA_1L_OVER_F1_0.py:47]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_OVER_F1_0
	layers = 96,96
	using GLOBAL obj = 
		{'shuffle_batches': True, 'epochs': 1000, 'log_dir': 'C:/Users/dhieg/research/research_msc/logs/onelayer/unigram/', 'executed_dir': 'C:/Users/dhieg/research/research_msc/executed/onelayer/unigram/', 'reports_dir': 'C:/Users/dhieg/research/research_msc/reports/onelayer/unigram/', 'checkpoints_dir': 'C:/Users/dhieg/research/research_msc/checkpoints/onelayer/unigram/', 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x000001C5FD701400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}, 'data_dir': 'C:/Users/dhieg/research/malware_dataset/malware_selected_1gram.pkl', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'numpy_seed': 666, 'batch': 32, 'autoencoder_configs': {'loss_function': 'mse', 'hidden_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x000001C5FD6FC588>, 'discard_decoder_function': True, 'output_layer_activation': 'relu'}, 'tensorflow_dir': 'C:/Users/dhieg/research/research_msc/tensorflow/onelayer/unigram/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'store_history': True}
	=======================================
	
[2017-09-17 00:00:52,220 AE_UNIGRAMA_1L_OVER_F1_0.py:160]: >> Loading dataset... 
[2017-09-17 00:00:52,236 AE_UNIGRAMA_1L_OVER_F1_0.py:63]: 
	=======================================
	loading malware dataset on = C:/Users/dhieg/research/malware_dataset/malware_selected_1gram.pkl	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-09-17 00:00:52,236 AE_UNIGRAMA_1L_OVER_F1_0.py:162]: >> Executing autoencoder part ... 
[2017-09-17 00:00:52,236 AE_UNIGRAMA_1L_OVER_F1_0.py:69]: =======================================
[2017-09-17 00:00:52,236 AE_UNIGRAMA_1L_OVER_F1_0.py:74]: setting configurations for autoencoder: 
	 {'loss_function': 'mse', 'hidden_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x000001C5FD6FC588>, 'discard_decoder_function': True, 'output_layer_activation': 'relu'}
[2017-09-17 00:00:52,267 AE_UNIGRAMA_1L_OVER_F1_0.py:85]: training and evaluate autoencoder
[2017-09-17 00:00:53,908 summary.py:89]: Summary name enc0_96/kernel:0 is illegal; using enc0_96/kernel_0 instead.
[2017-09-17 00:00:53,908 summary.py:89]: Summary name enc0_96/bias:0 is illegal; using enc0_96/bias_0 instead.
[2017-09-17 00:00:53,908 summary.py:89]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-09-17 00:00:53,908 summary.py:89]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-09-17 00:03:03,737 AE_UNIGRAMA_1L_OVER_F1_0.py:96]: trained and evaluated!
[2017-09-17 00:03:03,737 AE_UNIGRAMA_1L_OVER_F1_0.py:99]: Training history: 
{'val_loss': [0.0097456785467908858, 0.0091725405287141314, 0.0087129062083397494, 0.0083405199114648092, 0.0080360376331866205, 0.0077855021780776391, 0.0075771903705765045, 0.0074026986683805454, 0.0072555139113884342, 0.0071302755766276798, 0.0070227761634819559, 0.0069294058523034401, 0.0068478229058956406, 0.0067758820192852101, 0.0067120824369934938, 0.0066549669936140513, 0.0066034891165160422, 0.0065565626919050508, 0.0065135357039612651, 0.0064738570813134789, 0.0064370766689727755, 0.0064025510697037213, 0.0063697484772664709, 0.006338018601235223, 0.0063066543233079456, 0.0062732401206228271, 0.0062357289466742688, 0.0061951144406752019, 0.0061526699480249827, 0.0061081445329089793, 0.0060650779275604905, 0.0060238487652623778, 0.0059849894069065367, 0.0059490466999688905, 0.0059158860764663718, 0.0058852322194252937, 0.0058568209484671351, 0.005830216716864762, 0.0058051370664779335, 0.0057813200970597564, 0.0057584994352083462, 0.0057366227981224052, 0.0057156115883888756, 0.0056955260647346502, 0.0056765081813762242, 0.0056585911958735441, 0.0056417233150028645, 0.0056257600130568755, 0.0056105504575356957, 0.0055960173314664541, 0.0055820819608099108, 0.0055686783879647598, 0.0055557806943281416, 0.0055433207957189734, 0.0055312026836383966, 0.0055193871705327699, 0.0055078148689717927, 0.0054964852069331023, 0.0054853933952161435, 0.0054745400135016199, 0.0054639347468939904, 0.0054535121388356207, 0.0054432098688376339, 0.0054328545546111226, 0.0054220929734158313, 0.0054109872784123278, 0.0053997639747978606, 0.0053885485588455522, 0.0053774643617859113, 0.0053664938574441209, 0.0053556562141740876, 0.0053448948576376911, 0.0053341543504393952, 0.0053234782918927612, 0.005312891675182267, 0.005302467676685991, 0.0052922666808730623, 0.0052822518585306597, 0.0052724116814614726, 0.0052628043271208957, 0.0052534276510882152, 0.0052443385346341185, 0.0052355541525054717, 0.005227060386445887, 0.0052188463663190836, 0.0052108687351829826, 0.0052031118851271416, 0.0051955543811857781, 0.0051881731622152438, 0.0051809555827562982, 0.0051738806489036336, 0.005166932364652951, 0.0051600974605400599, 0.0051533614636718192, 0.0051467244916187189, 0.0051401846033124988, 0.0051337197601690121, 0.0051273368469073903, 0.0051210239468941939, 0.005114781262305316, 0.0051086083211046495, 0.0051024818544535156], 'loss': [0.010098401704448505, 0.0094614251997681715, 0.0089508277274109455, 0.0085396844477816734, 0.0082049490757057, 0.0079306264793059279, 0.0077040333373304508, 0.0075149187265800537, 0.0073560305912337073, 0.007221533102797861, 0.0071066379642229045, 0.0070075290663412695, 0.0069212443868025934, 0.0068456859350601367, 0.0067788667340008546, 0.0067193144984974062, 0.0066657892486753382, 0.0066173052916750708, 0.006572984506966981, 0.0065321917457585397, 0.0064944159421291073, 0.0064591970605650199, 0.0064259071403875902, 0.0063941043266498177, 0.0063631067315864827, 0.0063312759131835157, 0.0062961688419986648, 0.0062572837778545089, 0.0062161877443729311, 0.0061727141042593079, 0.0061292308154060381, 0.0060875197507626695, 0.0060477843268063299, 0.0060108152922456418, 0.0059766674983450403, 0.00594514772927884, 0.0059159586227912654, 0.00588880062858435, 0.0058632854118369814, 0.0058390781486515981, 0.0058158739187930851, 0.0057935705661089623, 0.0057722150255646223, 0.0057517280008786073, 0.0057322529548230645, 0.005713870611356836, 0.0056965457874176379, 0.0056802048537081349, 0.0056647015496017533, 0.0056499048183386684, 0.0056357484103841324, 0.0056221846278930159, 0.0056091478831560328, 0.0055965792123199506, 0.0055843976028954034, 0.0055725295790526579, 0.0055609309737302747, 0.0055495609903240097, 0.0055384352946466712, 0.0055275457140483075, 0.0055169045190210609, 0.0055064651546962084, 0.0054961717316595717, 0.0054859358914963775, 0.0054754693589476305, 0.0054645800621928838, 0.005453493681028568, 0.0054423420449824685, 0.0054312714524622002, 0.0054203397428635855, 0.0054095425116378604, 0.0053988795033486307, 0.0053882850506092031, 0.0053777037014880909, 0.005367195844200783, 0.005356789154128727, 0.0053465724567769201, 0.0053365658269080556, 0.0053267222309602361, 0.0053170936774749166, 0.0053076890567702846, 0.0052985400633070931, 0.0052896928041830443, 0.0052811458402321184, 0.0052728922987349694, 0.0052648863485497948, 0.0052571075383038316, 0.0052495313826269371, 0.005242147245899902, 0.005234937732098449, 0.0052278778766448458, 0.0052209465483934459, 0.0052141285944618931, 0.0052074147338040536, 0.0052007952540641007, 0.005194273452309139, 0.0051878396505349337, 0.0051814859078647656, 0.0051752110562301333, 0.0051690068033506597, 0.0051628747966167487, 0.005156801676630747]}
[2017-09-17 00:03:03,738 AE_UNIGRAMA_1L_OVER_F1_0.py:103]: done!
[2017-09-17 00:03:03,738 AE_UNIGRAMA_1L_OVER_F1_0.py:164]: >> Executing classifier part ... 
[2017-09-17 00:03:03,738 AE_UNIGRAMA_1L_OVER_F1_0.py:108]: =======================================
[2017-09-17 00:03:03,738 AE_UNIGRAMA_1L_OVER_F1_0.py:112]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x000001C5FD701400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-09-17 00:03:03,788 AE_UNIGRAMA_1L_OVER_F1_0.py:121]: training ... 
[2017-09-17 00:03:04,225 summary.py:89]: Summary name enc0_96/kernel:0 is illegal; using enc0_96/kernel_0 instead.
[2017-09-17 00:03:04,227 summary.py:89]: Summary name enc0_96/bias:0 is illegal; using enc0_96/bias_0 instead.
[2017-09-17 00:03:04,230 summary.py:89]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-09-17 00:03:04,233 summary.py:89]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-09-17 00:08:57,060 AE_UNIGRAMA_1L_OVER_F1_0.py:133]: trained!
[2017-09-17 00:08:57,060 AE_UNIGRAMA_1L_OVER_F1_0.py:136]: Training history: 
{'val_loss': [0.0097456785467908858, 0.0091725405287141314, 0.0087129062083397494, 0.0083405199114648092, 0.0080360376331866205, 0.0077855021780776391, 0.0075771903705765045, 0.0074026986683805454, 0.0072555139113884342, 0.0071302755766276798, 0.0070227761634819559, 0.0069294058523034401, 0.0068478229058956406, 0.0067758820192852101, 0.0067120824369934938, 0.0066549669936140513, 0.0066034891165160422, 0.0065565626919050508, 0.0065135357039612651, 0.0064738570813134789, 0.0064370766689727755, 0.0064025510697037213, 0.0063697484772664709, 0.006338018601235223, 0.0063066543233079456, 0.0062732401206228271, 0.0062357289466742688, 0.0061951144406752019, 0.0061526699480249827, 0.0061081445329089793, 0.0060650779275604905, 0.0060238487652623778, 0.0059849894069065367, 0.0059490466999688905, 0.0059158860764663718, 0.0058852322194252937, 0.0058568209484671351, 0.005830216716864762, 0.0058051370664779335, 0.0057813200970597564, 0.0057584994352083462, 0.0057366227981224052, 0.0057156115883888756, 0.0056955260647346502, 0.0056765081813762242, 0.0056585911958735441, 0.0056417233150028645, 0.0056257600130568755, 0.0056105504575356957, 0.0055960173314664541, 0.0055820819608099108, 0.0055686783879647598, 0.0055557806943281416, 0.0055433207957189734, 0.0055312026836383966, 0.0055193871705327699, 0.0055078148689717927, 0.0054964852069331023, 0.0054853933952161435, 0.0054745400135016199, 0.0054639347468939904, 0.0054535121388356207, 0.0054432098688376339, 0.0054328545546111226, 0.0054220929734158313, 0.0054109872784123278, 0.0053997639747978606, 0.0053885485588455522, 0.0053774643617859113, 0.0053664938574441209, 0.0053556562141740876, 0.0053448948576376911, 0.0053341543504393952, 0.0053234782918927612, 0.005312891675182267, 0.005302467676685991, 0.0052922666808730623, 0.0052822518585306597, 0.0052724116814614726, 0.0052628043271208957, 0.0052534276510882152, 0.0052443385346341185, 0.0052355541525054717, 0.005227060386445887, 0.0052188463663190836, 0.0052108687351829826, 0.0052031118851271416, 0.0051955543811857781, 0.0051881731622152438, 0.0051809555827562982, 0.0051738806489036336, 0.005166932364652951, 0.0051600974605400599, 0.0051533614636718192, 0.0051467244916187189, 0.0051401846033124988, 0.0051337197601690121, 0.0051273368469073903, 0.0051210239468941939, 0.005114781262305316, 0.0051086083211046495, 0.0051024818544535156], 'loss': [0.010098401704448505, 0.0094614251997681715, 0.0089508277274109455, 0.0085396844477816734, 0.0082049490757057, 0.0079306264793059279, 0.0077040333373304508, 0.0075149187265800537, 0.0073560305912337073, 0.007221533102797861, 0.0071066379642229045, 0.0070075290663412695, 0.0069212443868025934, 0.0068456859350601367, 0.0067788667340008546, 0.0067193144984974062, 0.0066657892486753382, 0.0066173052916750708, 0.006572984506966981, 0.0065321917457585397, 0.0064944159421291073, 0.0064591970605650199, 0.0064259071403875902, 0.0063941043266498177, 0.0063631067315864827, 0.0063312759131835157, 0.0062961688419986648, 0.0062572837778545089, 0.0062161877443729311, 0.0061727141042593079, 0.0061292308154060381, 0.0060875197507626695, 0.0060477843268063299, 0.0060108152922456418, 0.0059766674983450403, 0.00594514772927884, 0.0059159586227912654, 0.00588880062858435, 0.0058632854118369814, 0.0058390781486515981, 0.0058158739187930851, 0.0057935705661089623, 0.0057722150255646223, 0.0057517280008786073, 0.0057322529548230645, 0.005713870611356836, 0.0056965457874176379, 0.0056802048537081349, 0.0056647015496017533, 0.0056499048183386684, 0.0056357484103841324, 0.0056221846278930159, 0.0056091478831560328, 0.0055965792123199506, 0.0055843976028954034, 0.0055725295790526579, 0.0055609309737302747, 0.0055495609903240097, 0.0055384352946466712, 0.0055275457140483075, 0.0055169045190210609, 0.0055064651546962084, 0.0054961717316595717, 0.0054859358914963775, 0.0054754693589476305, 0.0054645800621928838, 0.005453493681028568, 0.0054423420449824685, 0.0054312714524622002, 0.0054203397428635855, 0.0054095425116378604, 0.0053988795033486307, 0.0053882850506092031, 0.0053777037014880909, 0.005367195844200783, 0.005356789154128727, 0.0053465724567769201, 0.0053365658269080556, 0.0053267222309602361, 0.0053170936774749166, 0.0053076890567702846, 0.0052985400633070931, 0.0052896928041830443, 0.0052811458402321184, 0.0052728922987349694, 0.0052648863485497948, 0.0052571075383038316, 0.0052495313826269371, 0.005242147245899902, 0.005234937732098449, 0.0052278778766448458, 0.0052209465483934459, 0.0052141285944618931, 0.0052074147338040536, 0.0052007952540641007, 0.005194273452309139, 0.0051878396505349337, 0.0051814859078647656, 0.0051752110562301333, 0.0051690068033506597, 0.0051628747966167487, 0.005156801676630747]}
[2017-09-17 00:08:57,060 AE_UNIGRAMA_1L_OVER_F1_0.py:140]: evaluating model ... 
[2017-09-17 00:08:57,138 AE_UNIGRAMA_1L_OVER_F1_0.py:144]: evaluated! 
[2017-09-17 00:08:57,138 AE_UNIGRAMA_1L_OVER_F1_0.py:146]: generating reports ... 
[2017-09-17 00:08:57,569 AE_UNIGRAMA_1L_OVER_F1_0.py:149]: done!
[2017-09-17 00:08:57,569 AE_UNIGRAMA_1L_OVER_F1_0.py:166]: >> experiment AE_UNIGRAMA_1L_OVER_F1_0 finished!

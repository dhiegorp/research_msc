[2017-10-02 10:06:37,502 AE_UNIGRAMA_1L_OVER_F1_0.py:160]: >> Initializing execution of experiment AE_UNIGRAMA_1L_OVER_F1_0
[2017-10-02 10:06:37,502 AE_UNIGRAMA_1L_OVER_F1_0.py:161]: >> Printing header log
[2017-10-02 10:06:37,502 AE_UNIGRAMA_1L_OVER_F1_0.py:49]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_OVER_F1_0
	layers = 96,96
	using GLOBAL obj = 
		{'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'shuffle_batches': True, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'loss_function': 'mse', 'discard_decoder_function': True, 'optimizer': <keras.optimizers.SGD object at 0x000000000196F668>, 'output_layer_activation': 'relu'}, 'batch': 32, 'epochs': 200, 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'executed_path': 'E:/research/research_msc/executed/onelayer/unigram/', 'mlp_configs': {'use_last_dim_as_classifier': False, 'activation': 'sigmoid', 'classifier_dim': 9, 'optimizer': <keras.optimizers.SGD object at 0x0000000001974588>, 'loss_function': 'categorical_crossentropy'}, 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'numpy_seed': 666, 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'store_history': True, 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram_mini.pkl'}
	=======================================
	
[2017-10-02 10:06:37,502 AE_UNIGRAMA_1L_OVER_F1_0.py:163]: >> Loading dataset... 
[2017-10-02 10:06:37,508 AE_UNIGRAMA_1L_OVER_F1_0.py:65]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram_mini.pkl	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-02 10:06:37,508 AE_UNIGRAMA_1L_OVER_F1_0.py:165]: >> Executing autoencoder part ... 
[2017-10-02 10:06:37,508 AE_UNIGRAMA_1L_OVER_F1_0.py:71]: =======================================
[2017-10-02 10:06:37,508 AE_UNIGRAMA_1L_OVER_F1_0.py:76]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'loss_function': 'mse', 'discard_decoder_function': True, 'optimizer': <keras.optimizers.SGD object at 0x000000000196F668>, 'output_layer_activation': 'relu'}
[2017-10-02 10:06:37,578 AE_UNIGRAMA_1L_OVER_F1_0.py:87]: training and evaluate autoencoder
[2017-10-02 10:06:38,143 summary.py:93]: Summary name enc0_96/kernel:0 is illegal; using enc0_96/kernel_0 instead.
[2017-10-02 10:06:38,146 summary.py:93]: Summary name enc0_96/bias:0 is illegal; using enc0_96/bias_0 instead.
[2017-10-02 10:06:38,150 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-10-02 10:06:38,153 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-10-02 10:06:53,085 AE_UNIGRAMA_1L_OVER_F1_0.py:98]: trained and evaluated!
[2017-10-02 10:06:53,086 AE_UNIGRAMA_1L_OVER_F1_0.py:101]: Training history: 
{'loss': [0.0098595433292043809, 0.0097433724031356049, 0.0096287272461834834, 0.0095161329920517568, 0.0094051015658902851, 0.0092954454587494302, 0.0091878240704811199, 0.0090813755224325495, 0.0089741585525491153, 0.0088698068878670083, 0.0087691272031367, 0.0086720116423888299, 0.008578594178121627, 0.0084885998303328245, 0.0084017423887696452, 0.0083181635363882636, 0.0082376896985878068, 0.0081603312080688242, 0.0080859663552239978, 0.0080144065103110677, 0.0079456509589535297, 0.0078794395307235799, 0.0078157477908537068, 0.0077544923009695487, 0.0076954654462580568, 0.007638622374121001, 0.0075838840598058468, 0.0075311266251032018, 0.0074801623318103937, 0.0074309822831350961, 0.0073834891764752763, 0.007337697049500976, 0.0072935321611554329, 0.0072509228934768011, 0.0072098651865970045, 0.0071702119327632834, 0.0071319276661587477, 0.0070949518345021622, 0.0070592319374170199, 0.0070247452393558838, 0.0069913923658531324, 0.0069591521758290802, 0.0069279731274196066, 0.0068978364865588098, 0.0068686579645467665, 0.0068404273357249214, 0.0068130659099185148, 0.0067866070392943994, 0.0067609717285795198, 0.006736121783817225, 0.0067121114618458044, 0.0066888462941001436, 0.0066663121129715269, 0.0066444513061127931, 0.0066232819398653314, 0.0066027377174563877, 0.0065828136794644594, 0.0065634751774842339, 0.0065446952875925675, 0.0065264672970544654, 0.0065087664545557767, 0.0064915763008160394, 0.0064748842395113962, 0.0064586504352792465, 0.0064429087649066899, 0.0064275860302745562, 0.006412691744095941, 0.0063982200926168608, 0.0063841244435944144, 0.0063704271078425714, 0.0063570717039970843, 0.0063440686677935744, 0.0063313739978179987, 0.006319014005221028, 0.0063069451588292427, 0.0062951678141136436, 0.0062836812028905223, 0.0062724570217115904, 0.0062614974486238035, 0.0062507886377168387, 0.0062403068943584555, 0.0062300266123296076, 0.0062199657761160404, 0.0062101089516362678, 0.0062004141120289317, 0.0061908942231131102, 0.0061815443263259235, 0.0061723552532631449, 0.0061633086831439981, 0.006154436618662093, 0.0061456920540723867, 0.0061370837736872529, 0.0061286243755477995, 0.0061203214599216873, 0.006112166269972563, 0.0061041497741038805, 0.0060962538149599366, 0.0060884897787748995, 0.0060808512321533096, 0.006073332994148254, 0.006065927796780184, 0.0060586129585950745], 'val_loss': [0.0097734370099235197, 0.0096600695572045658, 0.0095483759092686339, 0.0094385567090048226, 0.009329563806518967, 0.009222575508362741, 0.0091176533025990637, 0.0090123441721205368, 0.0089082521036765831, 0.0088077218039826835, 0.0087108114097253532, 0.008617421861419448, 0.0085277289366799663, 0.0084411709198942853, 0.0083578703648040289, 0.0082777522151188786, 0.0082007533122809631, 0.008126806768979946, 0.0080557086134544088, 0.0079873955105760289, 0.0079216258115650997, 0.0078583604026045712, 0.007797552470020867, 0.0077390069294319278, 0.0076826875388871559, 0.0076284944616452025, 0.0075763073684059108, 0.0075260092950941906, 0.0074774894108614954, 0.0074307231914570561, 0.0073856106599218116, 0.0073420480014860191, 0.0073000399402747811, 0.007259560742010414, 0.007220474167010266, 0.0071827800473592985, 0.0071463776444219964, 0.0071112369273730368, 0.0070773530941885864, 0.0070446009148729333, 0.0070129860777643311, 0.0069824121511614014, 0.0069528896790897977, 0.0069243253734946027, 0.0068967015963726326, 0.006869963011929426, 0.0068441037552562792, 0.0068190616268152199, 0.0067948115293670541, 0.0067713759340982897, 0.0067486791338314577, 0.0067267154056066475, 0.0067054127623434401, 0.006684795491134256, 0.0066647913417740828, 0.0066454115178311403, 0.0066266054128293209, 0.0066083770030659367, 0.0065906961278844496, 0.0065735336341185419, 0.0065568676218390465, 0.0065406851269664817, 0.0065249497102068035, 0.0065096922436916034, 0.0064948492589991776, 0.0064804336076886241, 0.0064664265334772354, 0.0064527991220881282, 0.006439549062525694, 0.006426651368340041, 0.0064140920870033782, 0.0064018428252947592, 0.0063899015007215136, 0.0063782484966527575, 0.0063668736516321461, 0.0063557787573304322, 0.0063449366236292522, 0.0063343544951103437, 0.0063240225755758443, 0.0063139100344401528, 0.0063040019722731587, 0.0062942854267264607, 0.006284767979942955, 0.0062754176640156031, 0.0062662349446056947, 0.0062572182931670689, 0.0062483413937782046, 0.0062395983538330712, 0.0062310145336954567, 0.0062225455778294339, 0.006214202920037242, 0.0062059846215060874, 0.0061979150939663547, 0.0061899798101707464, 0.0061821677777431491, 0.0061744645386795794, 0.0061668847137058089, 0.0061594259779775675, 0.0061520913989736685, 0.006144878502976717, 0.0061377567727271065, 0.006130693212054587]}
[2017-10-02 10:06:53,086 AE_UNIGRAMA_1L_OVER_F1_0.py:105]: done!
[2017-10-02 10:06:53,086 AE_UNIGRAMA_1L_OVER_F1_0.py:167]: >> Executing classifier part ... 
[2017-10-02 10:06:53,086 AE_UNIGRAMA_1L_OVER_F1_0.py:110]: =======================================
[2017-10-02 10:06:53,086 AE_UNIGRAMA_1L_OVER_F1_0.py:114]: setting configurations for classifier: 
	 {'use_last_dim_as_classifier': False, 'activation': 'sigmoid', 'classifier_dim': 9, 'optimizer': <keras.optimizers.SGD object at 0x0000000001974588>, 'loss_function': 'categorical_crossentropy'}
[2017-10-02 10:06:53,164 AE_UNIGRAMA_1L_OVER_F1_0.py:123]: training ... 
[2017-10-02 10:06:53,801 summary.py:93]: Summary name enc0_96/kernel:0 is illegal; using enc0_96/kernel_0 instead.
[2017-10-02 10:06:53,804 summary.py:93]: Summary name enc0_96/bias:0 is illegal; using enc0_96/bias_0 instead.
[2017-10-02 10:06:53,810 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-10-02 10:06:53,813 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-10-02 10:07:28,729 AE_UNIGRAMA_1L_OVER_F1_0.py:135]: trained!
[2017-10-02 10:07:28,730 AE_UNIGRAMA_1L_OVER_F1_0.py:138]: Training history: 
{'loss': [0.0098595433292043809, 0.0097433724031356049, 0.0096287272461834834, 0.0095161329920517568, 0.0094051015658902851, 0.0092954454587494302, 0.0091878240704811199, 0.0090813755224325495, 0.0089741585525491153, 0.0088698068878670083, 0.0087691272031367, 0.0086720116423888299, 0.008578594178121627, 0.0084885998303328245, 0.0084017423887696452, 0.0083181635363882636, 0.0082376896985878068, 0.0081603312080688242, 0.0080859663552239978, 0.0080144065103110677, 0.0079456509589535297, 0.0078794395307235799, 0.0078157477908537068, 0.0077544923009695487, 0.0076954654462580568, 0.007638622374121001, 0.0075838840598058468, 0.0075311266251032018, 0.0074801623318103937, 0.0074309822831350961, 0.0073834891764752763, 0.007337697049500976, 0.0072935321611554329, 0.0072509228934768011, 0.0072098651865970045, 0.0071702119327632834, 0.0071319276661587477, 0.0070949518345021622, 0.0070592319374170199, 0.0070247452393558838, 0.0069913923658531324, 0.0069591521758290802, 0.0069279731274196066, 0.0068978364865588098, 0.0068686579645467665, 0.0068404273357249214, 0.0068130659099185148, 0.0067866070392943994, 0.0067609717285795198, 0.006736121783817225, 0.0067121114618458044, 0.0066888462941001436, 0.0066663121129715269, 0.0066444513061127931, 0.0066232819398653314, 0.0066027377174563877, 0.0065828136794644594, 0.0065634751774842339, 0.0065446952875925675, 0.0065264672970544654, 0.0065087664545557767, 0.0064915763008160394, 0.0064748842395113962, 0.0064586504352792465, 0.0064429087649066899, 0.0064275860302745562, 0.006412691744095941, 0.0063982200926168608, 0.0063841244435944144, 0.0063704271078425714, 0.0063570717039970843, 0.0063440686677935744, 0.0063313739978179987, 0.006319014005221028, 0.0063069451588292427, 0.0062951678141136436, 0.0062836812028905223, 0.0062724570217115904, 0.0062614974486238035, 0.0062507886377168387, 0.0062403068943584555, 0.0062300266123296076, 0.0062199657761160404, 0.0062101089516362678, 0.0062004141120289317, 0.0061908942231131102, 0.0061815443263259235, 0.0061723552532631449, 0.0061633086831439981, 0.006154436618662093, 0.0061456920540723867, 0.0061370837736872529, 0.0061286243755477995, 0.0061203214599216873, 0.006112166269972563, 0.0061041497741038805, 0.0060962538149599366, 0.0060884897787748995, 0.0060808512321533096, 0.006073332994148254, 0.006065927796780184, 0.0060586129585950745], 'val_loss': [0.0097734370099235197, 0.0096600695572045658, 0.0095483759092686339, 0.0094385567090048226, 0.009329563806518967, 0.009222575508362741, 0.0091176533025990637, 0.0090123441721205368, 0.0089082521036765831, 0.0088077218039826835, 0.0087108114097253532, 0.008617421861419448, 0.0085277289366799663, 0.0084411709198942853, 0.0083578703648040289, 0.0082777522151188786, 0.0082007533122809631, 0.008126806768979946, 0.0080557086134544088, 0.0079873955105760289, 0.0079216258115650997, 0.0078583604026045712, 0.007797552470020867, 0.0077390069294319278, 0.0076826875388871559, 0.0076284944616452025, 0.0075763073684059108, 0.0075260092950941906, 0.0074774894108614954, 0.0074307231914570561, 0.0073856106599218116, 0.0073420480014860191, 0.0073000399402747811, 0.007259560742010414, 0.007220474167010266, 0.0071827800473592985, 0.0071463776444219964, 0.0071112369273730368, 0.0070773530941885864, 0.0070446009148729333, 0.0070129860777643311, 0.0069824121511614014, 0.0069528896790897977, 0.0069243253734946027, 0.0068967015963726326, 0.006869963011929426, 0.0068441037552562792, 0.0068190616268152199, 0.0067948115293670541, 0.0067713759340982897, 0.0067486791338314577, 0.0067267154056066475, 0.0067054127623434401, 0.006684795491134256, 0.0066647913417740828, 0.0066454115178311403, 0.0066266054128293209, 0.0066083770030659367, 0.0065906961278844496, 0.0065735336341185419, 0.0065568676218390465, 0.0065406851269664817, 0.0065249497102068035, 0.0065096922436916034, 0.0064948492589991776, 0.0064804336076886241, 0.0064664265334772354, 0.0064527991220881282, 0.006439549062525694, 0.006426651368340041, 0.0064140920870033782, 0.0064018428252947592, 0.0063899015007215136, 0.0063782484966527575, 0.0063668736516321461, 0.0063557787573304322, 0.0063449366236292522, 0.0063343544951103437, 0.0063240225755758443, 0.0063139100344401528, 0.0063040019722731587, 0.0062942854267264607, 0.006284767979942955, 0.0062754176640156031, 0.0062662349446056947, 0.0062572182931670689, 0.0062483413937782046, 0.0062395983538330712, 0.0062310145336954567, 0.0062225455778294339, 0.006214202920037242, 0.0062059846215060874, 0.0061979150939663547, 0.0061899798101707464, 0.0061821677777431491, 0.0061744645386795794, 0.0061668847137058089, 0.0061594259779775675, 0.0061520913989736685, 0.006144878502976717, 0.0061377567727271065, 0.006130693212054587]}
[2017-10-02 10:07:28,731 AE_UNIGRAMA_1L_OVER_F1_0.py:142]: evaluating model ... 
[2017-10-02 10:07:28,781 AE_UNIGRAMA_1L_OVER_F1_0.py:146]: evaluated! 
[2017-10-02 10:07:28,781 AE_UNIGRAMA_1L_OVER_F1_0.py:148]: generating reports ... 
[2017-10-02 10:07:29,732 AE_UNIGRAMA_1L_OVER_F1_0.py:151]: done!
[2017-10-02 10:07:29,732 AE_UNIGRAMA_1L_OVER_F1_0.py:169]: >> experiment AE_UNIGRAMA_1L_OVER_F1_0 finished!

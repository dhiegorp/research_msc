[2017-09-18 07:42:53,024 AE_UNIGRAMA_1L_OVER_F1_7.py:155]: >> Initializing execution of experiment AE_UNIGRAMA_1L_OVER_F1_7
[2017-09-18 07:42:53,024 AE_UNIGRAMA_1L_OVER_F1_7.py:156]: >> Printing header log
[2017-09-18 07:42:53,024 AE_UNIGRAMA_1L_OVER_F1_7.py:47]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_OVER_F1_7
	layers = 96,163
	using GLOBAL obj = 
		{'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'shuffle_batches': True, 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram.pkl', 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'store_history': True, 'executed_dir': 'E:/research/research_msc/executed/onelayer/unigram/', 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'autoencoder_configs': {'discard_decoder_function': True, 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x00000000017CB5C0>, 'output_layer_activation': 'relu', 'hidden_layer_activation': 'relu'}, 'numpy_seed': 666, 'mlp_configs': {'classifier_dim': 9, 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x00000000017CE438>, 'activation': 'sigmoid', 'use_last_dim_as_classifier': False}, 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'epochs': 1000, 'batch': 32, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9]}
	=======================================
	
[2017-09-18 07:42:53,024 AE_UNIGRAMA_1L_OVER_F1_7.py:158]: >> Loading dataset... 
[2017-09-18 07:42:53,049 AE_UNIGRAMA_1L_OVER_F1_7.py:63]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram.pkl	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-09-18 07:42:53,049 AE_UNIGRAMA_1L_OVER_F1_7.py:160]: >> Executing autoencoder part ... 
[2017-09-18 07:42:53,049 AE_UNIGRAMA_1L_OVER_F1_7.py:68]: =======================================
[2017-09-18 07:42:53,049 AE_UNIGRAMA_1L_OVER_F1_7.py:73]: setting configurations for autoencoder: 
	 {'discard_decoder_function': True, 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x00000000017CB5C0>, 'output_layer_activation': 'relu', 'hidden_layer_activation': 'relu'}
[2017-09-18 07:42:53,146 AE_UNIGRAMA_1L_OVER_F1_7.py:84]: training and evaluate autoencoder
[2017-09-18 07:42:53,727 summary.py:93]: Summary name enc0_163/kernel:0 is illegal; using enc0_163/kernel_0 instead.
[2017-09-18 07:42:53,731 summary.py:93]: Summary name enc0_163/bias:0 is illegal; using enc0_163/bias_0 instead.
[2017-09-18 07:42:53,737 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-09-18 07:42:53,740 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-09-18 07:44:04,406 AE_UNIGRAMA_1L_OVER_F1_7.py:95]: trained and evaluated!
[2017-09-18 07:44:04,406 AE_UNIGRAMA_1L_OVER_F1_7.py:98]: Training history: 
{'loss': [0.0096835110055785018, 0.0094866925285566912, 0.0089910851959086532, 0.008415653905314003, 0.0079313320470364556, 0.0075349065279573246, 0.0072095124332189221, 0.0069417748513365286, 0.0067206107426813827, 0.0065365744685168658, 0.0063820947069097213, 0.0062511388957889125, 0.0061393829663991158, 0.0060433574659082036, 0.0059599930285512154, 0.0058867451645103763, 0.005821648593390699, 0.0057629921208466727, 0.0057094201431404498, 0.0056594808065123618, 0.0056116555901332306, 0.0055644453189511696, 0.0055135662656136128, 0.0054504244182040735, 0.0053831783644704128, 0.0053194115622323705, 0.0052636569736010316, 0.0052148155960419782, 0.0051717616887348179, 0.0051333962370849239, 0.0050988766298793618, 0.0050675199789270474, 0.0050388115860692806, 0.0050122755923966544, 0.0049875914506139572, 0.0049644304869020444, 0.0049425559891729618, 0.0049217832940047041, 0.004901952086939285, 0.0048829225454732322, 0.004864607141031394, 0.0048468892488672524, 0.0048296485121136828, 0.0048127885289102465, 0.0047961491152892907, 0.0047796432713815553, 0.004763262786270212, 0.0047469592281234613, 0.0047306964159966594, 0.0047143906803246774, 0.0046980154957899844, 0.0046816892381558589, 0.0046655686757498373, 0.0046497438411839146, 0.0046342445800486255, 0.0046191272840001686, 0.004604390081362526, 0.0045899989754322797, 0.0045759278999229318, 0.0045621344138691766, 0.0045485513996869247, 0.0045351255943156654, 0.0045218163761385159, 0.004508644410897043, 0.0044956185672182063, 0.0044827796627973267, 0.0044701506066036267, 0.0044577330454273582, 0.0044455087680369161, 0.0044334758587165103, 0.0044216201869295103, 0.0044099423300227505, 0.0043983996836179364, 0.0043869597296162703, 0.0043754900582281047, 0.0043639100859303136, 0.0043524311806222857, 0.0043411664925954623, 0.0043301642056471331, 0.004319412016476812, 0.0043088894827997609, 0.0042985849751440075, 0.0042884581429901902, 0.0042784674343705267, 0.0042686507987080031, 0.0042590014172970104, 0.0042494966746143871, 0.0042401019403098461, 0.0042308208462785062, 0.0042216620216864236, 0.0042126409975121147, 0.0042037327106956568, 0.0041949483520831816, 0.0041862627364694155, 0.0041776901578325591, 0.0041692269000560738, 0.0041608748560499507, 0.0041526299163404676, 0.0041444903479440232, 0.0041364504261761064, 0.004128510409245242, 0.0041206601684897265], 'val_loss': [0.0095966108994218237, 0.0092832660716669121, 0.0086792845286508338, 0.0081450758083973004, 0.0077062517465138446, 0.0073463582715792434, 0.0070511092983243746, 0.0068077285237027104, 0.0066059858323263467, 0.0064374346019770677, 0.0062952302181521671, 0.0061742813024876619, 0.0060708192451790289, 0.0059814374137995641, 0.0059033904081050997, 0.0058344896922647152, 0.0057728861700585988, 0.0057169706730096055, 0.0056655467043773503, 0.0056170886287480069, 0.0055699975983483068, 0.0055220379958422806, 0.0054648087580045851, 0.0053970971007313538, 0.0053291300678600375, 0.0052686652107621539, 0.0052159033175020481, 0.0051695540709008943, 0.0051284418720307047, 0.0050916597356222976, 0.0050584283253148569, 0.0050281268682773059, 0.005000251365059871, 0.0049744512338943583, 0.0049503682345444205, 0.0049277224406142723, 0.0049062911248213114, 0.0048859257370220529, 0.0048664362703404506, 0.0048477264565358518, 0.004829683202807954, 0.0048121749604420677, 0.0047951045475447688, 0.0047783361864147875, 0.0047617515322137234, 0.0047452774306828375, 0.0047289137360997545, 0.0047126479502250492, 0.0046963792981631926, 0.0046800592132474035, 0.0046637527787875147, 0.0046475800197076592, 0.0046316364984404883, 0.0046159934956896661, 0.0046007024470045175, 0.0045857900441379496, 0.0045712436215650156, 0.0045570250057989439, 0.0045431221607960936, 0.0045294479880867355, 0.0045159393642970509, 0.0045025279763514416, 0.0044892270387366321, 0.0044760659589640622, 0.0044630671777662872, 0.0044502740717660373, 0.0044376851318425302, 0.0044253162118287614, 0.0044131456357137718, 0.0044011722215461912, 0.004389391440209528, 0.0043777811156759687, 0.0043663097389685162, 0.0043548841505762883, 0.0043433467878589392, 0.004331772868120711, 0.0043203404355258192, 0.0043091396116629347, 0.0042981985372514114, 0.0042875071338304991, 0.0042770281638994604, 0.0042667411666632848, 0.0042566172643408911, 0.0042466657370218005, 0.0042368925467449435, 0.0042272814972554116, 0.0042178069137336974, 0.0042084539962883869, 0.0041992191678116375, 0.0041901340127942447, 0.0041811584401268203, 0.004172304964798733, 0.0041635504200539797, 0.0041548917424282863, 0.0041463339320474326, 0.0041378831789677896, 0.0041295175551805128, 0.0041212619681095103, 0.0041131101297443946, 0.0041050650023652302, 0.0040971207388937518, 0.0040892859111086163]}
[2017-09-18 07:44:04,406 AE_UNIGRAMA_1L_OVER_F1_7.py:102]: done!
[2017-09-18 07:44:04,406 AE_UNIGRAMA_1L_OVER_F1_7.py:162]: >> Executing classifier part ... 
[2017-09-18 07:44:04,406 AE_UNIGRAMA_1L_OVER_F1_7.py:107]: =======================================
[2017-09-18 07:44:04,406 AE_UNIGRAMA_1L_OVER_F1_7.py:111]: setting configurations for classifier: 
	 {'classifier_dim': 9, 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x00000000017CE438>, 'activation': 'sigmoid', 'use_last_dim_as_classifier': False}
[2017-09-18 07:44:04,515 AE_UNIGRAMA_1L_OVER_F1_7.py:120]: training ... 
[2017-09-18 07:44:05,333 summary.py:93]: Summary name enc0_163/kernel:0 is illegal; using enc0_163/kernel_0 instead.
[2017-09-18 07:44:05,349 summary.py:93]: Summary name enc0_163/bias:0 is illegal; using enc0_163/bias_0 instead.
[2017-09-18 07:44:05,349 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-09-18 07:44:05,349 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-09-18 07:47:58,938 AE_UNIGRAMA_1L_OVER_F1_7.py:132]: trained!
[2017-09-18 07:47:58,954 AE_UNIGRAMA_1L_OVER_F1_7.py:135]: Training history: 
{'loss': [0.0096835110055785018, 0.0094866925285566912, 0.0089910851959086532, 0.008415653905314003, 0.0079313320470364556, 0.0075349065279573246, 0.0072095124332189221, 0.0069417748513365286, 0.0067206107426813827, 0.0065365744685168658, 0.0063820947069097213, 0.0062511388957889125, 0.0061393829663991158, 0.0060433574659082036, 0.0059599930285512154, 0.0058867451645103763, 0.005821648593390699, 0.0057629921208466727, 0.0057094201431404498, 0.0056594808065123618, 0.0056116555901332306, 0.0055644453189511696, 0.0055135662656136128, 0.0054504244182040735, 0.0053831783644704128, 0.0053194115622323705, 0.0052636569736010316, 0.0052148155960419782, 0.0051717616887348179, 0.0051333962370849239, 0.0050988766298793618, 0.0050675199789270474, 0.0050388115860692806, 0.0050122755923966544, 0.0049875914506139572, 0.0049644304869020444, 0.0049425559891729618, 0.0049217832940047041, 0.004901952086939285, 0.0048829225454732322, 0.004864607141031394, 0.0048468892488672524, 0.0048296485121136828, 0.0048127885289102465, 0.0047961491152892907, 0.0047796432713815553, 0.004763262786270212, 0.0047469592281234613, 0.0047306964159966594, 0.0047143906803246774, 0.0046980154957899844, 0.0046816892381558589, 0.0046655686757498373, 0.0046497438411839146, 0.0046342445800486255, 0.0046191272840001686, 0.004604390081362526, 0.0045899989754322797, 0.0045759278999229318, 0.0045621344138691766, 0.0045485513996869247, 0.0045351255943156654, 0.0045218163761385159, 0.004508644410897043, 0.0044956185672182063, 0.0044827796627973267, 0.0044701506066036267, 0.0044577330454273582, 0.0044455087680369161, 0.0044334758587165103, 0.0044216201869295103, 0.0044099423300227505, 0.0043983996836179364, 0.0043869597296162703, 0.0043754900582281047, 0.0043639100859303136, 0.0043524311806222857, 0.0043411664925954623, 0.0043301642056471331, 0.004319412016476812, 0.0043088894827997609, 0.0042985849751440075, 0.0042884581429901902, 0.0042784674343705267, 0.0042686507987080031, 0.0042590014172970104, 0.0042494966746143871, 0.0042401019403098461, 0.0042308208462785062, 0.0042216620216864236, 0.0042126409975121147, 0.0042037327106956568, 0.0041949483520831816, 0.0041862627364694155, 0.0041776901578325591, 0.0041692269000560738, 0.0041608748560499507, 0.0041526299163404676, 0.0041444903479440232, 0.0041364504261761064, 0.004128510409245242, 0.0041206601684897265], 'val_loss': [0.0095966108994218237, 0.0092832660716669121, 0.0086792845286508338, 0.0081450758083973004, 0.0077062517465138446, 0.0073463582715792434, 0.0070511092983243746, 0.0068077285237027104, 0.0066059858323263467, 0.0064374346019770677, 0.0062952302181521671, 0.0061742813024876619, 0.0060708192451790289, 0.0059814374137995641, 0.0059033904081050997, 0.0058344896922647152, 0.0057728861700585988, 0.0057169706730096055, 0.0056655467043773503, 0.0056170886287480069, 0.0055699975983483068, 0.0055220379958422806, 0.0054648087580045851, 0.0053970971007313538, 0.0053291300678600375, 0.0052686652107621539, 0.0052159033175020481, 0.0051695540709008943, 0.0051284418720307047, 0.0050916597356222976, 0.0050584283253148569, 0.0050281268682773059, 0.005000251365059871, 0.0049744512338943583, 0.0049503682345444205, 0.0049277224406142723, 0.0049062911248213114, 0.0048859257370220529, 0.0048664362703404506, 0.0048477264565358518, 0.004829683202807954, 0.0048121749604420677, 0.0047951045475447688, 0.0047783361864147875, 0.0047617515322137234, 0.0047452774306828375, 0.0047289137360997545, 0.0047126479502250492, 0.0046963792981631926, 0.0046800592132474035, 0.0046637527787875147, 0.0046475800197076592, 0.0046316364984404883, 0.0046159934956896661, 0.0046007024470045175, 0.0045857900441379496, 0.0045712436215650156, 0.0045570250057989439, 0.0045431221607960936, 0.0045294479880867355, 0.0045159393642970509, 0.0045025279763514416, 0.0044892270387366321, 0.0044760659589640622, 0.0044630671777662872, 0.0044502740717660373, 0.0044376851318425302, 0.0044253162118287614, 0.0044131456357137718, 0.0044011722215461912, 0.004389391440209528, 0.0043777811156759687, 0.0043663097389685162, 0.0043548841505762883, 0.0043433467878589392, 0.004331772868120711, 0.0043203404355258192, 0.0043091396116629347, 0.0042981985372514114, 0.0042875071338304991, 0.0042770281638994604, 0.0042667411666632848, 0.0042566172643408911, 0.0042466657370218005, 0.0042368925467449435, 0.0042272814972554116, 0.0042178069137336974, 0.0042084539962883869, 0.0041992191678116375, 0.0041901340127942447, 0.0041811584401268203, 0.004172304964798733, 0.0041635504200539797, 0.0041548917424282863, 0.0041463339320474326, 0.0041378831789677896, 0.0041295175551805128, 0.0041212619681095103, 0.0041131101297443946, 0.0041050650023652302, 0.0040971207388937518, 0.0040892859111086163]}
[2017-09-18 07:47:58,954 AE_UNIGRAMA_1L_OVER_F1_7.py:139]: evaluating model ... 
[2017-09-18 07:47:59,016 AE_UNIGRAMA_1L_OVER_F1_7.py:143]: evaluated! 
[2017-09-18 07:47:59,016 AE_UNIGRAMA_1L_OVER_F1_7.py:145]: generating reports ... 
[2017-09-18 07:47:59,922 AE_UNIGRAMA_1L_OVER_F1_7.py:148]: done!
[2017-09-18 07:47:59,922 AE_UNIGRAMA_1L_OVER_F1_7.py:164]: >> experiment AE_UNIGRAMA_1L_OVER_F1_7 finished!

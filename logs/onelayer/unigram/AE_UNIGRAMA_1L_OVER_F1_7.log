[2017-10-02 10:13:31,851 AE_UNIGRAMA_1L_OVER_F1_7.py:157]: >> Initializing execution of experiment AE_UNIGRAMA_1L_OVER_F1_7
[2017-10-02 10:13:31,851 AE_UNIGRAMA_1L_OVER_F1_7.py:158]: >> Printing header log
[2017-10-02 10:13:31,852 AE_UNIGRAMA_1L_OVER_F1_7.py:48]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_OVER_F1_7
	layers = 96,163
	using GLOBAL obj = 
		{'numpy_seed': 666, 'shuffle_batches': True, 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'mlp_configs': {'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x0000000001910390>, 'activation': 'sigmoid', 'classifier_dim': 9}, 'autoencoder_configs': {'discard_decoder_function': True, 'loss_function': 'mse', 'hidden_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x000000000170D518>, 'output_layer_activation': 'relu'}, 'epochs': 200, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'store_history': True, 'batch': 32, 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram_mini.pkl', 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'executed_path': 'E:/research/research_msc/executed/onelayer/unigram/'}
	=======================================
	
[2017-10-02 10:13:31,852 AE_UNIGRAMA_1L_OVER_F1_7.py:160]: >> Loading dataset... 
[2017-10-02 10:13:31,862 AE_UNIGRAMA_1L_OVER_F1_7.py:64]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram_mini.pkl	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-02 10:13:31,862 AE_UNIGRAMA_1L_OVER_F1_7.py:162]: >> Executing autoencoder part ... 
[2017-10-02 10:13:31,862 AE_UNIGRAMA_1L_OVER_F1_7.py:69]: =======================================
[2017-10-02 10:13:31,862 AE_UNIGRAMA_1L_OVER_F1_7.py:74]: setting configurations for autoencoder: 
	 {'discard_decoder_function': True, 'loss_function': 'mse', 'hidden_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x000000000170D518>, 'output_layer_activation': 'relu'}
[2017-10-02 10:13:31,981 AE_UNIGRAMA_1L_OVER_F1_7.py:85]: training and evaluate autoencoder
[2017-10-02 10:13:32,704 summary.py:93]: Summary name enc0_163/kernel:0 is illegal; using enc0_163/kernel_0 instead.
[2017-10-02 10:13:32,707 summary.py:93]: Summary name enc0_163/bias:0 is illegal; using enc0_163/bias_0 instead.
[2017-10-02 10:13:32,712 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-10-02 10:13:32,715 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-10-02 10:13:58,744 AE_UNIGRAMA_1L_OVER_F1_7.py:96]: trained and evaluated!
[2017-10-02 10:13:58,745 AE_UNIGRAMA_1L_OVER_F1_7.py:99]: Training history: 
{'val_loss': [0.0099928706787443516, 0.009890505794754258, 0.009774838826968767, 0.0096529280441401168, 0.0095304980333963743, 0.0094105446551922978, 0.0092945705067546402, 0.0091826675916748413, 0.0090749711282966748, 0.0089712844171377804, 0.0088715619376434716, 0.0087753233420195184, 0.0086825068132972624, 0.0085928820655248421, 0.0085062580944824835, 0.0084225142333088747, 0.008341292163433307, 0.008262560128140849, 0.0081862608407066665, 0.0081120350668172185, 0.008039787787334737, 0.0079696668852051386, 0.0079018173957430514, 0.0078361441405510809, 0.0077725011547231096, 0.0077110212400112454, 0.0076514362170599873, 0.0075936067371618794, 0.0075375333144485288, 0.0074833177313984103, 0.0074307629682788395, 0.0073798557632640833, 0.007330634143051162, 0.0072829569620686168, 0.0072367632290743101, 0.0071919858421036304, 0.0071486784145236015, 0.0071066704346732582, 0.0070658837130023197, 0.0070263073436888177, 0.006987943791794733, 0.0069507955985496925, 0.0069148012014542152, 0.0068799322488333437, 0.0068461073330537761, 0.0068133349433458206, 0.0067815268896935597, 0.0067506410340781994, 0.0067206560374414165, 0.0066915544573923911, 0.0066632654649451317, 0.0066357266147479025, 0.0066089732901342072, 0.0065829469251089826, 0.0065577159684192957, 0.0065331763594816388, 0.0065093266995810669, 0.006486158182699109, 0.0064636536538046976, 0.0064417897519347391, 0.0064205750182520279, 0.0063999243059842999, 0.0063798756089380017, 0.0063603753500988489, 0.0063414193904477428, 0.0063229991368894019, 0.0063050845464809237, 0.0062876506154615859, 0.0062706805627142188, 0.0062541340488151105, 0.0062380439556830435, 0.0062223792900106276, 0.006207108708811737, 0.0061922303632898842, 0.0061777235185346635, 0.006163591307806038, 0.0061498034475405867, 0.0061363376777439091, 0.0061231880417599114, 0.0061103254729764165, 0.0060977811949348365, 0.0060855386498276853, 0.0060735662540483213, 0.0060618490337300702, 0.0060503861302558378, 0.0060391972848944722, 0.0060282330475332126, 0.0060175162009534783, 0.0060070190980310335, 0.0059967333534005404, 0.0059866755439113954, 0.005976815469092153, 0.0059671570256103149, 0.0059576758761720585, 0.0059483801239762161, 0.0059392437144947761, 0.005930279565067983, 0.0059214754144359923, 0.005912828593269046, 0.0059043296238885275, 0.0058959774676447243, 0.0058877642256065814], 'loss': [0.01004571792427462, 0.0099501143557093382, 0.0098410440596265886, 0.0097205341096965169, 0.0095964081152659954, 0.0094728997514137263, 0.0093529294843120881, 0.0092372163768443295, 0.0091255133028228588, 0.0090180389381620003, 0.0089145663412449252, 0.0088148623522881654, 0.0087186093777006004, 0.0086257055987957135, 0.0085360173624840045, 0.0084492915407848937, 0.0083653818565227901, 0.0082839485887522771, 0.0082049639409003845, 0.0081282803936464764, 0.0080536471850959409, 0.0079810744925380931, 0.0079108062125834017, 0.0078428557958882053, 0.0077770010799458038, 0.0077131618041552021, 0.007651324308927834, 0.0075913506019665887, 0.007533189658872376, 0.0074769042735116824, 0.007422507227671498, 0.0073697678656068294, 0.0073186549903010946, 0.0072692126913205674, 0.0072213116762489902, 0.0071749267658904499, 0.0071299272256238775, 0.0070863686872333674, 0.0070441056700616834, 0.0070031046267477514, 0.0069633367475403843, 0.0069248007519425942, 0.00688747554094735, 0.006851270508087517, 0.0068161238260228321, 0.0067820497943041477, 0.0067490086436830347, 0.0067169486413942792, 0.006685812700569593, 0.0066555974757174039, 0.0066262399797804641, 0.0065976691597725767, 0.006569935516617418, 0.0065429850696679375, 0.0065168056567786259, 0.00649141075951634, 0.006466722906096057, 0.0064427018080870655, 0.0064193497488610604, 0.0063966561736196704, 0.0063746109116563747, 0.0063531970706571994, 0.0063323339375254565, 0.0063120560541968813, 0.006292317222893128, 0.0062731305156166414, 0.006254468845305409, 0.0062363274162492103, 0.0062186762804455125, 0.0062014854764399826, 0.0061847319578627134, 0.0061684493287440705, 0.0061525658941321126, 0.0061370794797005945, 0.0061219663727861392, 0.0061072330414154406, 0.0060928625277327699, 0.0060788320936148122, 0.0060651199013503077, 0.0060517268235890792, 0.0060386304576442182, 0.0060258467158516744, 0.006013361920305535, 0.0060011470382981642, 0.005989196499925251, 0.0059775001067180504, 0.0059660722761453299, 0.0059548560260911255, 0.0059439090161270058, 0.0059331674761291696, 0.0059226357498845588, 0.005912338392368272, 0.0059022258213860309, 0.0058923331510044342, 0.0058826112881595911, 0.0058730796257694517, 0.0058637185937529812, 0.0058545383407786426, 0.0058455177907360866, 0.0058366615793449643, 0.0058279466296110548, 0.0058193881807078341]}
[2017-10-02 10:13:58,746 AE_UNIGRAMA_1L_OVER_F1_7.py:103]: done!
[2017-10-02 10:13:58,746 AE_UNIGRAMA_1L_OVER_F1_7.py:164]: >> Executing classifier part ... 
[2017-10-02 10:13:58,746 AE_UNIGRAMA_1L_OVER_F1_7.py:108]: =======================================
[2017-10-02 10:13:58,747 AE_UNIGRAMA_1L_OVER_F1_7.py:112]: setting configurations for classifier: 
	 {'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x0000000001910390>, 'activation': 'sigmoid', 'classifier_dim': 9}
[2017-10-02 10:13:58,858 AE_UNIGRAMA_1L_OVER_F1_7.py:121]: training ... 
[2017-10-02 10:13:59,524 summary.py:93]: Summary name enc0_163/kernel:0 is illegal; using enc0_163/kernel_0 instead.
[2017-10-02 10:13:59,527 summary.py:93]: Summary name enc0_163/bias:0 is illegal; using enc0_163/bias_0 instead.
[2017-10-02 10:13:59,533 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-10-02 10:13:59,536 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-10-02 10:14:46,864 AE_UNIGRAMA_1L_OVER_F1_7.py:133]: trained!
[2017-10-02 10:14:46,864 AE_UNIGRAMA_1L_OVER_F1_7.py:136]: Training history: 
{'val_loss': [0.0099928706787443516, 0.009890505794754258, 0.009774838826968767, 0.0096529280441401168, 0.0095304980333963743, 0.0094105446551922978, 0.0092945705067546402, 0.0091826675916748413, 0.0090749711282966748, 0.0089712844171377804, 0.0088715619376434716, 0.0087753233420195184, 0.0086825068132972624, 0.0085928820655248421, 0.0085062580944824835, 0.0084225142333088747, 0.008341292163433307, 0.008262560128140849, 0.0081862608407066665, 0.0081120350668172185, 0.008039787787334737, 0.0079696668852051386, 0.0079018173957430514, 0.0078361441405510809, 0.0077725011547231096, 0.0077110212400112454, 0.0076514362170599873, 0.0075936067371618794, 0.0075375333144485288, 0.0074833177313984103, 0.0074307629682788395, 0.0073798557632640833, 0.007330634143051162, 0.0072829569620686168, 0.0072367632290743101, 0.0071919858421036304, 0.0071486784145236015, 0.0071066704346732582, 0.0070658837130023197, 0.0070263073436888177, 0.006987943791794733, 0.0069507955985496925, 0.0069148012014542152, 0.0068799322488333437, 0.0068461073330537761, 0.0068133349433458206, 0.0067815268896935597, 0.0067506410340781994, 0.0067206560374414165, 0.0066915544573923911, 0.0066632654649451317, 0.0066357266147479025, 0.0066089732901342072, 0.0065829469251089826, 0.0065577159684192957, 0.0065331763594816388, 0.0065093266995810669, 0.006486158182699109, 0.0064636536538046976, 0.0064417897519347391, 0.0064205750182520279, 0.0063999243059842999, 0.0063798756089380017, 0.0063603753500988489, 0.0063414193904477428, 0.0063229991368894019, 0.0063050845464809237, 0.0062876506154615859, 0.0062706805627142188, 0.0062541340488151105, 0.0062380439556830435, 0.0062223792900106276, 0.006207108708811737, 0.0061922303632898842, 0.0061777235185346635, 0.006163591307806038, 0.0061498034475405867, 0.0061363376777439091, 0.0061231880417599114, 0.0061103254729764165, 0.0060977811949348365, 0.0060855386498276853, 0.0060735662540483213, 0.0060618490337300702, 0.0060503861302558378, 0.0060391972848944722, 0.0060282330475332126, 0.0060175162009534783, 0.0060070190980310335, 0.0059967333534005404, 0.0059866755439113954, 0.005976815469092153, 0.0059671570256103149, 0.0059576758761720585, 0.0059483801239762161, 0.0059392437144947761, 0.005930279565067983, 0.0059214754144359923, 0.005912828593269046, 0.0059043296238885275, 0.0058959774676447243, 0.0058877642256065814], 'loss': [0.01004571792427462, 0.0099501143557093382, 0.0098410440596265886, 0.0097205341096965169, 0.0095964081152659954, 0.0094728997514137263, 0.0093529294843120881, 0.0092372163768443295, 0.0091255133028228588, 0.0090180389381620003, 0.0089145663412449252, 0.0088148623522881654, 0.0087186093777006004, 0.0086257055987957135, 0.0085360173624840045, 0.0084492915407848937, 0.0083653818565227901, 0.0082839485887522771, 0.0082049639409003845, 0.0081282803936464764, 0.0080536471850959409, 0.0079810744925380931, 0.0079108062125834017, 0.0078428557958882053, 0.0077770010799458038, 0.0077131618041552021, 0.007651324308927834, 0.0075913506019665887, 0.007533189658872376, 0.0074769042735116824, 0.007422507227671498, 0.0073697678656068294, 0.0073186549903010946, 0.0072692126913205674, 0.0072213116762489902, 0.0071749267658904499, 0.0071299272256238775, 0.0070863686872333674, 0.0070441056700616834, 0.0070031046267477514, 0.0069633367475403843, 0.0069248007519425942, 0.00688747554094735, 0.006851270508087517, 0.0068161238260228321, 0.0067820497943041477, 0.0067490086436830347, 0.0067169486413942792, 0.006685812700569593, 0.0066555974757174039, 0.0066262399797804641, 0.0065976691597725767, 0.006569935516617418, 0.0065429850696679375, 0.0065168056567786259, 0.00649141075951634, 0.006466722906096057, 0.0064427018080870655, 0.0064193497488610604, 0.0063966561736196704, 0.0063746109116563747, 0.0063531970706571994, 0.0063323339375254565, 0.0063120560541968813, 0.006292317222893128, 0.0062731305156166414, 0.006254468845305409, 0.0062363274162492103, 0.0062186762804455125, 0.0062014854764399826, 0.0061847319578627134, 0.0061684493287440705, 0.0061525658941321126, 0.0061370794797005945, 0.0061219663727861392, 0.0061072330414154406, 0.0060928625277327699, 0.0060788320936148122, 0.0060651199013503077, 0.0060517268235890792, 0.0060386304576442182, 0.0060258467158516744, 0.006013361920305535, 0.0060011470382981642, 0.005989196499925251, 0.0059775001067180504, 0.0059660722761453299, 0.0059548560260911255, 0.0059439090161270058, 0.0059331674761291696, 0.0059226357498845588, 0.005912338392368272, 0.0059022258213860309, 0.0058923331510044342, 0.0058826112881595911, 0.0058730796257694517, 0.0058637185937529812, 0.0058545383407786426, 0.0058455177907360866, 0.0058366615793449643, 0.0058279466296110548, 0.0058193881807078341]}
[2017-10-02 10:14:46,865 AE_UNIGRAMA_1L_OVER_F1_7.py:140]: evaluating model ... 
[2017-10-02 10:14:46,912 AE_UNIGRAMA_1L_OVER_F1_7.py:144]: evaluated! 
[2017-10-02 10:14:46,912 AE_UNIGRAMA_1L_OVER_F1_7.py:146]: generating reports ... 
[2017-10-02 10:14:47,890 AE_UNIGRAMA_1L_OVER_F1_7.py:149]: done!
[2017-10-02 10:14:47,890 AE_UNIGRAMA_1L_OVER_F1_7.py:166]: >> experiment AE_UNIGRAMA_1L_OVER_F1_7 finished!

[2017-10-02 10:21:37,063 AE_UNIGRAMA_1L_UNDER_F0_6.py:156]: >> Initializing execution of experiment AE_UNIGRAMA_1L_UNDER_F0_6
[2017-10-02 10:21:37,063 AE_UNIGRAMA_1L_UNDER_F0_6.py:157]: >> Printing header log
[2017-10-02 10:21:37,063 AE_UNIGRAMA_1L_UNDER_F0_6.py:48]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_UNDER_F0_6
	layers = 96,57
	using GLOBAL obj = 
		{'shuffle_batches': True, 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'autoencoder_configs': {'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x000000000198E4E0>, 'discard_decoder_function': True, 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu'}, 'batch': 32, 'numpy_seed': 666, 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'store_history': True, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'executed_path': 'E:/research/research_msc/executed/onelayer/unigram/', 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram_mini.pkl', 'mlp_configs': {'loss_function': 'categorical_crossentropy', 'use_last_dim_as_classifier': False, 'classifier_dim': 9, 'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x0000000001990358>}, 'epochs': 200}
	=======================================
	
[2017-10-02 10:21:37,064 AE_UNIGRAMA_1L_UNDER_F0_6.py:159]: >> Loading dataset... 
[2017-10-02 10:21:37,069 AE_UNIGRAMA_1L_UNDER_F0_6.py:64]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram_mini.pkl	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-02 10:21:37,069 AE_UNIGRAMA_1L_UNDER_F0_6.py:161]: >> Executing autoencoder part ... 
[2017-10-02 10:21:37,069 AE_UNIGRAMA_1L_UNDER_F0_6.py:69]: =======================================
[2017-10-02 10:21:37,069 AE_UNIGRAMA_1L_UNDER_F0_6.py:74]: setting configurations for autoencoder: 
	 {'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x000000000198E4E0>, 'discard_decoder_function': True, 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu'}
[2017-10-02 10:21:37,125 AE_UNIGRAMA_1L_UNDER_F0_6.py:85]: training and evaluate autoencoder
[2017-10-02 10:21:37,481 summary.py:93]: Summary name enc0_57/kernel:0 is illegal; using enc0_57/kernel_0 instead.
[2017-10-02 10:21:37,483 summary.py:93]: Summary name enc0_57/bias:0 is illegal; using enc0_57/bias_0 instead.
[2017-10-02 10:21:37,486 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-10-02 10:21:37,488 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-10-02 10:21:47,126 AE_UNIGRAMA_1L_UNDER_F0_6.py:96]: trained and evaluated!
[2017-10-02 10:21:47,127 AE_UNIGRAMA_1L_UNDER_F0_6.py:99]: Training history: 
{'val_loss': [0.010409347294071572, 0.010285540231153868, 0.010159113049701022, 0.010033034736837596, 0.0099074698319887144, 0.0097850010276782466, 0.0096649657623309182, 0.0095451679669292886, 0.0094275082492695419, 0.0093131644865948032, 0.0092025921787360337, 0.0090959383361733977, 0.008993111138810234, 0.008893936098688264, 0.0087981898212964645, 0.0087060294335631859, 0.0086174678147448482, 0.0085320412440980237, 0.0084497507758521679, 0.0083704336432109984, 0.0082939075060244165, 0.0082200073730546754, 0.0081483663170560366, 0.0080791954435823574, 0.008012369067363136, 0.007947940422658251, 0.0078857007045229563, 0.0078256011275803072, 0.0077675778339149565, 0.0077115728807216682, 0.0076573930341459562, 0.0076049983269469226, 0.0075544042401985163, 0.007505496666112354, 0.0074581806513318123, 0.0074123819670241786, 0.0073679617145635378, 0.0073247095518035737, 0.0072826416349405475, 0.0072417693423820475, 0.007202088566268465, 0.0071635901007011922, 0.0071263281147248463, 0.0070901870481725297, 0.0070551993605788088, 0.0070212771839091772, 0.0069883470925533641, 0.0069564167171245837, 0.0069254245228206803, 0.0068953327252962333, 0.0068661034744246742, 0.0068377211246791825, 0.0068101628119174437, 0.0067833603522480645, 0.0067572923858397289, 0.0067319380721859775, 0.0067072931961000629, 0.0066832914467222409, 0.0066599550667360815, 0.0066372325339226473, 0.0066150999991534815, 0.0065935333553687791, 0.0065725304958407097, 0.0065520631900701162, 0.0065321348015509794, 0.0065127034069187798, 0.0064937776183107082, 0.0064753332040289966, 0.0064573676314994303, 0.0064398644519727466, 0.0064228077723772776, 0.0064061945269652905, 0.0063899821414851125, 0.0063741798010623586, 0.0063587328709911236, 0.0063436207288813853, 0.0063287745139883576, 0.0063139561626049225, 0.0062988504878207213, 0.006283858467281197, 0.0062692144792180745, 0.0062548535180080777, 0.0062407753863077623, 0.0062269562540305809, 0.0062134170447749716, 0.0062001490442698554, 0.0061871563378707627, 0.0061744364068521441, 0.0061619625181015096, 0.0061496947718901931, 0.0061376516129059864, 0.0061258161994438192, 0.0061142023801665103, 0.0061027968551645049, 0.0060915932228934148, 0.0060805997994752619, 0.006069795865579387, 0.006059165631999092, 0.0060487234978815439, 0.0060384392766039607, 0.0060282861138780544, 0.0060182419003136315], 'loss': [0.010501657733974204, 0.010378906608644481, 0.010250860222425832, 0.010120789930293108, 0.0099910715767757684, 0.0098626971245956846, 0.0097379000140806245, 0.0096154193953137575, 0.0094943142964858986, 0.0093767281768233329, 0.009262771352543997, 0.0091528282772701582, 0.0090466885196105722, 0.0089442954761031652, 0.0088456047798455978, 0.0087504870588556351, 0.0086589950808285566, 0.008570998639198045, 0.0084861755450087312, 0.0084044509713286693, 0.0083256435094569529, 0.0082495979439254248, 0.008175961895929975, 0.0081047115929896441, 0.0080359021811926366, 0.0079694441041709384, 0.007905338416603, 0.0078433826525673295, 0.0077835897003204896, 0.0077258622526811104, 0.0076701264395123807, 0.0076161982871124955, 0.0075640329540453593, 0.0075136639707857429, 0.0074649484832121429, 0.0074178114494500014, 0.0073721681014001002, 0.0073278444749317476, 0.0072847446312265815, 0.0072428893321379792, 0.0072022625242291818, 0.0071628611384860633, 0.0071246310523021385, 0.0070876265394019984, 0.0070517233475016977, 0.0070169590228679694, 0.0069832282150009695, 0.0069504811453673654, 0.0069187437773744571, 0.0068879172623217029, 0.0068580083103682195, 0.0068289558549160306, 0.0068007438405249185, 0.0067733385349430953, 0.0067467136172887987, 0.006720815949226697, 0.0066956336259127542, 0.0066711325092514784, 0.0066472893496649027, 0.0066241053346322402, 0.0066015345059316916, 0.0065795774305423636, 0.0065581747379380648, 0.006537334831487605, 0.0065170354750774427, 0.0064972877429744441, 0.0064780296598685319, 0.0064592940286923826, 0.0064410246209171042, 0.0064232272085102335, 0.0064058884338332083, 0.0063889914549447565, 0.0063725453930246955, 0.006356500814993395, 0.0063408706812319686, 0.0063255976842053474, 0.0063106238492263668, 0.0062957841501706897, 0.006280699764855192, 0.0062654003845533492, 0.0062503371635004284, 0.0062356089275002885, 0.0062211397314042346, 0.0062069250050343725, 0.0061929622706834095, 0.0061792770550044207, 0.0061658654409473893, 0.006152737112950531, 0.0061398613720001181, 0.0061272405650061408, 0.0061148245359262075, 0.006102629933797038, 0.0060906455721580219, 0.0060788559694170546, 0.0060672775032851655, 0.0060558943796305293, 0.0060447337496258692, 0.006033722837023396, 0.0060228784376848091, 0.0060122305823269067, 0.006001725413944726, 0.0059913575320694077]}
[2017-10-02 10:21:47,127 AE_UNIGRAMA_1L_UNDER_F0_6.py:103]: done!
[2017-10-02 10:21:47,127 AE_UNIGRAMA_1L_UNDER_F0_6.py:163]: >> Executing classifier part ... 
[2017-10-02 10:21:47,127 AE_UNIGRAMA_1L_UNDER_F0_6.py:108]: =======================================
[2017-10-02 10:21:47,127 AE_UNIGRAMA_1L_UNDER_F0_6.py:112]: setting configurations for classifier: 
	 {'loss_function': 'categorical_crossentropy', 'use_last_dim_as_classifier': False, 'classifier_dim': 9, 'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x0000000001990358>}
[2017-10-02 10:21:47,182 AE_UNIGRAMA_1L_UNDER_F0_6.py:121]: training ... 
[2017-10-02 10:21:47,584 summary.py:93]: Summary name enc0_57/kernel:0 is illegal; using enc0_57/kernel_0 instead.
[2017-10-02 10:21:47,586 summary.py:93]: Summary name enc0_57/bias:0 is illegal; using enc0_57/bias_0 instead.
[2017-10-02 10:21:47,589 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-10-02 10:21:47,591 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-10-02 10:22:07,912 AE_UNIGRAMA_1L_UNDER_F0_6.py:133]: trained!
[2017-10-02 10:22:07,913 AE_UNIGRAMA_1L_UNDER_F0_6.py:136]: Training history: 
{'val_loss': [0.010409347294071572, 0.010285540231153868, 0.010159113049701022, 0.010033034736837596, 0.0099074698319887144, 0.0097850010276782466, 0.0096649657623309182, 0.0095451679669292886, 0.0094275082492695419, 0.0093131644865948032, 0.0092025921787360337, 0.0090959383361733977, 0.008993111138810234, 0.008893936098688264, 0.0087981898212964645, 0.0087060294335631859, 0.0086174678147448482, 0.0085320412440980237, 0.0084497507758521679, 0.0083704336432109984, 0.0082939075060244165, 0.0082200073730546754, 0.0081483663170560366, 0.0080791954435823574, 0.008012369067363136, 0.007947940422658251, 0.0078857007045229563, 0.0078256011275803072, 0.0077675778339149565, 0.0077115728807216682, 0.0076573930341459562, 0.0076049983269469226, 0.0075544042401985163, 0.007505496666112354, 0.0074581806513318123, 0.0074123819670241786, 0.0073679617145635378, 0.0073247095518035737, 0.0072826416349405475, 0.0072417693423820475, 0.007202088566268465, 0.0071635901007011922, 0.0071263281147248463, 0.0070901870481725297, 0.0070551993605788088, 0.0070212771839091772, 0.0069883470925533641, 0.0069564167171245837, 0.0069254245228206803, 0.0068953327252962333, 0.0068661034744246742, 0.0068377211246791825, 0.0068101628119174437, 0.0067833603522480645, 0.0067572923858397289, 0.0067319380721859775, 0.0067072931961000629, 0.0066832914467222409, 0.0066599550667360815, 0.0066372325339226473, 0.0066150999991534815, 0.0065935333553687791, 0.0065725304958407097, 0.0065520631900701162, 0.0065321348015509794, 0.0065127034069187798, 0.0064937776183107082, 0.0064753332040289966, 0.0064573676314994303, 0.0064398644519727466, 0.0064228077723772776, 0.0064061945269652905, 0.0063899821414851125, 0.0063741798010623586, 0.0063587328709911236, 0.0063436207288813853, 0.0063287745139883576, 0.0063139561626049225, 0.0062988504878207213, 0.006283858467281197, 0.0062692144792180745, 0.0062548535180080777, 0.0062407753863077623, 0.0062269562540305809, 0.0062134170447749716, 0.0062001490442698554, 0.0061871563378707627, 0.0061744364068521441, 0.0061619625181015096, 0.0061496947718901931, 0.0061376516129059864, 0.0061258161994438192, 0.0061142023801665103, 0.0061027968551645049, 0.0060915932228934148, 0.0060805997994752619, 0.006069795865579387, 0.006059165631999092, 0.0060487234978815439, 0.0060384392766039607, 0.0060282861138780544, 0.0060182419003136315], 'loss': [0.010501657733974204, 0.010378906608644481, 0.010250860222425832, 0.010120789930293108, 0.0099910715767757684, 0.0098626971245956846, 0.0097379000140806245, 0.0096154193953137575, 0.0094943142964858986, 0.0093767281768233329, 0.009262771352543997, 0.0091528282772701582, 0.0090466885196105722, 0.0089442954761031652, 0.0088456047798455978, 0.0087504870588556351, 0.0086589950808285566, 0.008570998639198045, 0.0084861755450087312, 0.0084044509713286693, 0.0083256435094569529, 0.0082495979439254248, 0.008175961895929975, 0.0081047115929896441, 0.0080359021811926366, 0.0079694441041709384, 0.007905338416603, 0.0078433826525673295, 0.0077835897003204896, 0.0077258622526811104, 0.0076701264395123807, 0.0076161982871124955, 0.0075640329540453593, 0.0075136639707857429, 0.0074649484832121429, 0.0074178114494500014, 0.0073721681014001002, 0.0073278444749317476, 0.0072847446312265815, 0.0072428893321379792, 0.0072022625242291818, 0.0071628611384860633, 0.0071246310523021385, 0.0070876265394019984, 0.0070517233475016977, 0.0070169590228679694, 0.0069832282150009695, 0.0069504811453673654, 0.0069187437773744571, 0.0068879172623217029, 0.0068580083103682195, 0.0068289558549160306, 0.0068007438405249185, 0.0067733385349430953, 0.0067467136172887987, 0.006720815949226697, 0.0066956336259127542, 0.0066711325092514784, 0.0066472893496649027, 0.0066241053346322402, 0.0066015345059316916, 0.0065795774305423636, 0.0065581747379380648, 0.006537334831487605, 0.0065170354750774427, 0.0064972877429744441, 0.0064780296598685319, 0.0064592940286923826, 0.0064410246209171042, 0.0064232272085102335, 0.0064058884338332083, 0.0063889914549447565, 0.0063725453930246955, 0.006356500814993395, 0.0063408706812319686, 0.0063255976842053474, 0.0063106238492263668, 0.0062957841501706897, 0.006280699764855192, 0.0062654003845533492, 0.0062503371635004284, 0.0062356089275002885, 0.0062211397314042346, 0.0062069250050343725, 0.0061929622706834095, 0.0061792770550044207, 0.0061658654409473893, 0.006152737112950531, 0.0061398613720001181, 0.0061272405650061408, 0.0061148245359262075, 0.006102629933797038, 0.0060906455721580219, 0.0060788559694170546, 0.0060672775032851655, 0.0060558943796305293, 0.0060447337496258692, 0.006033722837023396, 0.0060228784376848091, 0.0060122305823269067, 0.006001725413944726, 0.0059913575320694077]}
[2017-10-02 10:22:07,913 AE_UNIGRAMA_1L_UNDER_F0_6.py:140]: evaluating model ... 
[2017-10-02 10:22:07,934 AE_UNIGRAMA_1L_UNDER_F0_6.py:144]: evaluated! 
[2017-10-02 10:22:07,935 AE_UNIGRAMA_1L_UNDER_F0_6.py:146]: generating reports ... 
[2017-10-02 10:22:08,404 AE_UNIGRAMA_1L_UNDER_F0_6.py:149]: done!
[2017-10-02 10:22:08,404 AE_UNIGRAMA_1L_UNDER_F0_6.py:165]: >> experiment AE_UNIGRAMA_1L_UNDER_F0_6 finished!

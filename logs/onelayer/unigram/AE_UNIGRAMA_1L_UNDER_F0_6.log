[2017-09-18 07:42:52,948 AE_UNIGRAMA_1L_UNDER_F0_6.py:154]: >> Initializing execution of experiment AE_UNIGRAMA_1L_UNDER_F0_6
[2017-09-18 07:42:52,948 AE_UNIGRAMA_1L_UNDER_F0_6.py:155]: >> Printing header log
[2017-09-18 07:42:52,948 AE_UNIGRAMA_1L_UNDER_F0_6.py:47]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_UNDER_F0_6
	layers = 96,57
	using GLOBAL obj = 
		{'epochs': 1000, 'numpy_seed': 666, 'mlp_configs': {'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x00000000019CE400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9, 'loss_function': 'categorical_crossentropy'}, 'batch': 32, 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'shuffle_batches': True, 'executed_dir': 'E:/research/research_msc/executed/onelayer/unigram/', 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram.pkl', 'autoencoder_configs': {'discard_decoder_function': True, 'output_layer_activation': 'relu', 'hidden_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x00000000019CC588>, 'loss_function': 'mse'}, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'store_history': True}
	=======================================
	
[2017-09-18 07:42:52,949 AE_UNIGRAMA_1L_UNDER_F0_6.py:157]: >> Loading dataset... 
[2017-09-18 07:42:52,973 AE_UNIGRAMA_1L_UNDER_F0_6.py:63]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram.pkl	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-09-18 07:42:52,973 AE_UNIGRAMA_1L_UNDER_F0_6.py:159]: >> Executing autoencoder part ... 
[2017-09-18 07:42:52,973 AE_UNIGRAMA_1L_UNDER_F0_6.py:68]: =======================================
[2017-09-18 07:42:52,973 AE_UNIGRAMA_1L_UNDER_F0_6.py:73]: setting configurations for autoencoder: 
	 {'discard_decoder_function': True, 'output_layer_activation': 'relu', 'hidden_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x00000000019CC588>, 'loss_function': 'mse'}
[2017-09-18 07:42:53,074 AE_UNIGRAMA_1L_UNDER_F0_6.py:84]: training and evaluate autoencoder
[2017-09-18 07:42:53,684 summary.py:93]: Summary name enc0_57/kernel:0 is illegal; using enc0_57/kernel_0 instead.
[2017-09-18 07:42:53,688 summary.py:93]: Summary name enc0_57/bias:0 is illegal; using enc0_57/bias_0 instead.
[2017-09-18 07:42:53,694 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-09-18 07:42:53,696 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-09-18 07:44:32,252 AE_UNIGRAMA_1L_UNDER_F0_6.py:95]: trained and evaluated!
[2017-09-18 07:44:32,252 AE_UNIGRAMA_1L_UNDER_F0_6.py:98]: Training history: 
{'val_loss': [0.0098933688830755429, 0.0098268864881719611, 0.0097560390819087274, 0.0096193386822971769, 0.0093210708101453561, 0.0089204681414983503, 0.0085698711788175699, 0.0082680928263811886, 0.0080096360567432807, 0.0077883062970806397, 0.0075985117459814152, 0.0074345699363606837, 0.0072921753103904032, 0.0071679454747599763, 0.0070592491130746053, 0.0069638117179219791, 0.0068792294064322426, 0.0068037611081886822, 0.0067361465122007195, 0.0066754913699595157, 0.0066206389793408062, 0.0065707841459203076, 0.0065252089075290981, 0.0064833527390675012, 0.006444718615480181, 0.0064089330566484987, 0.0063756675330579049, 0.0063445308973560247, 0.0063153121662173845, 0.0062877765903061131, 0.0062618071873265348, 0.0062372099473156535, 0.0062138234399148192, 0.006191460017316134, 0.0061675303855049058, 0.0061427869245126564, 0.0061188359055681808, 0.006095583885288614, 0.0060730017351999042, 0.0060510027605851302, 0.0060295876198903807, 0.0060087610018165431, 0.005988363032573228, 0.0059682606714813588, 0.0059484311802882961, 0.0059286180918044365, 0.0059088897849927709, 0.0058889331588557877, 0.0058686457780928779, 0.0058483555714453636, 0.0058284507516240345, 0.0058090387074634818, 0.005790168260409333, 0.0057720135796769977, 0.0057546357051440292, 0.0057380554658689022, 0.0057222626565790261, 0.0057071747912216531, 0.0056927367903323667, 0.005678887101138768, 0.0056655226837164585, 0.0056525857315475082, 0.0056400388765543456, 0.0056278499483190083, 0.0056159961682007414, 0.0056044464745722746, 0.0055931690348382766, 0.0055821298603454484, 0.0055713303494467391, 0.0055607227571424986, 0.0055503044444287263, 0.0055400073533937288, 0.0055297688329137128, 0.0055195441186662187, 0.0055091040258051791, 0.0054983277972007237, 0.0054872396526305786, 0.0054760668703992552, 0.0054650059574307963, 0.0054541062929033303, 0.0054433865556359918, 0.0054328417736976701, 0.0054224603637424533, 0.0054122411519479316, 0.0054021728767040334, 0.0053922504325079343, 0.0053824840467943452, 0.0053728429150679659, 0.005363311750598003, 0.005353874118672804, 0.0053444729980323645, 0.0053349935530264923, 0.0053253714231386072, 0.0053156203749832294, 0.005305831163138622, 0.005296005567676774, 0.0052861496123311731, 0.0052763021031503442, 0.0052664554540139104, 0.0052566209904512731, 0.005246769293142604, 0.0052369623403046078], 'loss': [0.009933649693646943, 0.009864570310048287, 0.0097979861272175905, 0.00970169671160598, 0.0094907082893010142, 0.0091221169026174595, 0.0087480172086235007, 0.008424798234619545, 0.0081475456448152298, 0.0079102932448757591, 0.0077070477572354903, 0.00753254215446225, 0.0073815168126639312, 0.0072500080131318971, 0.0071352389001514893, 0.0070346539421252815, 0.0069460168458467409, 0.0068671911646458464, 0.0067967354039689823, 0.0067335944959983672, 0.0066767654291840983, 0.0066252099894804758, 0.0065782620811957702, 0.0065352886675603111, 0.0064957214999960891, 0.006459151201015991, 0.0064252048997317989, 0.0063935899592609553, 0.0063639576992103918, 0.0063361097416987158, 0.0063098665312315743, 0.0062850803540699706, 0.0062616095080037992, 0.006239278966119019, 0.0062170002858240323, 0.006192569686809782, 0.0061684927485409517, 0.0061450600532632644, 0.0061222236387786459, 0.0060999797898564981, 0.0060782971652116064, 0.0060572034237640895, 0.0060366448972360943, 0.0060163807044793629, 0.0059962803188117423, 0.0059762120249630766, 0.0059560353414337191, 0.0059358304671918499, 0.0059153700452144742, 0.0058947554759761706, 0.0058743468445419493, 0.0058544163430518641, 0.0058350614236620428, 0.0058164000694644665, 0.0057985230094196611, 0.0057814646104394811, 0.0057651881442115039, 0.0057496835637805182, 0.0057348525361378012, 0.0057206532629386249, 0.0057069992034304972, 0.0056937955685917386, 0.0056810121255333147, 0.0056686049656595201, 0.0056565481239095987, 0.0056448290029654288, 0.0056334087103641853, 0.0056222481603367359, 0.0056113271324833482, 0.0056006299080063084, 0.0055901065478619217, 0.0055797497649968941, 0.0055694751298813877, 0.0055592328340191921, 0.005548917751645433, 0.0055383496302884973, 0.0055274672524934275, 0.0055164386578543476, 0.0055054245813647646, 0.0054945762509145636, 0.0054838844326696168, 0.0054733833303002655, 0.0054630500323223606, 0.0054528722172593634, 0.0054428531144468661, 0.0054329772746985827, 0.0054232432150659315, 0.0054136406563060537, 0.0054041399058959152, 0.0053947468523616966, 0.0053854218946032045, 0.0053760723157829154, 0.0053665933850935458, 0.0053569719428453759, 0.0053472440582117637, 0.0053374733780655334, 0.0053276925509386525, 0.0053179093814446172, 0.0053081248895571181, 0.0052983461652507556, 0.0052885884222805104, 0.0052788580589022017]}
[2017-09-18 07:44:32,252 AE_UNIGRAMA_1L_UNDER_F0_6.py:102]: done!
[2017-09-18 07:44:32,252 AE_UNIGRAMA_1L_UNDER_F0_6.py:161]: >> Executing classifier part ... 
[2017-09-18 07:44:32,252 AE_UNIGRAMA_1L_UNDER_F0_6.py:107]: =======================================
[2017-09-18 07:44:32,252 AE_UNIGRAMA_1L_UNDER_F0_6.py:111]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x00000000019CE400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9, 'loss_function': 'categorical_crossentropy'}
[2017-09-18 07:44:32,505 AE_UNIGRAMA_1L_UNDER_F0_6.py:120]: training ... 
[2017-09-18 07:44:34,465 summary.py:93]: Summary name enc0_57/kernel:0 is illegal; using enc0_57/kernel_0 instead.
[2017-09-18 07:44:34,481 summary.py:93]: Summary name enc0_57/bias:0 is illegal; using enc0_57/bias_0 instead.
[2017-09-18 07:44:34,496 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-09-18 07:44:34,496 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-09-18 07:48:59,758 AE_UNIGRAMA_1L_UNDER_F0_6.py:132]: trained!
[2017-09-18 07:48:59,758 AE_UNIGRAMA_1L_UNDER_F0_6.py:135]: Training history: 
{'val_loss': [0.0098933688830755429, 0.0098268864881719611, 0.0097560390819087274, 0.0096193386822971769, 0.0093210708101453561, 0.0089204681414983503, 0.0085698711788175699, 0.0082680928263811886, 0.0080096360567432807, 0.0077883062970806397, 0.0075985117459814152, 0.0074345699363606837, 0.0072921753103904032, 0.0071679454747599763, 0.0070592491130746053, 0.0069638117179219791, 0.0068792294064322426, 0.0068037611081886822, 0.0067361465122007195, 0.0066754913699595157, 0.0066206389793408062, 0.0065707841459203076, 0.0065252089075290981, 0.0064833527390675012, 0.006444718615480181, 0.0064089330566484987, 0.0063756675330579049, 0.0063445308973560247, 0.0063153121662173845, 0.0062877765903061131, 0.0062618071873265348, 0.0062372099473156535, 0.0062138234399148192, 0.006191460017316134, 0.0061675303855049058, 0.0061427869245126564, 0.0061188359055681808, 0.006095583885288614, 0.0060730017351999042, 0.0060510027605851302, 0.0060295876198903807, 0.0060087610018165431, 0.005988363032573228, 0.0059682606714813588, 0.0059484311802882961, 0.0059286180918044365, 0.0059088897849927709, 0.0058889331588557877, 0.0058686457780928779, 0.0058483555714453636, 0.0058284507516240345, 0.0058090387074634818, 0.005790168260409333, 0.0057720135796769977, 0.0057546357051440292, 0.0057380554658689022, 0.0057222626565790261, 0.0057071747912216531, 0.0056927367903323667, 0.005678887101138768, 0.0056655226837164585, 0.0056525857315475082, 0.0056400388765543456, 0.0056278499483190083, 0.0056159961682007414, 0.0056044464745722746, 0.0055931690348382766, 0.0055821298603454484, 0.0055713303494467391, 0.0055607227571424986, 0.0055503044444287263, 0.0055400073533937288, 0.0055297688329137128, 0.0055195441186662187, 0.0055091040258051791, 0.0054983277972007237, 0.0054872396526305786, 0.0054760668703992552, 0.0054650059574307963, 0.0054541062929033303, 0.0054433865556359918, 0.0054328417736976701, 0.0054224603637424533, 0.0054122411519479316, 0.0054021728767040334, 0.0053922504325079343, 0.0053824840467943452, 0.0053728429150679659, 0.005363311750598003, 0.005353874118672804, 0.0053444729980323645, 0.0053349935530264923, 0.0053253714231386072, 0.0053156203749832294, 0.005305831163138622, 0.005296005567676774, 0.0052861496123311731, 0.0052763021031503442, 0.0052664554540139104, 0.0052566209904512731, 0.005246769293142604, 0.0052369623403046078], 'loss': [0.009933649693646943, 0.009864570310048287, 0.0097979861272175905, 0.00970169671160598, 0.0094907082893010142, 0.0091221169026174595, 0.0087480172086235007, 0.008424798234619545, 0.0081475456448152298, 0.0079102932448757591, 0.0077070477572354903, 0.00753254215446225, 0.0073815168126639312, 0.0072500080131318971, 0.0071352389001514893, 0.0070346539421252815, 0.0069460168458467409, 0.0068671911646458464, 0.0067967354039689823, 0.0067335944959983672, 0.0066767654291840983, 0.0066252099894804758, 0.0065782620811957702, 0.0065352886675603111, 0.0064957214999960891, 0.006459151201015991, 0.0064252048997317989, 0.0063935899592609553, 0.0063639576992103918, 0.0063361097416987158, 0.0063098665312315743, 0.0062850803540699706, 0.0062616095080037992, 0.006239278966119019, 0.0062170002858240323, 0.006192569686809782, 0.0061684927485409517, 0.0061450600532632644, 0.0061222236387786459, 0.0060999797898564981, 0.0060782971652116064, 0.0060572034237640895, 0.0060366448972360943, 0.0060163807044793629, 0.0059962803188117423, 0.0059762120249630766, 0.0059560353414337191, 0.0059358304671918499, 0.0059153700452144742, 0.0058947554759761706, 0.0058743468445419493, 0.0058544163430518641, 0.0058350614236620428, 0.0058164000694644665, 0.0057985230094196611, 0.0057814646104394811, 0.0057651881442115039, 0.0057496835637805182, 0.0057348525361378012, 0.0057206532629386249, 0.0057069992034304972, 0.0056937955685917386, 0.0056810121255333147, 0.0056686049656595201, 0.0056565481239095987, 0.0056448290029654288, 0.0056334087103641853, 0.0056222481603367359, 0.0056113271324833482, 0.0056006299080063084, 0.0055901065478619217, 0.0055797497649968941, 0.0055694751298813877, 0.0055592328340191921, 0.005548917751645433, 0.0055383496302884973, 0.0055274672524934275, 0.0055164386578543476, 0.0055054245813647646, 0.0054945762509145636, 0.0054838844326696168, 0.0054733833303002655, 0.0054630500323223606, 0.0054528722172593634, 0.0054428531144468661, 0.0054329772746985827, 0.0054232432150659315, 0.0054136406563060537, 0.0054041399058959152, 0.0053947468523616966, 0.0053854218946032045, 0.0053760723157829154, 0.0053665933850935458, 0.0053569719428453759, 0.0053472440582117637, 0.0053374733780655334, 0.0053276925509386525, 0.0053179093814446172, 0.0053081248895571181, 0.0052983461652507556, 0.0052885884222805104, 0.0052788580589022017]}
[2017-09-18 07:48:59,758 AE_UNIGRAMA_1L_UNDER_F0_6.py:139]: evaluating model ... 
[2017-09-18 07:48:59,836 AE_UNIGRAMA_1L_UNDER_F0_6.py:143]: evaluated! 
[2017-09-18 07:48:59,836 AE_UNIGRAMA_1L_UNDER_F0_6.py:145]: generating reports ... 
[2017-09-18 07:49:00,482 AE_UNIGRAMA_1L_UNDER_F0_6.py:148]: done!
[2017-09-18 07:49:00,482 AE_UNIGRAMA_1L_UNDER_F0_6.py:163]: >> experiment AE_UNIGRAMA_1L_UNDER_F0_6 finished!

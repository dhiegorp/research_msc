[2017-10-02 10:20:27,724 AE_UNIGRAMA_1L_UNDER_F0_4.py:157]: >> Initializing execution of experiment AE_UNIGRAMA_1L_UNDER_F0_4
[2017-10-02 10:20:27,724 AE_UNIGRAMA_1L_UNDER_F0_4.py:158]: >> Printing header log
[2017-10-02 10:20:27,724 AE_UNIGRAMA_1L_UNDER_F0_4.py:48]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_UNDER_F0_4
	layers = 96,38
	using GLOBAL obj = 
		{'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'mlp_configs': {'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x0000000001950358>, 'loss_function': 'categorical_crossentropy', 'use_last_dim_as_classifier': False, 'classifier_dim': 9}, 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'epochs': 200, 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram_mini.pkl', 'executed_path': 'E:/research/research_msc/executed/onelayer/unigram/', 'autoencoder_configs': {'discard_decoder_function': True, 'hidden_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x000000000174E4E0>, 'loss_function': 'mse', 'output_layer_activation': 'relu'}, 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'store_history': True, 'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'batch': 32, 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'shuffle_batches': True}
	=======================================
	
[2017-10-02 10:20:27,725 AE_UNIGRAMA_1L_UNDER_F0_4.py:160]: >> Loading dataset... 
[2017-10-02 10:20:27,730 AE_UNIGRAMA_1L_UNDER_F0_4.py:64]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram_mini.pkl	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-02 10:20:27,730 AE_UNIGRAMA_1L_UNDER_F0_4.py:162]: >> Executing autoencoder part ... 
[2017-10-02 10:20:27,730 AE_UNIGRAMA_1L_UNDER_F0_4.py:69]: =======================================
[2017-10-02 10:20:27,730 AE_UNIGRAMA_1L_UNDER_F0_4.py:74]: setting configurations for autoencoder: 
	 {'discard_decoder_function': True, 'hidden_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x000000000174E4E0>, 'loss_function': 'mse', 'output_layer_activation': 'relu'}
[2017-10-02 10:20:27,786 AE_UNIGRAMA_1L_UNDER_F0_4.py:85]: training and evaluate autoencoder
[2017-10-02 10:20:28,136 summary.py:93]: Summary name enc0_38/kernel:0 is illegal; using enc0_38/kernel_0 instead.
[2017-10-02 10:20:28,138 summary.py:93]: Summary name enc0_38/bias:0 is illegal; using enc0_38/bias_0 instead.
[2017-10-02 10:20:28,141 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-10-02 10:20:28,143 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-10-02 10:20:37,922 AE_UNIGRAMA_1L_UNDER_F0_4.py:96]: trained and evaluated!
[2017-10-02 10:20:37,922 AE_UNIGRAMA_1L_UNDER_F0_4.py:99]: Training history: 
{'val_loss': [0.0099099804976172604, 0.0098027536077736482, 0.009697567290699172, 0.0095955151441372011, 0.0094965932939243148, 0.0094011856076830387, 0.0093092101671106309, 0.00922045595320738, 0.0091347817096125231, 0.0090521387825114128, 0.0089724173797052151, 0.0088953985780699102, 0.0088210872488726465, 0.0087493054887286797, 0.0086798439300913351, 0.0086125334461659309, 0.0085472357234325554, 0.0084840084796556758, 0.008422855881551717, 0.0083637849538548952, 0.0083066657718728031, 0.008251399047617354, 0.0081979787621134712, 0.0081463824822584716, 0.0080965029657385605, 0.0080482427577823947, 0.00800154711462585, 0.0079564063283562875, 0.0079126611739729416, 0.0078703415957469929, 0.0078293686995774391, 0.0077896140027638927, 0.0077510796847396627, 0.0077136753743244366, 0.0076773760365980047, 0.0076421619752996698, 0.0076079564965347377, 0.0075746592805897434, 0.0075422564632221228, 0.0075106729465955696, 0.0074799558698272397, 0.007450060617718776, 0.0074210025293953361, 0.0073926760122650838, 0.0073650419490488049, 0.0073380643505339951, 0.0073117097202674607, 0.007285984560196395, 0.0072608483197049798, 0.0072363088405985373, 0.0072123064489889761, 0.0071888198629437104, 0.0071658422827692945, 0.0071434324752664034, 0.0071216210632906972, 0.0071003624674306704, 0.007079681594506405, 0.0070595454985490523, 0.0070399337216214622, 0.0070207851859273524, 0.0070021191688053666, 0.0069839450181029099, 0.0069662407629164178, 0.0069489646218301639, 0.0069321174153774198, 0.0069157085381448269, 0.00689969995477995, 0.0068841143511235714, 0.0068689096826353704, 0.0068541018666221747, 0.0068396479549184168, 0.0068255415840635294, 0.0068117588252992432, 0.0067983007640145081, 0.0067851813804344395, 0.0067723529018655585, 0.0067598736727243237, 0.0067476875176410911, 0.0067358237853945412, 0.0067242281355628514, 0.0067128825337248663, 0.0067017865886558605, 0.0066909557554635417, 0.0066803674798694241, 0.0066700192743074493, 0.0066598906566053074, 0.006649995271158041, 0.0066403027616967498, 0.0066308247368630424, 0.0066215558718460644, 0.0066124704669897885, 0.0066035643019142203, 0.0065948430580332817, 0.0065863001001063995, 0.0065779235442497913, 0.0065697067102147297, 0.0065616459194501537, 0.0065537242783185049, 0.0065459494607100696, 0.0065383201752370395, 0.0065308205582561545, 0.006523458712966247], 'loss': [0.0099613747542887723, 0.0098526198468465859, 0.0097447194327321528, 0.0096394827099403647, 0.0095377535889521661, 0.0094392194739498832, 0.009344175921039817, 0.0092524670891019553, 0.0091639081034500247, 0.009078455126095052, 0.0089960492152512325, 0.0089165197826175501, 0.0088396664410051052, 0.0087655392030658134, 0.0086938983411027314, 0.0086244646260616748, 0.0085570648599922038, 0.0084915870357563546, 0.0084282360260031965, 0.0083669680190749454, 0.0083077356165484478, 0.0082504026816165293, 0.0081949184798093457, 0.0081412725799706129, 0.0080893922988703147, 0.0080391768247035662, 0.007990597892660229, 0.0079435387370992306, 0.0078980166435850749, 0.0078538106594145413, 0.007811012453460847, 0.0077695358411787327, 0.0077292690907628464, 0.0076902480060423561, 0.007652322497830189, 0.0076154845545770167, 0.0075797536218631615, 0.0075450307078838126, 0.0075112571270098041, 0.0074783574043330633, 0.0074463015821199701, 0.0074150765357057086, 0.007384716612404211, 0.0073551500832047213, 0.0073263176279537469, 0.0072981733276400564, 0.0072706862082035171, 0.007243803687698191, 0.0072175452735254424, 0.0071918778711060989, 0.0071667921849593438, 0.0071422399016533369, 0.0071181734023843543, 0.0070945805516242797, 0.00707159165067446, 0.0070492133286969936, 0.0070274134061213975, 0.0070061645775085475, 0.0069854236602870214, 0.0069651726822780365, 0.0069453643541038954, 0.0069260586444666291, 0.0069072473989988514, 0.0068889250738412306, 0.0068710425032329067, 0.0068535726828261355, 0.0068365478998058107, 0.0068199591406065225, 0.0068038101488359145, 0.0067880487604125113, 0.0067726881357771931, 0.0067576843001333096, 0.0067430279328136921, 0.0067287028017874572, 0.0067147173298855974, 0.0067010846022761486, 0.0066877590537016279, 0.0066747862757507029, 0.0066621187503650538, 0.0066497766798603699, 0.0066377131383437904, 0.0066259044237416548, 0.0066143729304408254, 0.0066031073154246217, 0.0065920868105430802, 0.0065813162813413047, 0.0065707813959268793, 0.0065604910911613249, 0.0065504079916444049, 0.0065405521729014256, 0.0065309167187031277, 0.00652146616723954, 0.0065122107232759973, 0.0065031396697338879, 0.0064942493674716812, 0.0064855230360829396, 0.0064769525386589978, 0.0064685532703569826, 0.0064603019131950863, 0.006452209885176626, 0.006444273040857173, 0.0064364681478312723]}
[2017-10-02 10:20:37,922 AE_UNIGRAMA_1L_UNDER_F0_4.py:103]: done!
[2017-10-02 10:20:37,922 AE_UNIGRAMA_1L_UNDER_F0_4.py:164]: >> Executing classifier part ... 
[2017-10-02 10:20:37,922 AE_UNIGRAMA_1L_UNDER_F0_4.py:108]: =======================================
[2017-10-02 10:20:37,922 AE_UNIGRAMA_1L_UNDER_F0_4.py:112]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x0000000001950358>, 'loss_function': 'categorical_crossentropy', 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-02 10:20:37,976 AE_UNIGRAMA_1L_UNDER_F0_4.py:121]: training ... 
[2017-10-02 10:20:38,371 summary.py:93]: Summary name enc0_38/kernel:0 is illegal; using enc0_38/kernel_0 instead.
[2017-10-02 10:20:38,373 summary.py:93]: Summary name enc0_38/bias:0 is illegal; using enc0_38/bias_0 instead.
[2017-10-02 10:20:38,376 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-10-02 10:20:38,377 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-10-02 10:20:57,792 AE_UNIGRAMA_1L_UNDER_F0_4.py:133]: trained!
[2017-10-02 10:20:57,792 AE_UNIGRAMA_1L_UNDER_F0_4.py:136]: Training history: 
{'val_loss': [0.0099099804976172604, 0.0098027536077736482, 0.009697567290699172, 0.0095955151441372011, 0.0094965932939243148, 0.0094011856076830387, 0.0093092101671106309, 0.00922045595320738, 0.0091347817096125231, 0.0090521387825114128, 0.0089724173797052151, 0.0088953985780699102, 0.0088210872488726465, 0.0087493054887286797, 0.0086798439300913351, 0.0086125334461659309, 0.0085472357234325554, 0.0084840084796556758, 0.008422855881551717, 0.0083637849538548952, 0.0083066657718728031, 0.008251399047617354, 0.0081979787621134712, 0.0081463824822584716, 0.0080965029657385605, 0.0080482427577823947, 0.00800154711462585, 0.0079564063283562875, 0.0079126611739729416, 0.0078703415957469929, 0.0078293686995774391, 0.0077896140027638927, 0.0077510796847396627, 0.0077136753743244366, 0.0076773760365980047, 0.0076421619752996698, 0.0076079564965347377, 0.0075746592805897434, 0.0075422564632221228, 0.0075106729465955696, 0.0074799558698272397, 0.007450060617718776, 0.0074210025293953361, 0.0073926760122650838, 0.0073650419490488049, 0.0073380643505339951, 0.0073117097202674607, 0.007285984560196395, 0.0072608483197049798, 0.0072363088405985373, 0.0072123064489889761, 0.0071888198629437104, 0.0071658422827692945, 0.0071434324752664034, 0.0071216210632906972, 0.0071003624674306704, 0.007079681594506405, 0.0070595454985490523, 0.0070399337216214622, 0.0070207851859273524, 0.0070021191688053666, 0.0069839450181029099, 0.0069662407629164178, 0.0069489646218301639, 0.0069321174153774198, 0.0069157085381448269, 0.00689969995477995, 0.0068841143511235714, 0.0068689096826353704, 0.0068541018666221747, 0.0068396479549184168, 0.0068255415840635294, 0.0068117588252992432, 0.0067983007640145081, 0.0067851813804344395, 0.0067723529018655585, 0.0067598736727243237, 0.0067476875176410911, 0.0067358237853945412, 0.0067242281355628514, 0.0067128825337248663, 0.0067017865886558605, 0.0066909557554635417, 0.0066803674798694241, 0.0066700192743074493, 0.0066598906566053074, 0.006649995271158041, 0.0066403027616967498, 0.0066308247368630424, 0.0066215558718460644, 0.0066124704669897885, 0.0066035643019142203, 0.0065948430580332817, 0.0065863001001063995, 0.0065779235442497913, 0.0065697067102147297, 0.0065616459194501537, 0.0065537242783185049, 0.0065459494607100696, 0.0065383201752370395, 0.0065308205582561545, 0.006523458712966247], 'loss': [0.0099613747542887723, 0.0098526198468465859, 0.0097447194327321528, 0.0096394827099403647, 0.0095377535889521661, 0.0094392194739498832, 0.009344175921039817, 0.0092524670891019553, 0.0091639081034500247, 0.009078455126095052, 0.0089960492152512325, 0.0089165197826175501, 0.0088396664410051052, 0.0087655392030658134, 0.0086938983411027314, 0.0086244646260616748, 0.0085570648599922038, 0.0084915870357563546, 0.0084282360260031965, 0.0083669680190749454, 0.0083077356165484478, 0.0082504026816165293, 0.0081949184798093457, 0.0081412725799706129, 0.0080893922988703147, 0.0080391768247035662, 0.007990597892660229, 0.0079435387370992306, 0.0078980166435850749, 0.0078538106594145413, 0.007811012453460847, 0.0077695358411787327, 0.0077292690907628464, 0.0076902480060423561, 0.007652322497830189, 0.0076154845545770167, 0.0075797536218631615, 0.0075450307078838126, 0.0075112571270098041, 0.0074783574043330633, 0.0074463015821199701, 0.0074150765357057086, 0.007384716612404211, 0.0073551500832047213, 0.0073263176279537469, 0.0072981733276400564, 0.0072706862082035171, 0.007243803687698191, 0.0072175452735254424, 0.0071918778711060989, 0.0071667921849593438, 0.0071422399016533369, 0.0071181734023843543, 0.0070945805516242797, 0.00707159165067446, 0.0070492133286969936, 0.0070274134061213975, 0.0070061645775085475, 0.0069854236602870214, 0.0069651726822780365, 0.0069453643541038954, 0.0069260586444666291, 0.0069072473989988514, 0.0068889250738412306, 0.0068710425032329067, 0.0068535726828261355, 0.0068365478998058107, 0.0068199591406065225, 0.0068038101488359145, 0.0067880487604125113, 0.0067726881357771931, 0.0067576843001333096, 0.0067430279328136921, 0.0067287028017874572, 0.0067147173298855974, 0.0067010846022761486, 0.0066877590537016279, 0.0066747862757507029, 0.0066621187503650538, 0.0066497766798603699, 0.0066377131383437904, 0.0066259044237416548, 0.0066143729304408254, 0.0066031073154246217, 0.0065920868105430802, 0.0065813162813413047, 0.0065707813959268793, 0.0065604910911613249, 0.0065504079916444049, 0.0065405521729014256, 0.0065309167187031277, 0.00652146616723954, 0.0065122107232759973, 0.0065031396697338879, 0.0064942493674716812, 0.0064855230360829396, 0.0064769525386589978, 0.0064685532703569826, 0.0064603019131950863, 0.006452209885176626, 0.006444273040857173, 0.0064364681478312723]}
[2017-10-02 10:20:57,792 AE_UNIGRAMA_1L_UNDER_F0_4.py:140]: evaluating model ... 
[2017-10-02 10:20:57,814 AE_UNIGRAMA_1L_UNDER_F0_4.py:144]: evaluated! 
[2017-10-02 10:20:57,814 AE_UNIGRAMA_1L_UNDER_F0_4.py:146]: generating reports ... 
[2017-10-02 10:20:58,282 AE_UNIGRAMA_1L_UNDER_F0_4.py:149]: done!
[2017-10-02 10:20:58,282 AE_UNIGRAMA_1L_UNDER_F0_4.py:166]: >> experiment AE_UNIGRAMA_1L_UNDER_F0_4 finished!

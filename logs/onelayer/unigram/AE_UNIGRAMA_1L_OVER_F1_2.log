[2017-09-18 07:42:51,794 AE_UNIGRAMA_1L_OVER_F1_2.py:154]: >> Initializing execution of experiment AE_UNIGRAMA_1L_OVER_F1_2
[2017-09-18 07:42:51,794 AE_UNIGRAMA_1L_OVER_F1_2.py:155]: >> Printing header log
[2017-09-18 07:42:51,794 AE_UNIGRAMA_1L_OVER_F1_2.py:47]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_OVER_F1_2
	layers = 96,115
	using GLOBAL obj = 
		{'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'shuffle_batches': True, 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram.pkl', 'batch': 32, 'numpy_seed': 666, 'store_history': True, 'epochs': 1000, 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'mlp_configs': {'optimizer': <keras.optimizers.SGD object at 0x0000000001A01630>, 'activation': 'sigmoid', 'use_last_dim_as_classifier': False, 'classifier_dim': 9, 'loss_function': 'categorical_crossentropy'}, 'autoencoder_configs': {'optimizer': <keras.optimizers.SGD object at 0x00000000019FE780>, 'output_layer_activation': 'relu', 'hidden_layer_activation': 'relu', 'discard_decoder_function': True, 'loss_function': 'mse'}, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'executed_dir': 'E:/research/research_msc/executed/onelayer/unigram/'}
	=======================================
	
[2017-09-18 07:42:51,794 AE_UNIGRAMA_1L_OVER_F1_2.py:157]: >> Loading dataset... 
[2017-09-18 07:42:51,825 AE_UNIGRAMA_1L_OVER_F1_2.py:63]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram.pkl	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-09-18 07:42:51,825 AE_UNIGRAMA_1L_OVER_F1_2.py:159]: >> Executing autoencoder part ... 
[2017-09-18 07:42:51,825 AE_UNIGRAMA_1L_OVER_F1_2.py:68]: =======================================
[2017-09-18 07:42:51,825 AE_UNIGRAMA_1L_OVER_F1_2.py:73]: setting configurations for autoencoder: 
	 {'optimizer': <keras.optimizers.SGD object at 0x00000000019FE780>, 'output_layer_activation': 'relu', 'hidden_layer_activation': 'relu', 'discard_decoder_function': True, 'loss_function': 'mse'}
[2017-09-18 07:42:51,887 AE_UNIGRAMA_1L_OVER_F1_2.py:84]: training and evaluate autoencoder
[2017-09-18 07:42:52,264 summary.py:93]: Summary name enc0_115/kernel:0 is illegal; using enc0_115/kernel_0 instead.
[2017-09-18 07:42:52,264 summary.py:93]: Summary name enc0_115/bias:0 is illegal; using enc0_115/bias_0 instead.
[2017-09-18 07:42:52,264 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-09-18 07:42:52,264 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-09-18 07:44:35,280 AE_UNIGRAMA_1L_OVER_F1_2.py:95]: trained and evaluated!
[2017-09-18 07:44:35,280 AE_UNIGRAMA_1L_OVER_F1_2.py:98]: Training history: 
{'val_loss': [0.0099117025001900731, 0.0095980112214642203, 0.0090738193356856098, 0.0085641373590987554, 0.0081333248435873206, 0.0077758400621579238, 0.0074780350634865858, 0.0072285380393803363, 0.0070183679394051571, 0.0068396917682583278, 0.0066869404792952673, 0.0065556575639330152, 0.0064422683117761302, 0.0063434277663882909, 0.0062563678754397074, 0.0061789544655892481, 0.0061093933250719479, 0.0060463503412306798, 0.0059882689467455012, 0.0059296855339674341, 0.0058742683537089451, 0.0058220187488748926, 0.0057732525861930572, 0.0057277565036319509, 0.0056851757207706721, 0.0056450151588845806, 0.0056067303936135808, 0.0055702439289764582, 0.0055356324907564767, 0.005502786496667844, 0.0054715111739940337, 0.0054415480498305269, 0.0054125683217862873, 0.0053843188575150303, 0.0053569726724326831, 0.005330561087523251, 0.005304921876730857, 0.0052798786001209443, 0.0052549614303549208, 0.0052299170387934144, 0.0052048313463615367, 0.0051801395279932761, 0.0051561918859915979, 0.0051327726179244424, 0.0051098918455499895, 0.0050878071366340051, 0.0050665724710915591, 0.0050461022943143283, 0.005026355725057623, 0.0050073133571739478, 0.004988870649276461, 0.0049709856104740964, 0.0049536265432834625, 0.0049367891457712211, 0.0049204299669987966, 0.0049045409782878984, 0.004889095887745081, 0.0048740707914242624, 0.0048594288486892888, 0.0048450443433143827, 0.0048309084282484958, 0.0048170447643388998, 0.004803456488937873, 0.0047901345693972816, 0.0047770931030521272, 0.004764363950221789, 0.0047519619198251092, 0.0047398769868813653, 0.0047281031618842864, 0.0047166089214814447, 0.0047053684393979006, 0.0046943431472931518, 0.0046835132898165217, 0.0046728663614125174, 0.0046623829525537057, 0.0046520338143290147, 0.0046417644238513607, 0.0046315452613012479, 0.0046213055881769152, 0.0046109187781936713, 0.004600306509253636, 0.0045894279772089232, 0.0045782801084126631, 0.0045669740148077597, 0.0045557072731754918, 0.0045444632580302563, 0.0045332613559244681, 0.0045220816940225277, 0.0045108974914951951, 0.0044997059293888789, 0.0044885934181206778, 0.0044776136033341032, 0.0044668062055005647, 0.004456163951165314, 0.0044457089351948786, 0.0044354496017431798, 0.0044253750935519297, 0.0044154473466186681, 0.0044057073004599226, 0.0043962131870379315, 0.0043869878570417416, 0.0043780333350540218], 'loss': [0.0099982424694379443, 0.0097816835797850353, 0.0093427979707081388, 0.0088222641053165886, 0.0083547523755059371, 0.0079653201922198161, 0.0076418114524635086, 0.007371765500472062, 0.0071450531266870213, 0.0069534559883346466, 0.0067902967140373019, 0.0066505344465696854, 0.006530286704741187, 0.0064260937016065445, 0.0063348669625980601, 0.0062542184020185805, 0.006182176228788706, 0.006117235830645152, 0.006058094197969024, 0.0060005742405284373, 0.0059440410383890686, 0.0058904761579735921, 0.0058401114574497615, 0.0057930446682447328, 0.0057490201932390112, 0.0057076867212561633, 0.0056685302073893424, 0.0056311656370904416, 0.0055956636630712011, 0.0055619774623947181, 0.0055299398626016925, 0.0054993401941131953, 0.0054699380939699019, 0.0054413776856628649, 0.0054136195125857808, 0.0053868409343602484, 0.0053609473969957917, 0.0053357388675043674, 0.0053109456270035091, 0.0052860451820948354, 0.0052610971179896078, 0.0052361829953165972, 0.0052118817117050098, 0.0051882607798679984, 0.0051651169912098772, 0.0051426330436813517, 0.0051209778903088567, 0.0051001230662530176, 0.0050800160493560407, 0.0050606279387247956, 0.0050419107680458762, 0.0050237788898225381, 0.0050061997884137547, 0.0049891652337835475, 0.004972630633162208, 0.0049565718206894226, 0.0049409745591442846, 0.0049258226369751903, 0.0049110803935126729, 0.0048966690312306936, 0.0048824957180624217, 0.0048685851959861214, 0.0048549334152003911, 0.0048415573602820063, 0.0048284757569934328, 0.0048156969058457122, 0.0048032425470536794, 0.004791105824473633, 0.0047792751699634838, 0.0047677408990602129, 0.0047564776143903002, 0.0047454445247222992, 0.0047346271096204151, 0.0047239999724541749, 0.0047135407682263597, 0.0047032330375509062, 0.004693030638807048, 0.0046829017943128661, 0.0046727952885857477, 0.0046626311945552343, 0.0046522721674051391, 0.0046416177400982828, 0.0046306399992498293, 0.0046194440989175628, 0.0046081768087146511, 0.0045969472812586757, 0.0045857836998316887, 0.0045746428089755231, 0.0045635134801456055, 0.0045523506087277645, 0.0045412383108578485, 0.0045302349621823513, 0.0045194048163284088, 0.0045087594498116699, 0.0044982844600834643, 0.0044879913595288435, 0.0044778758635152533, 0.0044679132711320175, 0.0044581050391496327, 0.0044485055112748759, 0.0044391605003020274, 0.0044300759978692077]}
[2017-09-18 07:44:35,280 AE_UNIGRAMA_1L_OVER_F1_2.py:102]: done!
[2017-09-18 07:44:35,280 AE_UNIGRAMA_1L_OVER_F1_2.py:161]: >> Executing classifier part ... 
[2017-09-18 07:44:35,280 AE_UNIGRAMA_1L_OVER_F1_2.py:107]: =======================================
[2017-09-18 07:44:35,280 AE_UNIGRAMA_1L_OVER_F1_2.py:111]: setting configurations for classifier: 
	 {'optimizer': <keras.optimizers.SGD object at 0x0000000001A01630>, 'activation': 'sigmoid', 'use_last_dim_as_classifier': False, 'classifier_dim': 9, 'loss_function': 'categorical_crossentropy'}
[2017-09-18 07:44:35,437 AE_UNIGRAMA_1L_OVER_F1_2.py:120]: training ... 
[2017-09-18 07:44:36,770 summary.py:93]: Summary name enc0_115/kernel:0 is illegal; using enc0_115/kernel_0 instead.
[2017-09-18 07:44:36,770 summary.py:93]: Summary name enc0_115/bias:0 is illegal; using enc0_115/bias_0 instead.
[2017-09-18 07:44:36,785 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-09-18 07:44:36,801 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-09-18 07:48:30,594 AE_UNIGRAMA_1L_OVER_F1_2.py:132]: trained!
[2017-09-18 07:48:30,594 AE_UNIGRAMA_1L_OVER_F1_2.py:135]: Training history: 
{'val_loss': [0.0099117025001900731, 0.0095980112214642203, 0.0090738193356856098, 0.0085641373590987554, 0.0081333248435873206, 0.0077758400621579238, 0.0074780350634865858, 0.0072285380393803363, 0.0070183679394051571, 0.0068396917682583278, 0.0066869404792952673, 0.0065556575639330152, 0.0064422683117761302, 0.0063434277663882909, 0.0062563678754397074, 0.0061789544655892481, 0.0061093933250719479, 0.0060463503412306798, 0.0059882689467455012, 0.0059296855339674341, 0.0058742683537089451, 0.0058220187488748926, 0.0057732525861930572, 0.0057277565036319509, 0.0056851757207706721, 0.0056450151588845806, 0.0056067303936135808, 0.0055702439289764582, 0.0055356324907564767, 0.005502786496667844, 0.0054715111739940337, 0.0054415480498305269, 0.0054125683217862873, 0.0053843188575150303, 0.0053569726724326831, 0.005330561087523251, 0.005304921876730857, 0.0052798786001209443, 0.0052549614303549208, 0.0052299170387934144, 0.0052048313463615367, 0.0051801395279932761, 0.0051561918859915979, 0.0051327726179244424, 0.0051098918455499895, 0.0050878071366340051, 0.0050665724710915591, 0.0050461022943143283, 0.005026355725057623, 0.0050073133571739478, 0.004988870649276461, 0.0049709856104740964, 0.0049536265432834625, 0.0049367891457712211, 0.0049204299669987966, 0.0049045409782878984, 0.004889095887745081, 0.0048740707914242624, 0.0048594288486892888, 0.0048450443433143827, 0.0048309084282484958, 0.0048170447643388998, 0.004803456488937873, 0.0047901345693972816, 0.0047770931030521272, 0.004764363950221789, 0.0047519619198251092, 0.0047398769868813653, 0.0047281031618842864, 0.0047166089214814447, 0.0047053684393979006, 0.0046943431472931518, 0.0046835132898165217, 0.0046728663614125174, 0.0046623829525537057, 0.0046520338143290147, 0.0046417644238513607, 0.0046315452613012479, 0.0046213055881769152, 0.0046109187781936713, 0.004600306509253636, 0.0045894279772089232, 0.0045782801084126631, 0.0045669740148077597, 0.0045557072731754918, 0.0045444632580302563, 0.0045332613559244681, 0.0045220816940225277, 0.0045108974914951951, 0.0044997059293888789, 0.0044885934181206778, 0.0044776136033341032, 0.0044668062055005647, 0.004456163951165314, 0.0044457089351948786, 0.0044354496017431798, 0.0044253750935519297, 0.0044154473466186681, 0.0044057073004599226, 0.0043962131870379315, 0.0043869878570417416, 0.0043780333350540218], 'loss': [0.0099982424694379443, 0.0097816835797850353, 0.0093427979707081388, 0.0088222641053165886, 0.0083547523755059371, 0.0079653201922198161, 0.0076418114524635086, 0.007371765500472062, 0.0071450531266870213, 0.0069534559883346466, 0.0067902967140373019, 0.0066505344465696854, 0.006530286704741187, 0.0064260937016065445, 0.0063348669625980601, 0.0062542184020185805, 0.006182176228788706, 0.006117235830645152, 0.006058094197969024, 0.0060005742405284373, 0.0059440410383890686, 0.0058904761579735921, 0.0058401114574497615, 0.0057930446682447328, 0.0057490201932390112, 0.0057076867212561633, 0.0056685302073893424, 0.0056311656370904416, 0.0055956636630712011, 0.0055619774623947181, 0.0055299398626016925, 0.0054993401941131953, 0.0054699380939699019, 0.0054413776856628649, 0.0054136195125857808, 0.0053868409343602484, 0.0053609473969957917, 0.0053357388675043674, 0.0053109456270035091, 0.0052860451820948354, 0.0052610971179896078, 0.0052361829953165972, 0.0052118817117050098, 0.0051882607798679984, 0.0051651169912098772, 0.0051426330436813517, 0.0051209778903088567, 0.0051001230662530176, 0.0050800160493560407, 0.0050606279387247956, 0.0050419107680458762, 0.0050237788898225381, 0.0050061997884137547, 0.0049891652337835475, 0.004972630633162208, 0.0049565718206894226, 0.0049409745591442846, 0.0049258226369751903, 0.0049110803935126729, 0.0048966690312306936, 0.0048824957180624217, 0.0048685851959861214, 0.0048549334152003911, 0.0048415573602820063, 0.0048284757569934328, 0.0048156969058457122, 0.0048032425470536794, 0.004791105824473633, 0.0047792751699634838, 0.0047677408990602129, 0.0047564776143903002, 0.0047454445247222992, 0.0047346271096204151, 0.0047239999724541749, 0.0047135407682263597, 0.0047032330375509062, 0.004693030638807048, 0.0046829017943128661, 0.0046727952885857477, 0.0046626311945552343, 0.0046522721674051391, 0.0046416177400982828, 0.0046306399992498293, 0.0046194440989175628, 0.0046081768087146511, 0.0045969472812586757, 0.0045857836998316887, 0.0045746428089755231, 0.0045635134801456055, 0.0045523506087277645, 0.0045412383108578485, 0.0045302349621823513, 0.0045194048163284088, 0.0045087594498116699, 0.0044982844600834643, 0.0044879913595288435, 0.0044778758635152533, 0.0044679132711320175, 0.0044581050391496327, 0.0044485055112748759, 0.0044391605003020274, 0.0044300759978692077]}
[2017-09-18 07:48:30,594 AE_UNIGRAMA_1L_OVER_F1_2.py:139]: evaluating model ... 
[2017-09-18 07:48:30,703 AE_UNIGRAMA_1L_OVER_F1_2.py:143]: evaluated! 
[2017-09-18 07:48:30,703 AE_UNIGRAMA_1L_OVER_F1_2.py:145]: generating reports ... 
[2017-09-18 07:48:31,535 AE_UNIGRAMA_1L_OVER_F1_2.py:148]: done!
[2017-09-18 07:48:31,535 AE_UNIGRAMA_1L_OVER_F1_2.py:163]: >> experiment AE_UNIGRAMA_1L_OVER_F1_2 finished!

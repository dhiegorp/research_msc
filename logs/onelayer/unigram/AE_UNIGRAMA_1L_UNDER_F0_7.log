[2017-09-18 07:42:53,166 AE_UNIGRAMA_1L_UNDER_F0_7.py:154]: >> Initializing execution of experiment AE_UNIGRAMA_1L_UNDER_F0_7
[2017-09-18 07:42:53,167 AE_UNIGRAMA_1L_UNDER_F0_7.py:155]: >> Printing header log
[2017-09-18 07:42:53,167 AE_UNIGRAMA_1L_UNDER_F0_7.py:47]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_UNDER_F0_7
	layers = 96,67
	using GLOBAL obj = 
		{'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'executed_dir': 'E:/research/research_msc/executed/onelayer/unigram/', 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'autoencoder_configs': {'output_layer_activation': 'relu', 'hidden_layer_activation': 'relu', 'discard_decoder_function': True, 'optimizer': <keras.optimizers.SGD object at 0x00000000019EC588>, 'loss_function': 'mse'}, 'batch': 32, 'store_history': True, 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram.pkl', 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'numpy_seed': 666, 'mlp_configs': {'classifier_dim': 9, 'activation': 'sigmoid', 'use_last_dim_as_classifier': False, 'optimizer': <keras.optimizers.SGD object at 0x00000000019EE400>, 'loss_function': 'categorical_crossentropy'}, 'shuffle_batches': True, 'epochs': 1000}
	=======================================
	
[2017-09-18 07:42:53,167 AE_UNIGRAMA_1L_UNDER_F0_7.py:157]: >> Loading dataset... 
[2017-09-18 07:42:53,192 AE_UNIGRAMA_1L_UNDER_F0_7.py:63]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram.pkl	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-09-18 07:42:53,192 AE_UNIGRAMA_1L_UNDER_F0_7.py:159]: >> Executing autoencoder part ... 
[2017-09-18 07:42:53,192 AE_UNIGRAMA_1L_UNDER_F0_7.py:68]: =======================================
[2017-09-18 07:42:53,192 AE_UNIGRAMA_1L_UNDER_F0_7.py:73]: setting configurations for autoencoder: 
	 {'output_layer_activation': 'relu', 'hidden_layer_activation': 'relu', 'discard_decoder_function': True, 'optimizer': <keras.optimizers.SGD object at 0x00000000019EC588>, 'loss_function': 'mse'}
[2017-09-18 07:42:53,313 AE_UNIGRAMA_1L_UNDER_F0_7.py:84]: training and evaluate autoencoder
[2017-09-18 07:42:53,911 summary.py:93]: Summary name enc0_67/kernel:0 is illegal; using enc0_67/kernel_0 instead.
[2017-09-18 07:42:53,915 summary.py:93]: Summary name enc0_67/bias:0 is illegal; using enc0_67/bias_0 instead.
[2017-09-18 07:42:53,920 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-09-18 07:42:53,924 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-09-18 07:44:03,873 AE_UNIGRAMA_1L_UNDER_F0_7.py:95]: trained and evaluated!
[2017-09-18 07:44:03,873 AE_UNIGRAMA_1L_UNDER_F0_7.py:98]: Training history: 
{'val_loss': [0.009205870204377551, 0.0087391110582058801, 0.0083539769127389963, 0.0080336907629343958, 0.0077668114822701537, 0.0075430800295950015, 0.0073534554744721864, 0.0071918121930957934, 0.0070539827767289965, 0.0069358301215840367, 0.0068338113879385853, 0.0067441292996670626, 0.006665175223263725, 0.0065955597029718916, 0.0065339905109211326, 0.0064790523029146429, 0.0064297293104746134, 0.0063843152955385283, 0.0063390082543464607, 0.0062963730364336947, 0.0062571831935046684, 0.006220989753976492, 0.0061872624703167836, 0.0061555853206287821, 0.0061255751537225489, 0.0060969521651795429, 0.0060695575941073377, 0.0060433462478298502, 0.0060182966186484617, 0.0059942256389558862, 0.0059707914170176232, 0.0059472570957863095, 0.0059239648164272889, 0.0059013173301751803, 0.0058791889681233363, 0.0058573557500163067, 0.005835392450515382, 0.0058136336116591872, 0.0057919673746241584, 0.0057697775029262079, 0.0057449325993937771, 0.0057189722913558684, 0.0056941413940284754, 0.0056709301179135958, 0.005649285175598328, 0.0056289656116678159, 0.0056097385187238698, 0.0055914282852161552, 0.0055738560929319428, 0.0055568833563830024, 0.0055404020007357455, 0.0055243129879975527, 0.0055086230747066287, 0.0054933286467255616, 0.005478422661034342, 0.0054638666804682759, 0.0054496580113453852, 0.0054357920320501274, 0.005422262957754987, 0.0054090321372895992, 0.0053960967511869629, 0.0053834161778158265, 0.0053709766551823471, 0.0053587693688368996, 0.0053467676423432546, 0.0053349435699946877, 0.005323300006084393, 0.0053118160136525943, 0.0053004981924768416, 0.0052893495501882618, 0.0052783686142464092, 0.0052675388039605539, 0.0052568614681397499, 0.0052463315618633457, 0.0052359431282264952, 0.0052256988576595909, 0.0052155776618329893, 0.0052055754707883177, 0.0051956865927105227, 0.0051858996928288567, 0.0051762120527321749, 0.0051665980503536714, 0.0051570385948640869, 0.0051474838755656551, 0.0051379782653070416, 0.0051285806290828611, 0.0051193002887612339, 0.0051101149619960503, 0.0051010458168663699, 0.0050920779901176411, 0.0050832188602821689, 0.0050744698366656142, 0.0050658193091392646, 0.0050572741497581838, 0.0050488307822916011, 0.0050404851798218691, 0.0050322270696487818, 0.0050240496881319863, 0.0050159510221121474, 0.0050079216985514565, 0.0049999637727942952, 0.0049920707630614443], 'loss': [0.0095025898607035524, 0.0089898252522711657, 0.0085678418902322469, 0.0082184583164968267, 0.0079274901278761425, 0.0076846874706429751, 0.007480107410099278, 0.0073059760507919111, 0.0071574469151601105, 0.0070307140204402966, 0.0069218015431881325, 0.0068271010317346413, 0.0067436967419563986, 0.0066702761919397368, 0.0066054542947341522, 0.0065479337610327218, 0.0064964967706539417, 0.006449851315862707, 0.0064051981498211225, 0.0063610494682549102, 0.0063201594909503772, 0.0062824324282885107, 0.0062474484500094907, 0.0062147510316068813, 0.0061839448979801852, 0.0061547140722537173, 0.0061268078374062647, 0.0061001251495682316, 0.0060746104301473468, 0.0060501704113088105, 0.0060265590471051044, 0.0060032378776199912, 0.0059798685243947457, 0.0059570208804827531, 0.0059347681335833258, 0.0059128427972103261, 0.0058910211270881514, 0.0058691564168768693, 0.0058473885274039862, 0.0058255662136323999, 0.0058023345891495557, 0.0057770943910896789, 0.0057519989883694292, 0.0057283679769403349, 0.0057063277893575903, 0.0056857187786186758, 0.0056662816846725162, 0.005647825363134535, 0.0056301749193528993, 0.005613151670398029, 0.0055966744703752026, 0.0055806101429569611, 0.0055649168664212061, 0.005549612801843927, 0.0055346980107836381, 0.0055201395657231318, 0.0055058907638703466, 0.0054919799809562799, 0.0054783959022175685, 0.0054651358232521248, 0.0054521711545031434, 0.0054394933371081609, 0.005427060114148681, 0.0054148614529588406, 0.0054028740507549734, 0.0053910766376132823, 0.0053794481033077263, 0.0053679961372224945, 0.0053567065203698871, 0.0053455869487643503, 0.0053346243420506279, 0.0053238256555404985, 0.0053131771079575861, 0.0053026855904259162, 0.0052923364965449752, 0.0052821260781615066, 0.0052720504386273466, 0.0052620956550872523, 0.0052522498105104032, 0.0052425096925941108, 0.0052328720350219484, 0.005223313993869807, 0.0052138247649041666, 0.005204366042039903, 0.0051949362956308451, 0.0051855886406712744, 0.005176357089468577, 0.0051672382326985273, 0.0051582173802821865, 0.0051493081480824352, 0.0051404943339786379, 0.0051317838206041315, 0.0051231757464826775, 0.0051146610147292642, 0.0051062480177068671, 0.005097926949893106, 0.0050896996238632549, 0.0050815521766630197, 0.0050734777101380142, 0.0050654818828130693, 0.0050575481380773927, 0.0050496809555845672]}
[2017-09-18 07:44:03,873 AE_UNIGRAMA_1L_UNDER_F0_7.py:102]: done!
[2017-09-18 07:44:03,873 AE_UNIGRAMA_1L_UNDER_F0_7.py:161]: >> Executing classifier part ... 
[2017-09-18 07:44:03,873 AE_UNIGRAMA_1L_UNDER_F0_7.py:107]: =======================================
[2017-09-18 07:44:03,873 AE_UNIGRAMA_1L_UNDER_F0_7.py:111]: setting configurations for classifier: 
	 {'classifier_dim': 9, 'activation': 'sigmoid', 'use_last_dim_as_classifier': False, 'optimizer': <keras.optimizers.SGD object at 0x00000000019EE400>, 'loss_function': 'categorical_crossentropy'}
[2017-09-18 07:44:03,998 AE_UNIGRAMA_1L_UNDER_F0_7.py:120]: training ... 
[2017-09-18 07:44:04,877 summary.py:93]: Summary name enc0_67/kernel:0 is illegal; using enc0_67/kernel_0 instead.
[2017-09-18 07:44:04,877 summary.py:93]: Summary name enc0_67/bias:0 is illegal; using enc0_67/bias_0 instead.
[2017-09-18 07:44:04,877 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-09-18 07:44:04,892 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-09-18 07:47:39,103 AE_UNIGRAMA_1L_UNDER_F0_7.py:132]: trained!
[2017-09-18 07:47:39,104 AE_UNIGRAMA_1L_UNDER_F0_7.py:135]: Training history: 
{'val_loss': [0.009205870204377551, 0.0087391110582058801, 0.0083539769127389963, 0.0080336907629343958, 0.0077668114822701537, 0.0075430800295950015, 0.0073534554744721864, 0.0071918121930957934, 0.0070539827767289965, 0.0069358301215840367, 0.0068338113879385853, 0.0067441292996670626, 0.006665175223263725, 0.0065955597029718916, 0.0065339905109211326, 0.0064790523029146429, 0.0064297293104746134, 0.0063843152955385283, 0.0063390082543464607, 0.0062963730364336947, 0.0062571831935046684, 0.006220989753976492, 0.0061872624703167836, 0.0061555853206287821, 0.0061255751537225489, 0.0060969521651795429, 0.0060695575941073377, 0.0060433462478298502, 0.0060182966186484617, 0.0059942256389558862, 0.0059707914170176232, 0.0059472570957863095, 0.0059239648164272889, 0.0059013173301751803, 0.0058791889681233363, 0.0058573557500163067, 0.005835392450515382, 0.0058136336116591872, 0.0057919673746241584, 0.0057697775029262079, 0.0057449325993937771, 0.0057189722913558684, 0.0056941413940284754, 0.0056709301179135958, 0.005649285175598328, 0.0056289656116678159, 0.0056097385187238698, 0.0055914282852161552, 0.0055738560929319428, 0.0055568833563830024, 0.0055404020007357455, 0.0055243129879975527, 0.0055086230747066287, 0.0054933286467255616, 0.005478422661034342, 0.0054638666804682759, 0.0054496580113453852, 0.0054357920320501274, 0.005422262957754987, 0.0054090321372895992, 0.0053960967511869629, 0.0053834161778158265, 0.0053709766551823471, 0.0053587693688368996, 0.0053467676423432546, 0.0053349435699946877, 0.005323300006084393, 0.0053118160136525943, 0.0053004981924768416, 0.0052893495501882618, 0.0052783686142464092, 0.0052675388039605539, 0.0052568614681397499, 0.0052463315618633457, 0.0052359431282264952, 0.0052256988576595909, 0.0052155776618329893, 0.0052055754707883177, 0.0051956865927105227, 0.0051858996928288567, 0.0051762120527321749, 0.0051665980503536714, 0.0051570385948640869, 0.0051474838755656551, 0.0051379782653070416, 0.0051285806290828611, 0.0051193002887612339, 0.0051101149619960503, 0.0051010458168663699, 0.0050920779901176411, 0.0050832188602821689, 0.0050744698366656142, 0.0050658193091392646, 0.0050572741497581838, 0.0050488307822916011, 0.0050404851798218691, 0.0050322270696487818, 0.0050240496881319863, 0.0050159510221121474, 0.0050079216985514565, 0.0049999637727942952, 0.0049920707630614443], 'loss': [0.0095025898607035524, 0.0089898252522711657, 0.0085678418902322469, 0.0082184583164968267, 0.0079274901278761425, 0.0076846874706429751, 0.007480107410099278, 0.0073059760507919111, 0.0071574469151601105, 0.0070307140204402966, 0.0069218015431881325, 0.0068271010317346413, 0.0067436967419563986, 0.0066702761919397368, 0.0066054542947341522, 0.0065479337610327218, 0.0064964967706539417, 0.006449851315862707, 0.0064051981498211225, 0.0063610494682549102, 0.0063201594909503772, 0.0062824324282885107, 0.0062474484500094907, 0.0062147510316068813, 0.0061839448979801852, 0.0061547140722537173, 0.0061268078374062647, 0.0061001251495682316, 0.0060746104301473468, 0.0060501704113088105, 0.0060265590471051044, 0.0060032378776199912, 0.0059798685243947457, 0.0059570208804827531, 0.0059347681335833258, 0.0059128427972103261, 0.0058910211270881514, 0.0058691564168768693, 0.0058473885274039862, 0.0058255662136323999, 0.0058023345891495557, 0.0057770943910896789, 0.0057519989883694292, 0.0057283679769403349, 0.0057063277893575903, 0.0056857187786186758, 0.0056662816846725162, 0.005647825363134535, 0.0056301749193528993, 0.005613151670398029, 0.0055966744703752026, 0.0055806101429569611, 0.0055649168664212061, 0.005549612801843927, 0.0055346980107836381, 0.0055201395657231318, 0.0055058907638703466, 0.0054919799809562799, 0.0054783959022175685, 0.0054651358232521248, 0.0054521711545031434, 0.0054394933371081609, 0.005427060114148681, 0.0054148614529588406, 0.0054028740507549734, 0.0053910766376132823, 0.0053794481033077263, 0.0053679961372224945, 0.0053567065203698871, 0.0053455869487643503, 0.0053346243420506279, 0.0053238256555404985, 0.0053131771079575861, 0.0053026855904259162, 0.0052923364965449752, 0.0052821260781615066, 0.0052720504386273466, 0.0052620956550872523, 0.0052522498105104032, 0.0052425096925941108, 0.0052328720350219484, 0.005223313993869807, 0.0052138247649041666, 0.005204366042039903, 0.0051949362956308451, 0.0051855886406712744, 0.005176357089468577, 0.0051672382326985273, 0.0051582173802821865, 0.0051493081480824352, 0.0051404943339786379, 0.0051317838206041315, 0.0051231757464826775, 0.0051146610147292642, 0.0051062480177068671, 0.005097926949893106, 0.0050896996238632549, 0.0050815521766630197, 0.0050734777101380142, 0.0050654818828130693, 0.0050575481380773927, 0.0050496809555845672]}
[2017-09-18 07:47:39,104 AE_UNIGRAMA_1L_UNDER_F0_7.py:139]: evaluating model ... 
[2017-09-18 07:47:39,199 AE_UNIGRAMA_1L_UNDER_F0_7.py:143]: evaluated! 
[2017-09-18 07:47:39,199 AE_UNIGRAMA_1L_UNDER_F0_7.py:145]: generating reports ... 
[2017-09-18 07:47:40,542 AE_UNIGRAMA_1L_UNDER_F0_7.py:148]: done!
[2017-09-18 07:47:40,542 AE_UNIGRAMA_1L_UNDER_F0_7.py:163]: >> experiment AE_UNIGRAMA_1L_UNDER_F0_7 finished!

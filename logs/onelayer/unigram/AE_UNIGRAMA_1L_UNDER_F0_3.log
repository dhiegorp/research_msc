[2017-10-02 10:19:50,054 AE_UNIGRAMA_1L_UNDER_F0_3.py:157]: >> Initializing execution of experiment AE_UNIGRAMA_1L_UNDER_F0_3
[2017-10-02 10:19:50,054 AE_UNIGRAMA_1L_UNDER_F0_3.py:158]: >> Printing header log
[2017-10-02 10:19:50,054 AE_UNIGRAMA_1L_UNDER_F0_3.py:48]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_UNDER_F0_3
	layers = 96,28
	using GLOBAL obj = 
		{'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'store_history': True, 'epochs': 200, 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'mlp_configs': {'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x0000000001950358>, 'activation': 'sigmoid', 'classifier_dim': 9}, 'autoencoder_configs': {'output_layer_activation': 'relu', 'loss_function': 'mse', 'discard_decoder_function': True, 'optimizer': <keras.optimizers.SGD object at 0x000000000174E4E0>, 'hidden_layer_activation': 'relu'}, 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram_mini.pkl', 'numpy_seed': 666, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'batch': 32, 'executed_path': 'E:/research/research_msc/executed/onelayer/unigram/', 'shuffle_batches': True, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s'}
	=======================================
	
[2017-10-02 10:19:50,054 AE_UNIGRAMA_1L_UNDER_F0_3.py:160]: >> Loading dataset... 
[2017-10-02 10:19:50,059 AE_UNIGRAMA_1L_UNDER_F0_3.py:64]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram_mini.pkl	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-02 10:19:50,059 AE_UNIGRAMA_1L_UNDER_F0_3.py:162]: >> Executing autoencoder part ... 
[2017-10-02 10:19:50,059 AE_UNIGRAMA_1L_UNDER_F0_3.py:69]: =======================================
[2017-10-02 10:19:50,059 AE_UNIGRAMA_1L_UNDER_F0_3.py:74]: setting configurations for autoencoder: 
	 {'output_layer_activation': 'relu', 'loss_function': 'mse', 'discard_decoder_function': True, 'optimizer': <keras.optimizers.SGD object at 0x000000000174E4E0>, 'hidden_layer_activation': 'relu'}
[2017-10-02 10:19:50,115 AE_UNIGRAMA_1L_UNDER_F0_3.py:85]: training and evaluate autoencoder
[2017-10-02 10:19:50,470 summary.py:93]: Summary name enc0_28/kernel:0 is illegal; using enc0_28/kernel_0 instead.
[2017-10-02 10:19:50,472 summary.py:93]: Summary name enc0_28/bias:0 is illegal; using enc0_28/bias_0 instead.
[2017-10-02 10:19:50,475 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-10-02 10:19:50,477 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-10-02 10:20:00,623 AE_UNIGRAMA_1L_UNDER_F0_3.py:96]: trained and evaluated!
[2017-10-02 10:20:00,623 AE_UNIGRAMA_1L_UNDER_F0_3.py:99]: Training history: 
{'loss': [0.0090799565153962345, 0.0090064654572103824, 0.0089337515278954636, 0.008861454617009986, 0.0087896445371123573, 0.0087189111708633072, 0.0086495332252726504, 0.0085816006963247166, 0.0085150958471041406, 0.0084498068283425931, 0.0083858001989798453, 0.0083231659429794675, 0.0082619709953592468, 0.0082021386751283433, 0.0081436771850233874, 0.0080865789479596089, 0.0080307981665644016, 0.0079763482382593162, 0.0079232379381980501, 0.0078714477569757791, 0.0078209136768983192, 0.0077716877160807947, 0.0077237165186693863, 0.0076769074798889629, 0.0076311934057030125, 0.0075866211344245834, 0.0075431040224299226, 0.0075006494796580163, 0.0074592722979383965, 0.0074189105468957283, 0.0073795268691609116, 0.007341078082448731, 0.0073035506845853153, 0.0072669187691188622, 0.0072311448478829697, 0.0071962172352693417, 0.0071621189382185986, 0.0071288202325432816, 0.00709629925906649, 0.0070645456679151626, 0.0070335679543310501, 0.0070032764766559908, 0.0069736677056525332, 0.0069448008006249718, 0.0069165439264804182, 0.0068889298655445321, 0.0068618991725906938, 0.0068354705075567932, 0.0068096389465111861, 0.0067843478001292376, 0.0067596047874551538, 0.0067353867822668454, 0.0067116432201023398, 0.0066883906455322429, 0.0066655902429549659, 0.0066432437362045176, 0.00662132750277321, 0.0065998548324681825, 0.0065787594617168705, 0.0065580242039829251, 0.0065376670008208135, 0.0065177141739709218, 0.0064981403478982808, 0.0064789817651897466, 0.0064601994928982298, 0.0064417772898341732, 0.0064236923969810409, 0.0064059670644765919, 0.0063886050362146809, 0.0063715890005858269, 0.0063549043486477519, 0.0063385950697937401, 0.0063226194705953793, 0.0063070020602343999, 0.0062917021504467667, 0.0062767167872741824, 0.0062620459160508193, 0.0062477043801237447, 0.0062336863525733859, 0.0062199653616860813, 0.0062065074528260102, 0.0061933204532242034, 0.0061804021899854577, 0.0061677622330645766, 0.0061553818775889292, 0.0061432838473714016, 0.0061314350277982248, 0.0061198408373693931, 0.0061084843001980391, 0.0060973570000359672, 0.0060864632895425846, 0.0060757904069655023, 0.0060653442544971389, 0.0060551051192384011, 0.0060450812949402319, 0.0060352573460901015, 0.0060256262571443866, 0.0060161887358967962, 0.0060069497057065576, 0.0059978821479155014, 0.0059889972361048529, 0.0059802769328402864], 'val_loss': [0.0090275411476765429, 0.0089553458664607833, 0.0088836517752767935, 0.008812201870639972, 0.008741592877582546, 0.008672068331764534, 0.0086038120326388731, 0.0085369567057900272, 0.0084713416894184618, 0.0084071763406843494, 0.0083441963405469534, 0.0082827112239311183, 0.0082226310610826574, 0.0081638689377937172, 0.0081065367599152949, 0.0080505220486079675, 0.007995826438013949, 0.0079424551698521161, 0.0078904208481367193, 0.0078396511516883472, 0.0077901691714211685, 0.0077419674169396822, 0.0076949449453405953, 0.0076490329876265119, 0.0076042638371480445, 0.0075605464476025683, 0.0075178612889133418, 0.0074762617892215246, 0.0074356766417622566, 0.0073960787810551411, 0.0073574362045714849, 0.0073197224769450476, 0.007282902036540792, 0.0072469860903891046, 0.0072119185704474778, 0.0071776640189458443, 0.0071442346365561491, 0.0071115808312168351, 0.007079721324588951, 0.0070486500146054428, 0.0070182808404823001, 0.0069885584058371622, 0.0069595763241685231, 0.0069311881095143277, 0.0069034469788236243, 0.0068763167438093834, 0.0068497677267871822, 0.006823820297408946, 0.0067984094673622271, 0.0067735514534311885, 0.0067492227994431792, 0.0067253561905103992, 0.0067019979244437363, 0.0066790865218356865, 0.0066566392225403765, 0.006634612867200131, 0.0066130255889078277, 0.0065918361324969277, 0.0065710505671439118, 0.006550646664013871, 0.0065306692927743423, 0.0065110729380638849, 0.0064918736626002867, 0.0064730826699517692, 0.0064546508769951346, 0.0064365616964944901, 0.0064188193367122493, 0.0064014497067654665, 0.006384436955128461, 0.0063677711730829849, 0.0063514495078044976, 0.0063354663921305456, 0.0063198262160872442, 0.0063045141062107232, 0.006289503966426982, 0.0062748079749038897, 0.0062604483812493464, 0.0062463951563691122, 0.0062326606480771728, 0.0062192133870183535, 0.0062060352539484382, 0.0061931257070384944, 0.0061804785195835018, 0.0061680910499510265, 0.0061559875125280104, 0.0061441273099593959, 0.0061325286324637974, 0.0061211721299970906, 0.0061100546017870804, 0.0060991698038179191, 0.0060885130812078159, 0.0060780777814053695, 0.0060678614410796796, 0.0060578617907811275, 0.0060480730054159144, 0.0060384741302261123, 0.0060290710266582585, 0.0060198610201893463, 0.0060108216275152884, 0.0060019558347540053, 0.0059932620700822664, 0.0059847360871538354]}
[2017-10-02 10:20:00,623 AE_UNIGRAMA_1L_UNDER_F0_3.py:103]: done!
[2017-10-02 10:20:00,623 AE_UNIGRAMA_1L_UNDER_F0_3.py:164]: >> Executing classifier part ... 
[2017-10-02 10:20:00,623 AE_UNIGRAMA_1L_UNDER_F0_3.py:108]: =======================================
[2017-10-02 10:20:00,624 AE_UNIGRAMA_1L_UNDER_F0_3.py:112]: setting configurations for classifier: 
	 {'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x0000000001950358>, 'activation': 'sigmoid', 'classifier_dim': 9}
[2017-10-02 10:20:00,678 AE_UNIGRAMA_1L_UNDER_F0_3.py:121]: training ... 
[2017-10-02 10:20:01,078 summary.py:93]: Summary name enc0_28/kernel:0 is illegal; using enc0_28/kernel_0 instead.
[2017-10-02 10:20:01,080 summary.py:93]: Summary name enc0_28/bias:0 is illegal; using enc0_28/bias_0 instead.
[2017-10-02 10:20:01,083 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-10-02 10:20:01,085 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-10-02 10:20:22,821 AE_UNIGRAMA_1L_UNDER_F0_3.py:133]: trained!
[2017-10-02 10:20:22,822 AE_UNIGRAMA_1L_UNDER_F0_3.py:136]: Training history: 
{'loss': [0.0090799565153962345, 0.0090064654572103824, 0.0089337515278954636, 0.008861454617009986, 0.0087896445371123573, 0.0087189111708633072, 0.0086495332252726504, 0.0085816006963247166, 0.0085150958471041406, 0.0084498068283425931, 0.0083858001989798453, 0.0083231659429794675, 0.0082619709953592468, 0.0082021386751283433, 0.0081436771850233874, 0.0080865789479596089, 0.0080307981665644016, 0.0079763482382593162, 0.0079232379381980501, 0.0078714477569757791, 0.0078209136768983192, 0.0077716877160807947, 0.0077237165186693863, 0.0076769074798889629, 0.0076311934057030125, 0.0075866211344245834, 0.0075431040224299226, 0.0075006494796580163, 0.0074592722979383965, 0.0074189105468957283, 0.0073795268691609116, 0.007341078082448731, 0.0073035506845853153, 0.0072669187691188622, 0.0072311448478829697, 0.0071962172352693417, 0.0071621189382185986, 0.0071288202325432816, 0.00709629925906649, 0.0070645456679151626, 0.0070335679543310501, 0.0070032764766559908, 0.0069736677056525332, 0.0069448008006249718, 0.0069165439264804182, 0.0068889298655445321, 0.0068618991725906938, 0.0068354705075567932, 0.0068096389465111861, 0.0067843478001292376, 0.0067596047874551538, 0.0067353867822668454, 0.0067116432201023398, 0.0066883906455322429, 0.0066655902429549659, 0.0066432437362045176, 0.00662132750277321, 0.0065998548324681825, 0.0065787594617168705, 0.0065580242039829251, 0.0065376670008208135, 0.0065177141739709218, 0.0064981403478982808, 0.0064789817651897466, 0.0064601994928982298, 0.0064417772898341732, 0.0064236923969810409, 0.0064059670644765919, 0.0063886050362146809, 0.0063715890005858269, 0.0063549043486477519, 0.0063385950697937401, 0.0063226194705953793, 0.0063070020602343999, 0.0062917021504467667, 0.0062767167872741824, 0.0062620459160508193, 0.0062477043801237447, 0.0062336863525733859, 0.0062199653616860813, 0.0062065074528260102, 0.0061933204532242034, 0.0061804021899854577, 0.0061677622330645766, 0.0061553818775889292, 0.0061432838473714016, 0.0061314350277982248, 0.0061198408373693931, 0.0061084843001980391, 0.0060973570000359672, 0.0060864632895425846, 0.0060757904069655023, 0.0060653442544971389, 0.0060551051192384011, 0.0060450812949402319, 0.0060352573460901015, 0.0060256262571443866, 0.0060161887358967962, 0.0060069497057065576, 0.0059978821479155014, 0.0059889972361048529, 0.0059802769328402864], 'val_loss': [0.0090275411476765429, 0.0089553458664607833, 0.0088836517752767935, 0.008812201870639972, 0.008741592877582546, 0.008672068331764534, 0.0086038120326388731, 0.0085369567057900272, 0.0084713416894184618, 0.0084071763406843494, 0.0083441963405469534, 0.0082827112239311183, 0.0082226310610826574, 0.0081638689377937172, 0.0081065367599152949, 0.0080505220486079675, 0.007995826438013949, 0.0079424551698521161, 0.0078904208481367193, 0.0078396511516883472, 0.0077901691714211685, 0.0077419674169396822, 0.0076949449453405953, 0.0076490329876265119, 0.0076042638371480445, 0.0075605464476025683, 0.0075178612889133418, 0.0074762617892215246, 0.0074356766417622566, 0.0073960787810551411, 0.0073574362045714849, 0.0073197224769450476, 0.007282902036540792, 0.0072469860903891046, 0.0072119185704474778, 0.0071776640189458443, 0.0071442346365561491, 0.0071115808312168351, 0.007079721324588951, 0.0070486500146054428, 0.0070182808404823001, 0.0069885584058371622, 0.0069595763241685231, 0.0069311881095143277, 0.0069034469788236243, 0.0068763167438093834, 0.0068497677267871822, 0.006823820297408946, 0.0067984094673622271, 0.0067735514534311885, 0.0067492227994431792, 0.0067253561905103992, 0.0067019979244437363, 0.0066790865218356865, 0.0066566392225403765, 0.006634612867200131, 0.0066130255889078277, 0.0065918361324969277, 0.0065710505671439118, 0.006550646664013871, 0.0065306692927743423, 0.0065110729380638849, 0.0064918736626002867, 0.0064730826699517692, 0.0064546508769951346, 0.0064365616964944901, 0.0064188193367122493, 0.0064014497067654665, 0.006384436955128461, 0.0063677711730829849, 0.0063514495078044976, 0.0063354663921305456, 0.0063198262160872442, 0.0063045141062107232, 0.006289503966426982, 0.0062748079749038897, 0.0062604483812493464, 0.0062463951563691122, 0.0062326606480771728, 0.0062192133870183535, 0.0062060352539484382, 0.0061931257070384944, 0.0061804785195835018, 0.0061680910499510265, 0.0061559875125280104, 0.0061441273099593959, 0.0061325286324637974, 0.0061211721299970906, 0.0061100546017870804, 0.0060991698038179191, 0.0060885130812078159, 0.0060780777814053695, 0.0060678614410796796, 0.0060578617907811275, 0.0060480730054159144, 0.0060384741302261123, 0.0060290710266582585, 0.0060198610201893463, 0.0060108216275152884, 0.0060019558347540053, 0.0059932620700822664, 0.0059847360871538354]}
[2017-10-02 10:20:22,822 AE_UNIGRAMA_1L_UNDER_F0_3.py:140]: evaluating model ... 
[2017-10-02 10:20:22,843 AE_UNIGRAMA_1L_UNDER_F0_3.py:144]: evaluated! 
[2017-10-02 10:20:22,843 AE_UNIGRAMA_1L_UNDER_F0_3.py:146]: generating reports ... 
[2017-10-02 10:20:23,309 AE_UNIGRAMA_1L_UNDER_F0_3.py:149]: done!
[2017-10-02 10:20:23,309 AE_UNIGRAMA_1L_UNDER_F0_3.py:166]: >> experiment AE_UNIGRAMA_1L_UNDER_F0_3 finished!

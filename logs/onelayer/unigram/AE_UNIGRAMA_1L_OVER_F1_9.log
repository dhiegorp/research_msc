[2017-10-02 10:16:16,845 AE_UNIGRAMA_1L_OVER_F1_9.py:156]: >> Initializing execution of experiment AE_UNIGRAMA_1L_OVER_F1_9
[2017-10-02 10:16:16,845 AE_UNIGRAMA_1L_OVER_F1_9.py:157]: >> Printing header log
[2017-10-02 10:16:16,845 AE_UNIGRAMA_1L_OVER_F1_9.py:48]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_OVER_F1_9
	layers = 96,182
	using GLOBAL obj = 
		{'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'batch': 32, 'shuffle_batches': True, 'mlp_configs': {'classifier_dim': 9, 'optimizer': <keras.optimizers.SGD object at 0x0000000001900390>, 'use_last_dim_as_classifier': False, 'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy'}, 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'executed_path': 'E:/research/research_msc/executed/onelayer/unigram/', 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram_mini.pkl', 'epochs': 200, 'store_history': True, 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'autoencoder_configs': {'discard_decoder_function': True, 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x00000000018FE518>, 'loss_function': 'mse'}}
	=======================================
	
[2017-10-02 10:16:16,845 AE_UNIGRAMA_1L_OVER_F1_9.py:159]: >> Loading dataset... 
[2017-10-02 10:16:16,850 AE_UNIGRAMA_1L_OVER_F1_9.py:64]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram_mini.pkl	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-02 10:16:16,851 AE_UNIGRAMA_1L_OVER_F1_9.py:161]: >> Executing autoencoder part ... 
[2017-10-02 10:16:16,851 AE_UNIGRAMA_1L_OVER_F1_9.py:69]: =======================================
[2017-10-02 10:16:16,851 AE_UNIGRAMA_1L_OVER_F1_9.py:74]: setting configurations for autoencoder: 
	 {'discard_decoder_function': True, 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x00000000018FE518>, 'loss_function': 'mse'}
[2017-10-02 10:16:16,907 AE_UNIGRAMA_1L_OVER_F1_9.py:85]: training and evaluate autoencoder
[2017-10-02 10:16:17,262 summary.py:93]: Summary name enc0_182/kernel:0 is illegal; using enc0_182/kernel_0 instead.
[2017-10-02 10:16:17,263 summary.py:93]: Summary name enc0_182/bias:0 is illegal; using enc0_182/bias_0 instead.
[2017-10-02 10:16:17,267 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-10-02 10:16:17,268 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-10-02 10:16:29,341 AE_UNIGRAMA_1L_OVER_F1_9.py:96]: trained and evaluated!
[2017-10-02 10:16:29,342 AE_UNIGRAMA_1L_OVER_F1_9.py:99]: Training history: 
{'val_loss': [0.0098674552009672921, 0.0096976546896102266, 0.009533245576940283, 0.0093751098392842874, 0.0092232904732781271, 0.0090776983766252227, 0.0089385527563471782, 0.0088057149457831801, 0.0086788347641830101, 0.0085577516432256053, 0.0084422585107801571, 0.0083320986541839774, 0.0082271250421839127, 0.008127081614735512, 0.0080315728263313218, 0.0079403966353673028, 0.0078533390713474791, 0.007770264277158506, 0.0076908691609659163, 0.007615052637917623, 0.007542694453150034, 0.0074735185941577397, 0.0074073667724557967, 0.0073440677025892031, 0.0072835860514258582, 0.0072257288170763769, 0.0071703414242285336, 0.0071173201273558974, 0.0070664851777394021, 0.0070177902152491764, 0.0069710371503433326, 0.0069261690840595937, 0.0068831002689399463, 0.0068416773379679947, 0.0068018956172200386, 0.0067636778952076086, 0.006726951861137794, 0.0066916051573469738, 0.0066576299004838368, 0.0066249499229028763, 0.0065934872739432469, 0.0065632056631840293, 0.0065339657072961107, 0.0065058348163768483, 0.0064787216983098524, 0.006452573513522135, 0.0064273300203304311, 0.006403005147027371, 0.0063795228644540763, 0.0063568586552841073, 0.0063349861222350467, 0.0063138620747897264, 0.0062934451435301382, 0.0062737043091826497, 0.0062545968243873035, 0.0062361026985993176, 0.0062181993896577884, 0.0062008400994688828, 0.0061840471486149006, 0.0061677873833970512, 0.0061520082048628633, 0.0061367218725410979, 0.0061218875034480293, 0.0061074759842322437, 0.0060935010856578344, 0.0060799261935913871, 0.0060667329741344129, 0.0060538836325549948, 0.0060413961530728852, 0.0060292379792128798, 0.0060174230133013653, 0.0060058937245308242, 0.005994666558188355, 0.005983721530653509, 0.005973049107121934, 0.0059626383281080921, 0.0059524856847070406, 0.0059425678661570898, 0.0059328789677346285, 0.0059234298502534736, 0.0059141932785871081, 0.0059051577912359651, 0.0058963232566377486, 0.0058876631684518215, 0.0058791903540021204, 0.0058708992340086117, 0.0058627702178066544, 0.0058547973296982428, 0.0058469873555281569, 0.0058393210404618298, 0.0058317859103162268, 0.005824382958732905, 0.0058171192294879919, 0.0058099794890523844, 0.005802957302991121, 0.0057960516170747437, 0.0057892481239034781, 0.0057825462124050774, 0.0057759410303543047, 0.0057694188675749703, 0.0057629873616046176, 0.0057566402078394995], 'loss': [0.009974548124926326, 0.0098003619719701958, 0.0096292496311404466, 0.0094646894760526019, 0.0093067842092051344, 0.0091555422245219731, 0.0090109327482889596, 0.0088726637865512298, 0.0087406899380487908, 0.008614624306083311, 0.008494320125207443, 0.0083796489994100581, 0.0082702461478987872, 0.008165915624868781, 0.0080664552577622995, 0.0079714666099528556, 0.0078807828410402091, 0.0077941526012574158, 0.0077114457999526102, 0.0076323562927347209, 0.0075568314753335425, 0.0074847028330289004, 0.0074157384687893839, 0.0073497850186298539, 0.0072866639093173632, 0.0072263313440769708, 0.0071686014264579299, 0.0071132970116940938, 0.007060338160024238, 0.0070095342685844572, 0.0069608480970649424, 0.0069140853628186488, 0.0068691654280217318, 0.006826002303036943, 0.0067844958048595486, 0.006744614733324673, 0.0067062747150146672, 0.0066694253294304539, 0.0066339749998579603, 0.0065998858125386941, 0.0065670752587036153, 0.006535448621358601, 0.0065049843198076562, 0.0064755655354611259, 0.0064472417340264154, 0.0064199390791393196, 0.006393607267073843, 0.0063682057855841967, 0.0063437346816085823, 0.0063200895013384977, 0.0062972638531649267, 0.0062752238062073577, 0.006253916340048374, 0.0062333318907435535, 0.0062134398128001617, 0.0061941706445514605, 0.0061755125552814252, 0.0061574553179004551, 0.0061399401984101399, 0.0061229948625861497, 0.0061065846053538842, 0.0060906777920839089, 0.0060752640399891833, 0.0060602883878722097, 0.0060457479962581096, 0.0060316378481974613, 0.006017933831193565, 0.0060046205228994837, 0.0059916612514155591, 0.0059790616381636373, 0.0059667848014532052, 0.0059548501570988958, 0.0059432198385666246, 0.005931886113360387, 0.0059208288140819351, 0.0059100619726771397, 0.0058995632379766289, 0.0058893133077905562, 0.0058793065784420052, 0.0058695187742954097, 0.0058599918460806562, 0.0058506621229883048, 0.0058415431146336501, 0.0058326236236801565, 0.0058238763942027759, 0.0058153263893099784, 0.0058069407923310792, 0.0057987266869273333, 0.0057906638713554693, 0.0057827722144982311, 0.0057750196893342851, 0.0057674051464501521, 0.0057599248803039231, 0.0057525811072944976, 0.0057453636498463502, 0.0057382711310102188, 0.0057312885191138164, 0.0057244081008371098, 0.0057176219831211071, 0.0057109365381126436, 0.0057043205507639992, 0.005697785617386408]}
[2017-10-02 10:16:29,342 AE_UNIGRAMA_1L_OVER_F1_9.py:103]: done!
[2017-10-02 10:16:29,342 AE_UNIGRAMA_1L_OVER_F1_9.py:163]: >> Executing classifier part ... 
[2017-10-02 10:16:29,342 AE_UNIGRAMA_1L_OVER_F1_9.py:108]: =======================================
[2017-10-02 10:16:29,342 AE_UNIGRAMA_1L_OVER_F1_9.py:112]: setting configurations for classifier: 
	 {'classifier_dim': 9, 'optimizer': <keras.optimizers.SGD object at 0x0000000001900390>, 'use_last_dim_as_classifier': False, 'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy'}
[2017-10-02 10:16:29,396 AE_UNIGRAMA_1L_OVER_F1_9.py:121]: training ... 
[2017-10-02 10:16:29,790 summary.py:93]: Summary name enc0_182/kernel:0 is illegal; using enc0_182/kernel_0 instead.
[2017-10-02 10:16:29,792 summary.py:93]: Summary name enc0_182/bias:0 is illegal; using enc0_182/bias_0 instead.
[2017-10-02 10:16:29,795 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-10-02 10:16:29,797 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-10-02 10:16:52,995 AE_UNIGRAMA_1L_OVER_F1_9.py:133]: trained!
[2017-10-02 10:16:52,995 AE_UNIGRAMA_1L_OVER_F1_9.py:136]: Training history: 
{'val_loss': [0.0098674552009672921, 0.0096976546896102266, 0.009533245576940283, 0.0093751098392842874, 0.0092232904732781271, 0.0090776983766252227, 0.0089385527563471782, 0.0088057149457831801, 0.0086788347641830101, 0.0085577516432256053, 0.0084422585107801571, 0.0083320986541839774, 0.0082271250421839127, 0.008127081614735512, 0.0080315728263313218, 0.0079403966353673028, 0.0078533390713474791, 0.007770264277158506, 0.0076908691609659163, 0.007615052637917623, 0.007542694453150034, 0.0074735185941577397, 0.0074073667724557967, 0.0073440677025892031, 0.0072835860514258582, 0.0072257288170763769, 0.0071703414242285336, 0.0071173201273558974, 0.0070664851777394021, 0.0070177902152491764, 0.0069710371503433326, 0.0069261690840595937, 0.0068831002689399463, 0.0068416773379679947, 0.0068018956172200386, 0.0067636778952076086, 0.006726951861137794, 0.0066916051573469738, 0.0066576299004838368, 0.0066249499229028763, 0.0065934872739432469, 0.0065632056631840293, 0.0065339657072961107, 0.0065058348163768483, 0.0064787216983098524, 0.006452573513522135, 0.0064273300203304311, 0.006403005147027371, 0.0063795228644540763, 0.0063568586552841073, 0.0063349861222350467, 0.0063138620747897264, 0.0062934451435301382, 0.0062737043091826497, 0.0062545968243873035, 0.0062361026985993176, 0.0062181993896577884, 0.0062008400994688828, 0.0061840471486149006, 0.0061677873833970512, 0.0061520082048628633, 0.0061367218725410979, 0.0061218875034480293, 0.0061074759842322437, 0.0060935010856578344, 0.0060799261935913871, 0.0060667329741344129, 0.0060538836325549948, 0.0060413961530728852, 0.0060292379792128798, 0.0060174230133013653, 0.0060058937245308242, 0.005994666558188355, 0.005983721530653509, 0.005973049107121934, 0.0059626383281080921, 0.0059524856847070406, 0.0059425678661570898, 0.0059328789677346285, 0.0059234298502534736, 0.0059141932785871081, 0.0059051577912359651, 0.0058963232566377486, 0.0058876631684518215, 0.0058791903540021204, 0.0058708992340086117, 0.0058627702178066544, 0.0058547973296982428, 0.0058469873555281569, 0.0058393210404618298, 0.0058317859103162268, 0.005824382958732905, 0.0058171192294879919, 0.0058099794890523844, 0.005802957302991121, 0.0057960516170747437, 0.0057892481239034781, 0.0057825462124050774, 0.0057759410303543047, 0.0057694188675749703, 0.0057629873616046176, 0.0057566402078394995], 'loss': [0.009974548124926326, 0.0098003619719701958, 0.0096292496311404466, 0.0094646894760526019, 0.0093067842092051344, 0.0091555422245219731, 0.0090109327482889596, 0.0088726637865512298, 0.0087406899380487908, 0.008614624306083311, 0.008494320125207443, 0.0083796489994100581, 0.0082702461478987872, 0.008165915624868781, 0.0080664552577622995, 0.0079714666099528556, 0.0078807828410402091, 0.0077941526012574158, 0.0077114457999526102, 0.0076323562927347209, 0.0075568314753335425, 0.0074847028330289004, 0.0074157384687893839, 0.0073497850186298539, 0.0072866639093173632, 0.0072263313440769708, 0.0071686014264579299, 0.0071132970116940938, 0.007060338160024238, 0.0070095342685844572, 0.0069608480970649424, 0.0069140853628186488, 0.0068691654280217318, 0.006826002303036943, 0.0067844958048595486, 0.006744614733324673, 0.0067062747150146672, 0.0066694253294304539, 0.0066339749998579603, 0.0065998858125386941, 0.0065670752587036153, 0.006535448621358601, 0.0065049843198076562, 0.0064755655354611259, 0.0064472417340264154, 0.0064199390791393196, 0.006393607267073843, 0.0063682057855841967, 0.0063437346816085823, 0.0063200895013384977, 0.0062972638531649267, 0.0062752238062073577, 0.006253916340048374, 0.0062333318907435535, 0.0062134398128001617, 0.0061941706445514605, 0.0061755125552814252, 0.0061574553179004551, 0.0061399401984101399, 0.0061229948625861497, 0.0061065846053538842, 0.0060906777920839089, 0.0060752640399891833, 0.0060602883878722097, 0.0060457479962581096, 0.0060316378481974613, 0.006017933831193565, 0.0060046205228994837, 0.0059916612514155591, 0.0059790616381636373, 0.0059667848014532052, 0.0059548501570988958, 0.0059432198385666246, 0.005931886113360387, 0.0059208288140819351, 0.0059100619726771397, 0.0058995632379766289, 0.0058893133077905562, 0.0058793065784420052, 0.0058695187742954097, 0.0058599918460806562, 0.0058506621229883048, 0.0058415431146336501, 0.0058326236236801565, 0.0058238763942027759, 0.0058153263893099784, 0.0058069407923310792, 0.0057987266869273333, 0.0057906638713554693, 0.0057827722144982311, 0.0057750196893342851, 0.0057674051464501521, 0.0057599248803039231, 0.0057525811072944976, 0.0057453636498463502, 0.0057382711310102188, 0.0057312885191138164, 0.0057244081008371098, 0.0057176219831211071, 0.0057109365381126436, 0.0057043205507639992, 0.005697785617386408]}
[2017-10-02 10:16:52,996 AE_UNIGRAMA_1L_OVER_F1_9.py:140]: evaluating model ... 
[2017-10-02 10:16:53,019 AE_UNIGRAMA_1L_OVER_F1_9.py:144]: evaluated! 
[2017-10-02 10:16:53,019 AE_UNIGRAMA_1L_OVER_F1_9.py:146]: generating reports ... 
[2017-10-02 10:16:53,489 AE_UNIGRAMA_1L_OVER_F1_9.py:149]: done!
[2017-10-02 10:16:53,489 AE_UNIGRAMA_1L_OVER_F1_9.py:165]: >> experiment AE_UNIGRAMA_1L_OVER_F1_9 finished!

[2017-09-18 07:42:53,063 AE_UNIGRAMA_1L_OVER_F1_9.py:154]: >> Initializing execution of experiment AE_UNIGRAMA_1L_OVER_F1_9
[2017-09-18 07:42:53,063 AE_UNIGRAMA_1L_OVER_F1_9.py:155]: >> Printing header log
[2017-09-18 07:42:53,064 AE_UNIGRAMA_1L_OVER_F1_9.py:47]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_OVER_F1_9
	layers = 96,182
	using GLOBAL obj = 
		{'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'epochs': 1000, 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'mlp_configs': {'use_last_dim_as_classifier': False, 'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x000000000112E438>, 'classifier_dim': 9}, 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'store_history': True, 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'autoencoder_configs': {'discard_decoder_function': True, 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x000000000112B5C0>, 'hidden_layer_activation': 'relu'}, 'executed_dir': 'E:/research/research_msc/executed/onelayer/unigram/', 'shuffle_batches': True, 'batch': 32, 'numpy_seed': 666, 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram.pkl'}
	=======================================
	
[2017-09-18 07:42:53,064 AE_UNIGRAMA_1L_OVER_F1_9.py:157]: >> Loading dataset... 
[2017-09-18 07:42:53,089 AE_UNIGRAMA_1L_OVER_F1_9.py:63]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram.pkl	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-09-18 07:42:53,090 AE_UNIGRAMA_1L_OVER_F1_9.py:159]: >> Executing autoencoder part ... 
[2017-09-18 07:42:53,090 AE_UNIGRAMA_1L_OVER_F1_9.py:68]: =======================================
[2017-09-18 07:42:53,090 AE_UNIGRAMA_1L_OVER_F1_9.py:73]: setting configurations for autoencoder: 
	 {'discard_decoder_function': True, 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x000000000112B5C0>, 'hidden_layer_activation': 'relu'}
[2017-09-18 07:42:53,185 AE_UNIGRAMA_1L_OVER_F1_9.py:84]: training and evaluate autoencoder
[2017-09-18 07:42:53,773 summary.py:93]: Summary name enc0_182/kernel:0 is illegal; using enc0_182/kernel_0 instead.
[2017-09-18 07:42:53,776 summary.py:93]: Summary name enc0_182/bias:0 is illegal; using enc0_182/bias_0 instead.
[2017-09-18 07:42:53,781 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-09-18 07:42:53,786 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-09-18 07:44:40,056 AE_UNIGRAMA_1L_OVER_F1_9.py:95]: trained and evaluated!
[2017-09-18 07:44:40,056 AE_UNIGRAMA_1L_OVER_F1_9.py:98]: Training history: 
{'val_loss': [0.0090129861402099779, 0.0084219758687366329, 0.0079423733259585804, 0.0075479782638590114, 0.0072205000952672033, 0.0069488029985543846, 0.0067248897129332302, 0.0065398374327671673, 0.0063854137153865464, 0.0062551933958700685, 0.006144340295523942, 0.0060489803682862121, 0.0059659911259886964, 0.0058930664830175407, 0.0058280929882156031, 0.0057699544045003524, 0.0057177239568107921, 0.0056705089280493382, 0.0056273642449425135, 0.0055876198520446495, 0.0055507712192985389, 0.0055163768449546999, 0.0054840642232577928, 0.0054535776855391873, 0.005424627457163168, 0.0053970029740021018, 0.0053705300282493908, 0.0053449205462764351, 0.0053200034016674166, 0.0052959278090872371, 0.0052727560500913147, 0.0052504074450538457, 0.0052288109871316858, 0.0052079472896012858, 0.0051876645639965923, 0.0051678490319461432, 0.0051485019062058055, 0.0051295913137921305, 0.0051111166714733411, 0.0050931016442895436, 0.0050755356475594496, 0.005058409790506738, 0.0050416309999158958, 0.0050252056767899119, 0.0050091182652864984, 0.0049933666300551556, 0.0049779046168917079, 0.0049626791260339725, 0.0049476302465463647, 0.0049326533850166743, 0.0049175048087908724, 0.0049023851143036729, 0.0048874518675325754, 0.004872739825232412, 0.0048582654989549386, 0.0048439685306715472, 0.0048297389924871221, 0.0048155889398692527, 0.0048015640880152699, 0.0047876359912413157, 0.0047738230690097892, 0.0047601413204910034, 0.0047466396969800921, 0.004733373539223487, 0.0047203365497983166, 0.0047075715121268564, 0.0046950164907764219, 0.0046826713538866589, 0.0046705277719220383, 0.0046585690119234965, 0.0046467309714904557, 0.0046348511703871668, 0.0046228181822937382, 0.0046108034419276448, 0.0045988215723967276, 0.0045868897292378284, 0.0045750854539543589, 0.0045634591737618337, 0.0045519961646676901, 0.0045406719682021465, 0.004529462898446494, 0.0045183383013340499, 0.0045072991451955658, 0.0044964020158352793, 0.0044856819749725264, 0.0044751517674966124, 0.0044647669135132522, 0.004454525870829615, 0.0044442792432054122, 0.0044337800121737811, 0.0044231257181582464, 0.0044125171891406445, 0.0044020164663157602, 0.0043916637439452566, 0.0043814907003025009, 0.0043715331617428573, 0.0043618050219493866, 0.00435228175960258, 0.0043429422960419841, 0.0043337788887716248, 0.0043247469994114581, 0.0043158141401288663], 'loss': [0.0093453928167042712, 0.0086949157497828566, 0.0081680190885615334, 0.0077382388275619206, 0.0073831813245082588, 0.0070882770406614747, 0.0068445634331206198, 0.0066436829140982083, 0.0064771334494701759, 0.0063374906395838289, 0.006219379923201122, 0.0061184164739430053, 0.0060310093835165409, 0.0059546473256811977, 0.0058870720464452263, 0.0058267432217200075, 0.0057726708478353182, 0.0057239327251653272, 0.0056796212290481469, 0.0056389061104434469, 0.0056012551145559735, 0.0055662114023993106, 0.0055333679165621178, 0.005502437147694478, 0.0054731494504183338, 0.0054452363920640522, 0.0054185441236179839, 0.0053928242422474799, 0.0053678266082781622, 0.005343540736186138, 0.0053201192513024119, 0.0052975322001804466, 0.0052757383284424333, 0.0052546851727455343, 0.0052342930576261401, 0.0052143964154330981, 0.0051949447892195638, 0.0051759599887037646, 0.0051573992948496733, 0.0051392701075392783, 0.0051215832595847988, 0.0051043533481844065, 0.0050875106507486337, 0.0050710078726206084, 0.0050548513937086264, 0.0050390265389661437, 0.0050234990925482953, 0.0050082414928168456, 0.0049931972552062533, 0.0049782959892429026, 0.0049633625260909432, 0.0049483056433500686, 0.0049333681690351058, 0.0049186210767394002, 0.0049041175151229403, 0.0048898205022659454, 0.0048756347518202547, 0.0048615288436234484, 0.0048475351359622493, 0.0048336543652525198, 0.0048198746581602676, 0.0048062243570365691, 0.0047927412841577881, 0.0047794417521583787, 0.0047663765518415214, 0.0047535430441074493, 0.0047409666579377218, 0.0047285909476624038, 0.0047164159028788488, 0.0047044371755097973, 0.0046926079470766234, 0.0046808363206074606, 0.0046689130056741359, 0.0046569181807824805, 0.0046449566667055159, 0.0046330307994659281, 0.004621196950086095, 0.0046095032895028931, 0.0045979749079260073, 0.0045866080497717204, 0.004575387474735443, 0.0045642819963427608, 0.0045532649741325737, 0.004542370358596547, 0.0045316556892256599, 0.004521127914129861, 0.0045107814612634582, 0.0045005851792752549, 0.0044904806008954547, 0.0044802431102839348, 0.0044697673413004006, 0.0044592610345788718, 0.0044488381598191866, 0.0044385462136724485, 0.004428413550950046, 0.0044184706544902986, 0.0044087455511926266, 0.0043992267592226058, 0.0043898879079591942, 0.0043807234323584802, 0.0043717038509796845, 0.0043627747227198308]}
[2017-09-18 07:44:40,056 AE_UNIGRAMA_1L_OVER_F1_9.py:102]: done!
[2017-09-18 07:44:40,056 AE_UNIGRAMA_1L_OVER_F1_9.py:161]: >> Executing classifier part ... 
[2017-09-18 07:44:40,056 AE_UNIGRAMA_1L_OVER_F1_9.py:107]: =======================================
[2017-09-18 07:44:40,056 AE_UNIGRAMA_1L_OVER_F1_9.py:111]: setting configurations for classifier: 
	 {'use_last_dim_as_classifier': False, 'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x000000000112E438>, 'classifier_dim': 9}
[2017-09-18 07:44:40,259 AE_UNIGRAMA_1L_OVER_F1_9.py:120]: training ... 
[2017-09-18 07:44:42,288 summary.py:93]: Summary name enc0_182/kernel:0 is illegal; using enc0_182/kernel_0 instead.
[2017-09-18 07:44:42,304 summary.py:93]: Summary name enc0_182/bias:0 is illegal; using enc0_182/bias_0 instead.
[2017-09-18 07:44:42,304 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-09-18 07:44:42,319 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-09-18 07:48:16,090 AE_UNIGRAMA_1L_OVER_F1_9.py:132]: trained!
[2017-09-18 07:48:16,090 AE_UNIGRAMA_1L_OVER_F1_9.py:135]: Training history: 
{'val_loss': [0.0090129861402099779, 0.0084219758687366329, 0.0079423733259585804, 0.0075479782638590114, 0.0072205000952672033, 0.0069488029985543846, 0.0067248897129332302, 0.0065398374327671673, 0.0063854137153865464, 0.0062551933958700685, 0.006144340295523942, 0.0060489803682862121, 0.0059659911259886964, 0.0058930664830175407, 0.0058280929882156031, 0.0057699544045003524, 0.0057177239568107921, 0.0056705089280493382, 0.0056273642449425135, 0.0055876198520446495, 0.0055507712192985389, 0.0055163768449546999, 0.0054840642232577928, 0.0054535776855391873, 0.005424627457163168, 0.0053970029740021018, 0.0053705300282493908, 0.0053449205462764351, 0.0053200034016674166, 0.0052959278090872371, 0.0052727560500913147, 0.0052504074450538457, 0.0052288109871316858, 0.0052079472896012858, 0.0051876645639965923, 0.0051678490319461432, 0.0051485019062058055, 0.0051295913137921305, 0.0051111166714733411, 0.0050931016442895436, 0.0050755356475594496, 0.005058409790506738, 0.0050416309999158958, 0.0050252056767899119, 0.0050091182652864984, 0.0049933666300551556, 0.0049779046168917079, 0.0049626791260339725, 0.0049476302465463647, 0.0049326533850166743, 0.0049175048087908724, 0.0049023851143036729, 0.0048874518675325754, 0.004872739825232412, 0.0048582654989549386, 0.0048439685306715472, 0.0048297389924871221, 0.0048155889398692527, 0.0048015640880152699, 0.0047876359912413157, 0.0047738230690097892, 0.0047601413204910034, 0.0047466396969800921, 0.004733373539223487, 0.0047203365497983166, 0.0047075715121268564, 0.0046950164907764219, 0.0046826713538866589, 0.0046705277719220383, 0.0046585690119234965, 0.0046467309714904557, 0.0046348511703871668, 0.0046228181822937382, 0.0046108034419276448, 0.0045988215723967276, 0.0045868897292378284, 0.0045750854539543589, 0.0045634591737618337, 0.0045519961646676901, 0.0045406719682021465, 0.004529462898446494, 0.0045183383013340499, 0.0045072991451955658, 0.0044964020158352793, 0.0044856819749725264, 0.0044751517674966124, 0.0044647669135132522, 0.004454525870829615, 0.0044442792432054122, 0.0044337800121737811, 0.0044231257181582464, 0.0044125171891406445, 0.0044020164663157602, 0.0043916637439452566, 0.0043814907003025009, 0.0043715331617428573, 0.0043618050219493866, 0.00435228175960258, 0.0043429422960419841, 0.0043337788887716248, 0.0043247469994114581, 0.0043158141401288663], 'loss': [0.0093453928167042712, 0.0086949157497828566, 0.0081680190885615334, 0.0077382388275619206, 0.0073831813245082588, 0.0070882770406614747, 0.0068445634331206198, 0.0066436829140982083, 0.0064771334494701759, 0.0063374906395838289, 0.006219379923201122, 0.0061184164739430053, 0.0060310093835165409, 0.0059546473256811977, 0.0058870720464452263, 0.0058267432217200075, 0.0057726708478353182, 0.0057239327251653272, 0.0056796212290481469, 0.0056389061104434469, 0.0056012551145559735, 0.0055662114023993106, 0.0055333679165621178, 0.005502437147694478, 0.0054731494504183338, 0.0054452363920640522, 0.0054185441236179839, 0.0053928242422474799, 0.0053678266082781622, 0.005343540736186138, 0.0053201192513024119, 0.0052975322001804466, 0.0052757383284424333, 0.0052546851727455343, 0.0052342930576261401, 0.0052143964154330981, 0.0051949447892195638, 0.0051759599887037646, 0.0051573992948496733, 0.0051392701075392783, 0.0051215832595847988, 0.0051043533481844065, 0.0050875106507486337, 0.0050710078726206084, 0.0050548513937086264, 0.0050390265389661437, 0.0050234990925482953, 0.0050082414928168456, 0.0049931972552062533, 0.0049782959892429026, 0.0049633625260909432, 0.0049483056433500686, 0.0049333681690351058, 0.0049186210767394002, 0.0049041175151229403, 0.0048898205022659454, 0.0048756347518202547, 0.0048615288436234484, 0.0048475351359622493, 0.0048336543652525198, 0.0048198746581602676, 0.0048062243570365691, 0.0047927412841577881, 0.0047794417521583787, 0.0047663765518415214, 0.0047535430441074493, 0.0047409666579377218, 0.0047285909476624038, 0.0047164159028788488, 0.0047044371755097973, 0.0046926079470766234, 0.0046808363206074606, 0.0046689130056741359, 0.0046569181807824805, 0.0046449566667055159, 0.0046330307994659281, 0.004621196950086095, 0.0046095032895028931, 0.0045979749079260073, 0.0045866080497717204, 0.004575387474735443, 0.0045642819963427608, 0.0045532649741325737, 0.004542370358596547, 0.0045316556892256599, 0.004521127914129861, 0.0045107814612634582, 0.0045005851792752549, 0.0044904806008954547, 0.0044802431102839348, 0.0044697673413004006, 0.0044592610345788718, 0.0044488381598191866, 0.0044385462136724485, 0.004428413550950046, 0.0044184706544902986, 0.0044087455511926266, 0.0043992267592226058, 0.0043898879079591942, 0.0043807234323584802, 0.0043717038509796845, 0.0043627747227198308]}
[2017-09-18 07:48:16,090 AE_UNIGRAMA_1L_OVER_F1_9.py:139]: evaluating model ... 
[2017-09-18 07:48:16,152 AE_UNIGRAMA_1L_OVER_F1_9.py:143]: evaluated! 
[2017-09-18 07:48:16,152 AE_UNIGRAMA_1L_OVER_F1_9.py:145]: generating reports ... 
[2017-09-18 07:48:16,950 AE_UNIGRAMA_1L_OVER_F1_9.py:148]: done!
[2017-09-18 07:48:16,950 AE_UNIGRAMA_1L_OVER_F1_9.py:163]: >> experiment AE_UNIGRAMA_1L_OVER_F1_9 finished!

[2017-09-18 07:42:52,846 AE_UNIGRAMA_1L_UNDER_F0_9.py:155]: >> Initializing execution of experiment AE_UNIGRAMA_1L_UNDER_F0_9
[2017-09-18 07:42:52,847 AE_UNIGRAMA_1L_UNDER_F0_9.py:156]: >> Printing header log
[2017-09-18 07:42:52,847 AE_UNIGRAMA_1L_UNDER_F0_9.py:47]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_UNDER_F0_9
	layers = 96,86
	using GLOBAL obj = 
		{'epochs': 1000, 'mlp_configs': {'classifier_dim': 9, 'optimizer': <keras.optimizers.SGD object at 0x00000000010FE400>, 'loss_function': 'categorical_crossentropy', 'use_last_dim_as_classifier': False, 'activation': 'sigmoid'}, 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'numpy_seed': 666, 'executed_dir': 'E:/research/research_msc/executed/onelayer/unigram/', 'autoencoder_configs': {'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x00000000010FC588>, 'loss_function': 'mse', 'discard_decoder_function': True, 'hidden_layer_activation': 'relu'}, 'batch': 32, 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram.pkl', 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'shuffle_batches': True, 'store_history': True}
	=======================================
	
[2017-09-18 07:42:52,847 AE_UNIGRAMA_1L_UNDER_F0_9.py:158]: >> Loading dataset... 
[2017-09-18 07:42:52,870 AE_UNIGRAMA_1L_UNDER_F0_9.py:63]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram.pkl	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-09-18 07:42:52,870 AE_UNIGRAMA_1L_UNDER_F0_9.py:160]: >> Executing autoencoder part ... 
[2017-09-18 07:42:52,870 AE_UNIGRAMA_1L_UNDER_F0_9.py:68]: =======================================
[2017-09-18 07:42:52,870 AE_UNIGRAMA_1L_UNDER_F0_9.py:73]: setting configurations for autoencoder: 
	 {'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x00000000010FC588>, 'loss_function': 'mse', 'discard_decoder_function': True, 'hidden_layer_activation': 'relu'}
[2017-09-18 07:42:52,950 AE_UNIGRAMA_1L_UNDER_F0_9.py:84]: training and evaluate autoencoder
[2017-09-18 07:42:53,574 summary.py:93]: Summary name enc0_86/kernel:0 is illegal; using enc0_86/kernel_0 instead.
[2017-09-18 07:42:53,574 summary.py:93]: Summary name enc0_86/bias:0 is illegal; using enc0_86/bias_0 instead.
[2017-09-18 07:42:53,574 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-09-18 07:42:53,575 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-09-18 07:44:01,302 AE_UNIGRAMA_1L_UNDER_F0_9.py:95]: trained and evaluated!
[2017-09-18 07:44:01,302 AE_UNIGRAMA_1L_UNDER_F0_9.py:98]: Training history: 
{'val_loss': [0.0097133326766898152, 0.0095099990185280349, 0.0090039914757292609, 0.0085272598674179263, 0.0081240268965285627, 0.0077827295007095844, 0.0074922021983950529, 0.007243616064412821, 0.007030138025249915, 0.0068459161923488396, 0.0066863594264221929, 0.0065474410692639906, 0.0064260393530178308, 0.0063193054427041952, 0.0062248013207352815, 0.0061407750692336286, 0.0060654552619204679, 0.0059976829844809324, 0.0059364427738295552, 0.0058808464671422488, 0.0058300392513972177, 0.0057832210351059605, 0.0057398050891537353, 0.0056990305955587819, 0.0056597879456814128, 0.0056224204943840861, 0.0055871886528586203, 0.0055538775787463916, 0.0055222449350509299, 0.0054911770119418371, 0.0054570629849885503, 0.0054246931313203343, 0.0053942494026516337, 0.0053654877415549133, 0.00533815699204897, 0.0053121364509117969, 0.0052872193097682841, 0.0052633326686251309, 0.0052404031198566249, 0.0052183772382425339, 0.0051971812837253006, 0.0051767123060558334, 0.0051568652378605351, 0.0051375511015098966, 0.0051186793981885309, 0.0051002341931588599, 0.0050821818393552093, 0.0050644595966630231, 0.0050470297027927595, 0.0050299049501239881, 0.0050130790153922883, 0.0049965247819994231, 0.0049801426953784995, 0.0049639827616646945, 0.0049480941428644435, 0.0049324580425025542, 0.0049170874677771665, 0.0049020011741335986, 0.0048871795978935864, 0.0048726164555390672, 0.0048582895700154073, 0.0048441868992036329, 0.0048303127084567445, 0.0048166623695276726, 0.0048032478846606851, 0.0047900631781397076, 0.0047771028511774498, 0.0047643313670663713, 0.0047517042954560839, 0.0047391723098355876, 0.0047266116391974184, 0.0047139744667931216, 0.0047011366470411245, 0.0046880411159401867, 0.0046750566503614907, 0.0046622782480741764, 0.0046497742833349906, 0.0046375455061478275, 0.0046255720517204826, 0.0046138497073670865, 0.0046023832278898431, 0.004591144080924466, 0.0045800787786149152, 0.0045691311929031975, 0.0045582346725306696, 0.0045474658432515533, 0.0045368614158097162, 0.0045264446878588759, 0.004516206637147413, 0.004506152485850178, 0.004496281450891231, 0.0044865844429763926, 0.0044770517849162476, 0.0044676782345130237, 0.0044584599342737969, 0.0044493902738105802, 0.0044404637282087888, 0.0044316751208157718, 0.0044230227630317779, 0.0044145091126276915, 0.0044061186155581553, 0.0043978453284808572], 'loss': [0.0097926874339033659, 0.00962530006863185, 0.009274733456875248, 0.0087694932238077759, 0.0083343844826040472, 0.0079665967387084254, 0.0076546965313706574, 0.0073886275984990689, 0.0071606050812236567, 0.0069644870516015651, 0.0067951743957626936, 0.0066483518485049827, 0.0065202772169454751, 0.0064080386380620993, 0.0063091230986138469, 0.0062213757000378856, 0.0061431316996883312, 0.0060729130518870642, 0.00600958735114726, 0.0059522374311803388, 0.0059000730895308927, 0.0058522285475510281, 0.0058080055796060808, 0.0057667797006441691, 0.0057275926239758355, 0.0056899053137097842, 0.005654189154360321, 0.0056204745121075251, 0.005588492344583842, 0.0055577936494816474, 0.005525232032588436, 0.0054916100656197371, 0.0054599767468748051, 0.0054301696656196595, 0.0054019623111036781, 0.00537515058027512, 0.005349547004369932, 0.0053250039412673297, 0.0053014868458958623, 0.0052789031944956806, 0.0052571876235287971, 0.0052362641939104363, 0.0052160277282054385, 0.005196367057740626, 0.0051772096875071436, 0.0051584900835808124, 0.0051401810392136546, 0.0051222423875044356, 0.0051046194903857983, 0.0050872986209952046, 0.0050702849699099019, 0.0050535545550305979, 0.0050370482670384908, 0.0050207379484295154, 0.005004678008584295, 0.0049888774880306498, 0.0049733569792629467, 0.0049581214798950701, 0.0049431661269759546, 0.0049284746766600695, 0.0049140389712726985, 0.0048998434647457741, 0.0048858781030365695, 0.0048721390696315845, 0.0048586300101437106, 0.0048453403045577081, 0.0048322644557040701, 0.0048193774060671414, 0.0048066741588903969, 0.0047940985065072911, 0.0047815827126621033, 0.0047690158909820257, 0.0047563192159338925, 0.0047433419467231329, 0.0047302768038208773, 0.0047173706294057179, 0.0047047059769017782, 0.0046923176648786397, 0.004680211019119365, 0.0046683569679159508, 0.0046567561974143329, 0.0046453995373965636, 0.0046342594732363632, 0.0046232795526906963, 0.0046123871274545789, 0.0046015826865095141, 0.0045909251243482375, 0.0045804620643969517, 0.004570195505621189, 0.0045601024785220465, 0.0045501887078411955, 0.0045404494311960036, 0.0045308748332615993, 0.0045214656243043379, 0.0045122165192657999, 0.0045031188330228403, 0.0044941657437833522, 0.0044853535954174828, 0.004476677365276409, 0.0044681368972061307, 0.0044597294319906203, 0.00445143555266305]}
[2017-09-18 07:44:01,302 AE_UNIGRAMA_1L_UNDER_F0_9.py:102]: done!
[2017-09-18 07:44:01,302 AE_UNIGRAMA_1L_UNDER_F0_9.py:162]: >> Executing classifier part ... 
[2017-09-18 07:44:01,318 AE_UNIGRAMA_1L_UNDER_F0_9.py:107]: =======================================
[2017-09-18 07:44:01,318 AE_UNIGRAMA_1L_UNDER_F0_9.py:111]: setting configurations for classifier: 
	 {'classifier_dim': 9, 'optimizer': <keras.optimizers.SGD object at 0x00000000010FE400>, 'loss_function': 'categorical_crossentropy', 'use_last_dim_as_classifier': False, 'activation': 'sigmoid'}
[2017-09-18 07:44:01,536 AE_UNIGRAMA_1L_UNDER_F0_9.py:120]: training ... 
[2017-09-18 07:44:03,603 summary.py:93]: Summary name enc0_86/kernel:0 is illegal; using enc0_86/kernel_0 instead.
[2017-09-18 07:44:03,621 summary.py:93]: Summary name enc0_86/bias:0 is illegal; using enc0_86/bias_0 instead.
[2017-09-18 07:44:03,637 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-09-18 07:44:03,637 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-09-18 07:46:56,120 AE_UNIGRAMA_1L_UNDER_F0_9.py:132]: trained!
[2017-09-18 07:46:56,135 AE_UNIGRAMA_1L_UNDER_F0_9.py:135]: Training history: 
{'val_loss': [0.0097133326766898152, 0.0095099990185280349, 0.0090039914757292609, 0.0085272598674179263, 0.0081240268965285627, 0.0077827295007095844, 0.0074922021983950529, 0.007243616064412821, 0.007030138025249915, 0.0068459161923488396, 0.0066863594264221929, 0.0065474410692639906, 0.0064260393530178308, 0.0063193054427041952, 0.0062248013207352815, 0.0061407750692336286, 0.0060654552619204679, 0.0059976829844809324, 0.0059364427738295552, 0.0058808464671422488, 0.0058300392513972177, 0.0057832210351059605, 0.0057398050891537353, 0.0056990305955587819, 0.0056597879456814128, 0.0056224204943840861, 0.0055871886528586203, 0.0055538775787463916, 0.0055222449350509299, 0.0054911770119418371, 0.0054570629849885503, 0.0054246931313203343, 0.0053942494026516337, 0.0053654877415549133, 0.00533815699204897, 0.0053121364509117969, 0.0052872193097682841, 0.0052633326686251309, 0.0052404031198566249, 0.0052183772382425339, 0.0051971812837253006, 0.0051767123060558334, 0.0051568652378605351, 0.0051375511015098966, 0.0051186793981885309, 0.0051002341931588599, 0.0050821818393552093, 0.0050644595966630231, 0.0050470297027927595, 0.0050299049501239881, 0.0050130790153922883, 0.0049965247819994231, 0.0049801426953784995, 0.0049639827616646945, 0.0049480941428644435, 0.0049324580425025542, 0.0049170874677771665, 0.0049020011741335986, 0.0048871795978935864, 0.0048726164555390672, 0.0048582895700154073, 0.0048441868992036329, 0.0048303127084567445, 0.0048166623695276726, 0.0048032478846606851, 0.0047900631781397076, 0.0047771028511774498, 0.0047643313670663713, 0.0047517042954560839, 0.0047391723098355876, 0.0047266116391974184, 0.0047139744667931216, 0.0047011366470411245, 0.0046880411159401867, 0.0046750566503614907, 0.0046622782480741764, 0.0046497742833349906, 0.0046375455061478275, 0.0046255720517204826, 0.0046138497073670865, 0.0046023832278898431, 0.004591144080924466, 0.0045800787786149152, 0.0045691311929031975, 0.0045582346725306696, 0.0045474658432515533, 0.0045368614158097162, 0.0045264446878588759, 0.004516206637147413, 0.004506152485850178, 0.004496281450891231, 0.0044865844429763926, 0.0044770517849162476, 0.0044676782345130237, 0.0044584599342737969, 0.0044493902738105802, 0.0044404637282087888, 0.0044316751208157718, 0.0044230227630317779, 0.0044145091126276915, 0.0044061186155581553, 0.0043978453284808572], 'loss': [0.0097926874339033659, 0.00962530006863185, 0.009274733456875248, 0.0087694932238077759, 0.0083343844826040472, 0.0079665967387084254, 0.0076546965313706574, 0.0073886275984990689, 0.0071606050812236567, 0.0069644870516015651, 0.0067951743957626936, 0.0066483518485049827, 0.0065202772169454751, 0.0064080386380620993, 0.0063091230986138469, 0.0062213757000378856, 0.0061431316996883312, 0.0060729130518870642, 0.00600958735114726, 0.0059522374311803388, 0.0059000730895308927, 0.0058522285475510281, 0.0058080055796060808, 0.0057667797006441691, 0.0057275926239758355, 0.0056899053137097842, 0.005654189154360321, 0.0056204745121075251, 0.005588492344583842, 0.0055577936494816474, 0.005525232032588436, 0.0054916100656197371, 0.0054599767468748051, 0.0054301696656196595, 0.0054019623111036781, 0.00537515058027512, 0.005349547004369932, 0.0053250039412673297, 0.0053014868458958623, 0.0052789031944956806, 0.0052571876235287971, 0.0052362641939104363, 0.0052160277282054385, 0.005196367057740626, 0.0051772096875071436, 0.0051584900835808124, 0.0051401810392136546, 0.0051222423875044356, 0.0051046194903857983, 0.0050872986209952046, 0.0050702849699099019, 0.0050535545550305979, 0.0050370482670384908, 0.0050207379484295154, 0.005004678008584295, 0.0049888774880306498, 0.0049733569792629467, 0.0049581214798950701, 0.0049431661269759546, 0.0049284746766600695, 0.0049140389712726985, 0.0048998434647457741, 0.0048858781030365695, 0.0048721390696315845, 0.0048586300101437106, 0.0048453403045577081, 0.0048322644557040701, 0.0048193774060671414, 0.0048066741588903969, 0.0047940985065072911, 0.0047815827126621033, 0.0047690158909820257, 0.0047563192159338925, 0.0047433419467231329, 0.0047302768038208773, 0.0047173706294057179, 0.0047047059769017782, 0.0046923176648786397, 0.004680211019119365, 0.0046683569679159508, 0.0046567561974143329, 0.0046453995373965636, 0.0046342594732363632, 0.0046232795526906963, 0.0046123871274545789, 0.0046015826865095141, 0.0045909251243482375, 0.0045804620643969517, 0.004570195505621189, 0.0045601024785220465, 0.0045501887078411955, 0.0045404494311960036, 0.0045308748332615993, 0.0045214656243043379, 0.0045122165192657999, 0.0045031188330228403, 0.0044941657437833522, 0.0044853535954174828, 0.004476677365276409, 0.0044681368972061307, 0.0044597294319906203, 0.00445143555266305]}
[2017-09-18 07:46:56,135 AE_UNIGRAMA_1L_UNDER_F0_9.py:139]: evaluating model ... 
[2017-09-18 07:46:56,213 AE_UNIGRAMA_1L_UNDER_F0_9.py:143]: evaluated! 
[2017-09-18 07:46:56,213 AE_UNIGRAMA_1L_UNDER_F0_9.py:145]: generating reports ... 
[2017-09-18 07:46:59,256 AE_UNIGRAMA_1L_UNDER_F0_9.py:148]: done!
[2017-09-18 07:46:59,256 AE_UNIGRAMA_1L_UNDER_F0_9.py:164]: >> experiment AE_UNIGRAMA_1L_UNDER_F0_9 finished!

[2017-10-02 10:18:28,835 AE_UNIGRAMA_1L_UNDER_F0_1.py:157]: >> Initializing execution of experiment AE_UNIGRAMA_1L_UNDER_F0_1
[2017-10-02 10:18:28,835 AE_UNIGRAMA_1L_UNDER_F0_1.py:158]: >> Printing header log
[2017-10-02 10:18:28,835 AE_UNIGRAMA_1L_UNDER_F0_1.py:48]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_UNDER_F0_1
	layers = 96,9
	using GLOBAL obj = 
		{'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'epochs': 200, 'store_history': True, 'executed_path': 'E:/research/research_msc/executed/onelayer/unigram/', 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram_mini.pkl', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'numpy_seed': 666, 'shuffle_batches': True, 'mlp_configs': {'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x0000000001920358>, 'activation': 'sigmoid', 'classifier_dim': 9, 'use_last_dim_as_classifier': False}, 'batch': 32, 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'discard_decoder_function': True, 'optimizer': <keras.optimizers.SGD object at 0x000000000171E4E0>}, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s'}
	=======================================
	
[2017-10-02 10:18:28,836 AE_UNIGRAMA_1L_UNDER_F0_1.py:160]: >> Loading dataset... 
[2017-10-02 10:18:28,847 AE_UNIGRAMA_1L_UNDER_F0_1.py:64]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram_mini.pkl	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-02 10:18:28,848 AE_UNIGRAMA_1L_UNDER_F0_1.py:162]: >> Executing autoencoder part ... 
[2017-10-02 10:18:28,848 AE_UNIGRAMA_1L_UNDER_F0_1.py:69]: =======================================
[2017-10-02 10:18:28,848 AE_UNIGRAMA_1L_UNDER_F0_1.py:74]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'discard_decoder_function': True, 'optimizer': <keras.optimizers.SGD object at 0x000000000171E4E0>}
[2017-10-02 10:18:29,000 AE_UNIGRAMA_1L_UNDER_F0_1.py:85]: training and evaluate autoencoder
[2017-10-02 10:18:29,729 summary.py:93]: Summary name enc0_9/kernel:0 is illegal; using enc0_9/kernel_0 instead.
[2017-10-02 10:18:29,732 summary.py:93]: Summary name enc0_9/bias:0 is illegal; using enc0_9/bias_0 instead.
[2017-10-02 10:18:29,737 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-10-02 10:18:29,739 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-10-02 10:18:48,171 AE_UNIGRAMA_1L_UNDER_F0_1.py:96]: trained and evaluated!
[2017-10-02 10:18:48,172 AE_UNIGRAMA_1L_UNDER_F0_1.py:99]: Training history: 
{'val_loss': [0.0096402194551763482, 0.0095731549269647848, 0.0095067935680700506, 0.009441340134434097, 0.0093770589416355011, 0.0093138406579434656, 0.0092519313775584599, 0.0091912191859740752, 0.0091317266115025515, 0.0090734999952318506, 0.0090165553289053603, 0.0089608862906085072, 0.0089063825515067717, 0.0088531328434450027, 0.0088010517617195961, 0.0087501412520676735, 0.0087003647505572296, 0.0086517427047389153, 0.008604206020171758, 0.0085577935700522929, 0.008512414095154703, 0.0084680632989313515, 0.0084247873545551608, 0.0083825179586900205, 0.0083412564286899828, 0.0083009603963022337, 0.0082615477268386736, 0.0082230315315208243, 0.0081853449195761884, 0.0081485071960407333, 0.0081124925435448001, 0.0080773042598012209, 0.0080429064057988969, 0.0080093164723989696, 0.0079765846800460699, 0.0079445927161515637, 0.0079133933527762122, 0.0078829498113337278, 0.007853217424693271, 0.0078241928934109257, 0.0077958539644166214, 0.007768190285834903, 0.0077411748198826964, 0.0077147790573565047, 0.0076890135232400717, 0.0076638209654302184, 0.0076392303899512192, 0.0076152285003556856, 0.0075918118050495049, 0.0075689477060114805, 0.0075466239714101786, 0.0075248330727662738, 0.0075035533213427073, 0.0074827484613402186, 0.0074624597029171909, 0.0074425930309639102, 0.0074232063346220435, 0.0074043007304400313, 0.0073857980582960033, 0.0073677551409845905, 0.0073501185884484567, 0.0073329009579626162, 0.0073160689763835593, 0.0072996160067396315, 0.0072835562819940454, 0.0072678512682425042, 0.0072525114125700247, 0.0072375059709451454, 0.0072228327743210537, 0.0072084641219099434, 0.0071943965688569395, 0.0071806234781903846, 0.0071671362758569113, 0.0071539161224818361, 0.0071409714155480763, 0.0071282973097547275, 0.0071158751353732272, 0.007103723344015698, 0.0070918107052164005, 0.0070801447630344048, 0.0070687194950324675, 0.007057498951812991, 0.0070465041331420602, 0.007035710594398714, 0.007025126904443073, 0.0070147412105508455, 0.0070045439779176811, 0.0069945276295939347, 0.0069846811195399235, 0.0069750031442502615, 0.0069654821729820682, 0.0069561320249697531, 0.0069469343230377564, 0.0069378791688543273, 0.0069289752178337272, 0.0069202429694590955, 0.0069116591545147306, 0.0069032200477103321, 0.0068949195746761715, 0.0068867685771841543, 0.0068787411980497128, 0.0068708607411102074], 'loss': [0.0096697631511280854, 0.0096012287210505941, 0.0095335006400182627, 0.0094666914990344658, 0.0094010199448202533, 0.0093364710275589801, 0.009273074317171703, 0.009210976027295717, 0.0091500510521732234, 0.0090903944639831365, 0.0090320516760062051, 0.0089750035969882788, 0.0089192536127763282, 0.0088647177772620527, 0.0088114452742374446, 0.0087593277354198647, 0.0087083072207533811, 0.0086584350348352362, 0.0086097230518851538, 0.0085621174469535238, 0.0085156130923282249, 0.0084701854862689451, 0.0084258126639878382, 0.0083824981870639151, 0.0083401896484246556, 0.0082988793107085096, 0.0082585089041473086, 0.0082190076980256706, 0.0081803913954611052, 0.0081426093965017796, 0.008105664260996839, 0.0080695602013635057, 0.0080342973166299368, 0.0079998468474176444, 0.0079662175929218482, 0.0079334342987325262, 0.0079013953968818454, 0.0078701565234470233, 0.0078396574326761673, 0.0078098803338467089, 0.0077808065976450692, 0.007752409242620187, 0.0077246834793584292, 0.0076976138634748011, 0.0076711650390564922, 0.0076453626867367692, 0.0076201278782153719, 0.0075954945515280276, 0.0075714459972480138, 0.007547977357844066, 0.0075250489862787994, 0.0075026558650303785, 0.0074807960601877268, 0.0074594337945390714, 0.0074385494015511006, 0.0074181649828193447, 0.0073982112209261671, 0.0073787379899985526, 0.0073597425770657917, 0.0073411601355737825, 0.0073230232515091283, 0.0073053050026659341, 0.0072879975291853969, 0.0072710814498841174, 0.0072545488968894538, 0.0072383972196241571, 0.0072225961618391041, 0.0072071561629906272, 0.0071920478211620793, 0.0071772491217653262, 0.0071627637188247401, 0.0071485763185010157, 0.0071346945227790661, 0.0071210852345038426, 0.0071077493123009516, 0.0070946905109401711, 0.0070818985778593399, 0.0070693686752755841, 0.0070571090511464783, 0.0070450793240235381, 0.0070332892152658805, 0.0070217441785771495, 0.0070103891208177158, 0.0069992591537645097, 0.0069883296586179299, 0.0069776018466124997, 0.0069670837381700101, 0.0069567525067287094, 0.0069466056190568498, 0.0069366379085179482, 0.0069268399222164921, 0.0069171945583338598, 0.0069077251159620932, 0.0068984011688441975, 0.0068892221445631015, 0.0068802082648966745, 0.0068713645032906397, 0.006862672931928538, 0.0068541344091497683, 0.0068457546989080286, 0.0068375037636175138, 0.0068293904019010232]}
[2017-10-02 10:18:48,173 AE_UNIGRAMA_1L_UNDER_F0_1.py:103]: done!
[2017-10-02 10:18:48,173 AE_UNIGRAMA_1L_UNDER_F0_1.py:164]: >> Executing classifier part ... 
[2017-10-02 10:18:48,173 AE_UNIGRAMA_1L_UNDER_F0_1.py:108]: =======================================
[2017-10-02 10:18:48,173 AE_UNIGRAMA_1L_UNDER_F0_1.py:112]: setting configurations for classifier: 
	 {'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x0000000001920358>, 'activation': 'sigmoid', 'classifier_dim': 9, 'use_last_dim_as_classifier': False}
[2017-10-02 10:18:48,273 AE_UNIGRAMA_1L_UNDER_F0_1.py:121]: training ... 
[2017-10-02 10:18:48,993 summary.py:93]: Summary name enc0_9/kernel:0 is illegal; using enc0_9/kernel_0 instead.
[2017-10-02 10:18:48,996 summary.py:93]: Summary name enc0_9/bias:0 is illegal; using enc0_9/bias_0 instead.
[2017-10-02 10:18:49,002 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-10-02 10:18:49,005 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-10-02 10:19:09,329 AE_UNIGRAMA_1L_UNDER_F0_1.py:133]: trained!
[2017-10-02 10:19:09,330 AE_UNIGRAMA_1L_UNDER_F0_1.py:136]: Training history: 
{'val_loss': [0.0096402194551763482, 0.0095731549269647848, 0.0095067935680700506, 0.009441340134434097, 0.0093770589416355011, 0.0093138406579434656, 0.0092519313775584599, 0.0091912191859740752, 0.0091317266115025515, 0.0090734999952318506, 0.0090165553289053603, 0.0089608862906085072, 0.0089063825515067717, 0.0088531328434450027, 0.0088010517617195961, 0.0087501412520676735, 0.0087003647505572296, 0.0086517427047389153, 0.008604206020171758, 0.0085577935700522929, 0.008512414095154703, 0.0084680632989313515, 0.0084247873545551608, 0.0083825179586900205, 0.0083412564286899828, 0.0083009603963022337, 0.0082615477268386736, 0.0082230315315208243, 0.0081853449195761884, 0.0081485071960407333, 0.0081124925435448001, 0.0080773042598012209, 0.0080429064057988969, 0.0080093164723989696, 0.0079765846800460699, 0.0079445927161515637, 0.0079133933527762122, 0.0078829498113337278, 0.007853217424693271, 0.0078241928934109257, 0.0077958539644166214, 0.007768190285834903, 0.0077411748198826964, 0.0077147790573565047, 0.0076890135232400717, 0.0076638209654302184, 0.0076392303899512192, 0.0076152285003556856, 0.0075918118050495049, 0.0075689477060114805, 0.0075466239714101786, 0.0075248330727662738, 0.0075035533213427073, 0.0074827484613402186, 0.0074624597029171909, 0.0074425930309639102, 0.0074232063346220435, 0.0074043007304400313, 0.0073857980582960033, 0.0073677551409845905, 0.0073501185884484567, 0.0073329009579626162, 0.0073160689763835593, 0.0072996160067396315, 0.0072835562819940454, 0.0072678512682425042, 0.0072525114125700247, 0.0072375059709451454, 0.0072228327743210537, 0.0072084641219099434, 0.0071943965688569395, 0.0071806234781903846, 0.0071671362758569113, 0.0071539161224818361, 0.0071409714155480763, 0.0071282973097547275, 0.0071158751353732272, 0.007103723344015698, 0.0070918107052164005, 0.0070801447630344048, 0.0070687194950324675, 0.007057498951812991, 0.0070465041331420602, 0.007035710594398714, 0.007025126904443073, 0.0070147412105508455, 0.0070045439779176811, 0.0069945276295939347, 0.0069846811195399235, 0.0069750031442502615, 0.0069654821729820682, 0.0069561320249697531, 0.0069469343230377564, 0.0069378791688543273, 0.0069289752178337272, 0.0069202429694590955, 0.0069116591545147306, 0.0069032200477103321, 0.0068949195746761715, 0.0068867685771841543, 0.0068787411980497128, 0.0068708607411102074], 'loss': [0.0096697631511280854, 0.0096012287210505941, 0.0095335006400182627, 0.0094666914990344658, 0.0094010199448202533, 0.0093364710275589801, 0.009273074317171703, 0.009210976027295717, 0.0091500510521732234, 0.0090903944639831365, 0.0090320516760062051, 0.0089750035969882788, 0.0089192536127763282, 0.0088647177772620527, 0.0088114452742374446, 0.0087593277354198647, 0.0087083072207533811, 0.0086584350348352362, 0.0086097230518851538, 0.0085621174469535238, 0.0085156130923282249, 0.0084701854862689451, 0.0084258126639878382, 0.0083824981870639151, 0.0083401896484246556, 0.0082988793107085096, 0.0082585089041473086, 0.0082190076980256706, 0.0081803913954611052, 0.0081426093965017796, 0.008105664260996839, 0.0080695602013635057, 0.0080342973166299368, 0.0079998468474176444, 0.0079662175929218482, 0.0079334342987325262, 0.0079013953968818454, 0.0078701565234470233, 0.0078396574326761673, 0.0078098803338467089, 0.0077808065976450692, 0.007752409242620187, 0.0077246834793584292, 0.0076976138634748011, 0.0076711650390564922, 0.0076453626867367692, 0.0076201278782153719, 0.0075954945515280276, 0.0075714459972480138, 0.007547977357844066, 0.0075250489862787994, 0.0075026558650303785, 0.0074807960601877268, 0.0074594337945390714, 0.0074385494015511006, 0.0074181649828193447, 0.0073982112209261671, 0.0073787379899985526, 0.0073597425770657917, 0.0073411601355737825, 0.0073230232515091283, 0.0073053050026659341, 0.0072879975291853969, 0.0072710814498841174, 0.0072545488968894538, 0.0072383972196241571, 0.0072225961618391041, 0.0072071561629906272, 0.0071920478211620793, 0.0071772491217653262, 0.0071627637188247401, 0.0071485763185010157, 0.0071346945227790661, 0.0071210852345038426, 0.0071077493123009516, 0.0070946905109401711, 0.0070818985778593399, 0.0070693686752755841, 0.0070571090511464783, 0.0070450793240235381, 0.0070332892152658805, 0.0070217441785771495, 0.0070103891208177158, 0.0069992591537645097, 0.0069883296586179299, 0.0069776018466124997, 0.0069670837381700101, 0.0069567525067287094, 0.0069466056190568498, 0.0069366379085179482, 0.0069268399222164921, 0.0069171945583338598, 0.0069077251159620932, 0.0068984011688441975, 0.0068892221445631015, 0.0068802082648966745, 0.0068713645032906397, 0.006862672931928538, 0.0068541344091497683, 0.0068457546989080286, 0.0068375037636175138, 0.0068293904019010232]}
[2017-10-02 10:19:09,331 AE_UNIGRAMA_1L_UNDER_F0_1.py:140]: evaluating model ... 
[2017-10-02 10:19:09,380 AE_UNIGRAMA_1L_UNDER_F0_1.py:144]: evaluated! 
[2017-10-02 10:19:09,380 AE_UNIGRAMA_1L_UNDER_F0_1.py:146]: generating reports ... 
[2017-10-02 10:19:10,205 AE_UNIGRAMA_1L_UNDER_F0_1.py:149]: done!
[2017-10-02 10:19:10,205 AE_UNIGRAMA_1L_UNDER_F0_1.py:166]: >> experiment AE_UNIGRAMA_1L_UNDER_F0_1 finished!

[2017-09-18 07:42:52,501 AE_UNIGRAMA_1L_OVER_F1_1.py:155]: >> Initializing execution of experiment AE_UNIGRAMA_1L_OVER_F1_1
[2017-09-18 07:42:52,501 AE_UNIGRAMA_1L_OVER_F1_1.py:156]: >> Printing header log
[2017-09-18 07:42:52,501 AE_UNIGRAMA_1L_OVER_F1_1.py:47]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_OVER_F1_1
	layers = 96,105
	using GLOBAL obj = 
		{'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'store_history': True, 'epochs': 1000, 'numpy_seed': 666, 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'autoencoder_configs': {'optimizer': <keras.optimizers.SGD object at 0x00000000017CB5C0>, 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'discard_decoder_function': True, 'loss_function': 'mse'}, 'mlp_configs': {'classifier_dim': 9, 'use_last_dim_as_classifier': False, 'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x00000000017CE438>}, 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'batch': 32, 'shuffle_batches': True, 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram.pkl', 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'executed_dir': 'E:/research/research_msc/executed/onelayer/unigram/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s'}
	=======================================
	
[2017-09-18 07:42:52,501 AE_UNIGRAMA_1L_OVER_F1_1.py:158]: >> Loading dataset... 
[2017-09-18 07:42:52,522 AE_UNIGRAMA_1L_OVER_F1_1.py:63]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram.pkl	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-09-18 07:42:52,522 AE_UNIGRAMA_1L_OVER_F1_1.py:160]: >> Executing autoencoder part ... 
[2017-09-18 07:42:52,522 AE_UNIGRAMA_1L_OVER_F1_1.py:68]: =======================================
[2017-09-18 07:42:52,522 AE_UNIGRAMA_1L_OVER_F1_1.py:73]: setting configurations for autoencoder: 
	 {'optimizer': <keras.optimizers.SGD object at 0x00000000017CB5C0>, 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'discard_decoder_function': True, 'loss_function': 'mse'}
[2017-09-18 07:42:52,583 AE_UNIGRAMA_1L_OVER_F1_1.py:84]: training and evaluate autoencoder
[2017-09-18 07:42:53,115 summary.py:93]: Summary name enc0_105/kernel:0 is illegal; using enc0_105/kernel_0 instead.
[2017-09-18 07:42:53,118 summary.py:93]: Summary name enc0_105/bias:0 is illegal; using enc0_105/bias_0 instead.
[2017-09-18 07:42:53,125 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-09-18 07:42:53,131 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-09-18 07:44:03,746 AE_UNIGRAMA_1L_OVER_F1_1.py:95]: trained and evaluated!
[2017-09-18 07:44:03,746 AE_UNIGRAMA_1L_OVER_F1_1.py:98]: Training history: 
{'val_loss': [0.0099043340895575496, 0.0097922694361749843, 0.0096950361420267295, 0.0096102378223993593, 0.009535602689575224, 0.0094691064193001429, 0.0094093547990899539, 0.0093554479601556488, 0.0093065853419247151, 0.0092616285899437024, 0.0092200451670505466, 0.0091818477965286225, 0.0091463790272760595, 0.0091133331089324702, 0.0090822711722491987, 0.0090527523480813023, 0.0090241872759255926, 0.0089954201988424066, 0.0089662849317136729, 0.0089355705909017515, 0.0089025301687646677, 0.0088652804821116316, 0.0088173676585420573, 0.0087341438809143447, 0.0084365981287681975, 0.008098645608780446, 0.00781057179535478, 0.0075658654230374685, 0.0073576708143191583, 0.0071792641042970262, 0.0070253304222606203, 0.0068919104599256655, 0.0067753236164441229, 0.0066732274832526405, 0.0065804369049745747, 0.0064957257079899045, 0.0064195913609386979, 0.0063503817983727407, 0.0062869248675741733, 0.0062281156058201772, 0.0061732899515353247, 0.006121964766929739, 0.0060735542145076808, 0.006027933165211284, 0.0059847747379087679, 0.0059438846400058946, 0.0059051138128283012, 0.0058684214492332231, 0.0058339701087351988, 0.0058016006415350469, 0.0057711225657257328, 0.0057424133329815512, 0.0057152832065219825, 0.0056895780006922629, 0.0056651202835675185, 0.0056417353128831596, 0.0056193326663216301, 0.0055978013457883063, 0.0055770310144583968, 0.0055569446258396131, 0.0055374314917647823, 0.0055184268084748651, 0.005499733747737821, 0.0054811488017946402, 0.0054627075134709791, 0.0054445016389190384, 0.0054262867461799622, 0.0054079065114247399, 0.0053895178698660454, 0.0053710569920225734, 0.0053525290706765505, 0.0053338429866442837, 0.0053148961528274551, 0.0052957676955351918, 0.0052766201063410099, 0.0052574353645295892, 0.0052382911741836232, 0.0052191643796495628, 0.0052002560748975043, 0.0051818314152682465, 0.0051640361376847415, 0.0051468183879560155, 0.0051300657611632588, 0.0051137138877624631, 0.0050977467857824914, 0.0050821091926433158, 0.0050667631963968894, 0.0050515531124502629, 0.0050362764615722987, 0.0050211241384502669, 0.0050062212459154312, 0.004991601178950012, 0.0049772602242004515, 0.0049631552744122173, 0.0049491273472427868, 0.0049350330601311129, 0.004920903365519644, 0.0049068142738428076, 0.0048927914620593097, 0.0048788900588351914, 0.004865134004654088, 0.0048514301236616212], 'loss': [0.0099729621872978961, 0.0098522217631956416, 0.0097480672587093812, 0.0096574548886371233, 0.0095779764869175932, 0.0095076183702170712, 0.0094446789634936319, 0.0093880165497494273, 0.0093368592789679922, 0.0092901466965329658, 0.0092469990335526508, 0.0092072308400049808, 0.0091705392187407982, 0.0091363603219013143, 0.0091044276011246934, 0.0090742390888614039, 0.00904522818455257, 0.0090166664284170289, 0.0089877792817545151, 0.0089576910133859385, 0.0089255374926825431, 0.008890885751357441, 0.0088486432912802358, 0.0087889140673924615, 0.0086125070462374879, 0.0082747508369672446, 0.0079634934768370615, 0.0076993131023908598, 0.0074751938569079523, 0.0072841737289047982, 0.007120020672547714, 0.0069779885161864227, 0.0068546454097521891, 0.0067467606147243427, 0.006651258238820912, 0.0065628306234189818, 0.0064830998204784759, 0.0064109879395772128, 0.0063450765498558647, 0.0062841703963575843, 0.0062276325267454375, 0.0061747943942471782, 0.0061251799382449545, 0.0060783900375172405, 0.0060341126468739983, 0.0059921204589620074, 0.0059522537993432021, 0.0059144311524288364, 0.005878741735080583, 0.0058452312817299339, 0.0058137223941168931, 0.005784015456159447, 0.0057559785804865262, 0.0057294516315713672, 0.005704279711047729, 0.0056802892385408917, 0.0056573166082700852, 0.0056352770849134133, 0.0056140772730036174, 0.0055936267090191082, 0.0055738242321462629, 0.0055545867023832031, 0.005535791716885315, 0.0055172056373749695, 0.0054987138889984214, 0.0054804302227998989, 0.0054622822898648463, 0.0054440429285342404, 0.0054257424680644846, 0.0054074117889378838, 0.0053890149052594032, 0.005370516148757643, 0.0053518092729255501, 0.0053328495379845993, 0.0053137402408916928, 0.0052946266817434024, 0.005275484134308327, 0.0052564256483666316, 0.0052374643886378865, 0.0052188169225438567, 0.0052007276655602445, 0.0051832531485786586, 0.005166315149133599, 0.0051498253977471948, 0.0051337116038054319, 0.0051179400733104511, 0.0051024698379571977, 0.0050872447897616201, 0.0050720205309096513, 0.005056777556440655, 0.0050417048044066508, 0.0050269151783791897, 0.0050124107922959035, 0.004998180698543948, 0.0049841307111407286, 0.0049700818648848767, 0.0049559783244902652, 0.0049418796405879331, 0.0049278569843071805, 0.0049139410272771977, 0.0049001793446833445, 0.0048865529272339048]}
[2017-09-18 07:44:03,746 AE_UNIGRAMA_1L_OVER_F1_1.py:102]: done!
[2017-09-18 07:44:03,746 AE_UNIGRAMA_1L_OVER_F1_1.py:162]: >> Executing classifier part ... 
[2017-09-18 07:44:03,746 AE_UNIGRAMA_1L_OVER_F1_1.py:107]: =======================================
[2017-09-18 07:44:03,746 AE_UNIGRAMA_1L_OVER_F1_1.py:111]: setting configurations for classifier: 
	 {'classifier_dim': 9, 'use_last_dim_as_classifier': False, 'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x00000000017CE438>}
[2017-09-18 07:44:03,857 AE_UNIGRAMA_1L_OVER_F1_1.py:120]: training ... 
[2017-09-18 07:44:04,749 summary.py:93]: Summary name enc0_105/kernel:0 is illegal; using enc0_105/kernel_0 instead.
[2017-09-18 07:44:04,765 summary.py:93]: Summary name enc0_105/bias:0 is illegal; using enc0_105/bias_0 instead.
[2017-09-18 07:44:04,765 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-09-18 07:44:04,781 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-09-18 07:47:40,353 AE_UNIGRAMA_1L_OVER_F1_1.py:132]: trained!
[2017-09-18 07:47:40,353 AE_UNIGRAMA_1L_OVER_F1_1.py:135]: Training history: 
{'val_loss': [0.0099043340895575496, 0.0097922694361749843, 0.0096950361420267295, 0.0096102378223993593, 0.009535602689575224, 0.0094691064193001429, 0.0094093547990899539, 0.0093554479601556488, 0.0093065853419247151, 0.0092616285899437024, 0.0092200451670505466, 0.0091818477965286225, 0.0091463790272760595, 0.0091133331089324702, 0.0090822711722491987, 0.0090527523480813023, 0.0090241872759255926, 0.0089954201988424066, 0.0089662849317136729, 0.0089355705909017515, 0.0089025301687646677, 0.0088652804821116316, 0.0088173676585420573, 0.0087341438809143447, 0.0084365981287681975, 0.008098645608780446, 0.00781057179535478, 0.0075658654230374685, 0.0073576708143191583, 0.0071792641042970262, 0.0070253304222606203, 0.0068919104599256655, 0.0067753236164441229, 0.0066732274832526405, 0.0065804369049745747, 0.0064957257079899045, 0.0064195913609386979, 0.0063503817983727407, 0.0062869248675741733, 0.0062281156058201772, 0.0061732899515353247, 0.006121964766929739, 0.0060735542145076808, 0.006027933165211284, 0.0059847747379087679, 0.0059438846400058946, 0.0059051138128283012, 0.0058684214492332231, 0.0058339701087351988, 0.0058016006415350469, 0.0057711225657257328, 0.0057424133329815512, 0.0057152832065219825, 0.0056895780006922629, 0.0056651202835675185, 0.0056417353128831596, 0.0056193326663216301, 0.0055978013457883063, 0.0055770310144583968, 0.0055569446258396131, 0.0055374314917647823, 0.0055184268084748651, 0.005499733747737821, 0.0054811488017946402, 0.0054627075134709791, 0.0054445016389190384, 0.0054262867461799622, 0.0054079065114247399, 0.0053895178698660454, 0.0053710569920225734, 0.0053525290706765505, 0.0053338429866442837, 0.0053148961528274551, 0.0052957676955351918, 0.0052766201063410099, 0.0052574353645295892, 0.0052382911741836232, 0.0052191643796495628, 0.0052002560748975043, 0.0051818314152682465, 0.0051640361376847415, 0.0051468183879560155, 0.0051300657611632588, 0.0051137138877624631, 0.0050977467857824914, 0.0050821091926433158, 0.0050667631963968894, 0.0050515531124502629, 0.0050362764615722987, 0.0050211241384502669, 0.0050062212459154312, 0.004991601178950012, 0.0049772602242004515, 0.0049631552744122173, 0.0049491273472427868, 0.0049350330601311129, 0.004920903365519644, 0.0049068142738428076, 0.0048927914620593097, 0.0048788900588351914, 0.004865134004654088, 0.0048514301236616212], 'loss': [0.0099729621872978961, 0.0098522217631956416, 0.0097480672587093812, 0.0096574548886371233, 0.0095779764869175932, 0.0095076183702170712, 0.0094446789634936319, 0.0093880165497494273, 0.0093368592789679922, 0.0092901466965329658, 0.0092469990335526508, 0.0092072308400049808, 0.0091705392187407982, 0.0091363603219013143, 0.0091044276011246934, 0.0090742390888614039, 0.00904522818455257, 0.0090166664284170289, 0.0089877792817545151, 0.0089576910133859385, 0.0089255374926825431, 0.008890885751357441, 0.0088486432912802358, 0.0087889140673924615, 0.0086125070462374879, 0.0082747508369672446, 0.0079634934768370615, 0.0076993131023908598, 0.0074751938569079523, 0.0072841737289047982, 0.007120020672547714, 0.0069779885161864227, 0.0068546454097521891, 0.0067467606147243427, 0.006651258238820912, 0.0065628306234189818, 0.0064830998204784759, 0.0064109879395772128, 0.0063450765498558647, 0.0062841703963575843, 0.0062276325267454375, 0.0061747943942471782, 0.0061251799382449545, 0.0060783900375172405, 0.0060341126468739983, 0.0059921204589620074, 0.0059522537993432021, 0.0059144311524288364, 0.005878741735080583, 0.0058452312817299339, 0.0058137223941168931, 0.005784015456159447, 0.0057559785804865262, 0.0057294516315713672, 0.005704279711047729, 0.0056802892385408917, 0.0056573166082700852, 0.0056352770849134133, 0.0056140772730036174, 0.0055936267090191082, 0.0055738242321462629, 0.0055545867023832031, 0.005535791716885315, 0.0055172056373749695, 0.0054987138889984214, 0.0054804302227998989, 0.0054622822898648463, 0.0054440429285342404, 0.0054257424680644846, 0.0054074117889378838, 0.0053890149052594032, 0.005370516148757643, 0.0053518092729255501, 0.0053328495379845993, 0.0053137402408916928, 0.0052946266817434024, 0.005275484134308327, 0.0052564256483666316, 0.0052374643886378865, 0.0052188169225438567, 0.0052007276655602445, 0.0051832531485786586, 0.005166315149133599, 0.0051498253977471948, 0.0051337116038054319, 0.0051179400733104511, 0.0051024698379571977, 0.0050872447897616201, 0.0050720205309096513, 0.005056777556440655, 0.0050417048044066508, 0.0050269151783791897, 0.0050124107922959035, 0.004998180698543948, 0.0049841307111407286, 0.0049700818648848767, 0.0049559783244902652, 0.0049418796405879331, 0.0049278569843071805, 0.0049139410272771977, 0.0049001793446833445, 0.0048865529272339048]}
[2017-09-18 07:47:40,353 AE_UNIGRAMA_1L_OVER_F1_1.py:139]: evaluating model ... 
[2017-09-18 07:47:40,431 AE_UNIGRAMA_1L_OVER_F1_1.py:143]: evaluated! 
[2017-09-18 07:47:40,431 AE_UNIGRAMA_1L_OVER_F1_1.py:145]: generating reports ... 
[2017-09-18 07:47:41,655 AE_UNIGRAMA_1L_OVER_F1_1.py:148]: done!
[2017-09-18 07:47:41,655 AE_UNIGRAMA_1L_OVER_F1_1.py:164]: >> experiment AE_UNIGRAMA_1L_OVER_F1_1 finished!

[2017-10-02 10:07:37,761 AE_UNIGRAMA_1L_OVER_F1_1.py:157]: >> Initializing execution of experiment AE_UNIGRAMA_1L_OVER_F1_1
[2017-10-02 10:07:37,761 AE_UNIGRAMA_1L_OVER_F1_1.py:158]: >> Printing header log
[2017-10-02 10:07:37,762 AE_UNIGRAMA_1L_OVER_F1_1.py:48]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_OVER_F1_1
	layers = 96,105
	using GLOBAL obj = 
		{'numpy_seed': 666, 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'executed_path': 'E:/research/research_msc/executed/onelayer/unigram/', 'epochs': 200, 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram_mini.pkl', 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'autoencoder_configs': {'discard_decoder_function': True, 'optimizer': <keras.optimizers.SGD object at 0x000000000194D518>, 'loss_function': 'mse', 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu'}, 'mlp_configs': {'classifier_dim': 9, 'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x0000000001950390>, 'loss_function': 'categorical_crossentropy', 'use_last_dim_as_classifier': False}, 'batch': 32, 'shuffle_batches': True, 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'store_history': True}
	=======================================
	
[2017-10-02 10:07:37,762 AE_UNIGRAMA_1L_OVER_F1_1.py:160]: >> Loading dataset... 
[2017-10-02 10:07:37,771 AE_UNIGRAMA_1L_OVER_F1_1.py:64]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram_mini.pkl	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-02 10:07:37,771 AE_UNIGRAMA_1L_OVER_F1_1.py:162]: >> Executing autoencoder part ... 
[2017-10-02 10:07:37,771 AE_UNIGRAMA_1L_OVER_F1_1.py:69]: =======================================
[2017-10-02 10:07:37,772 AE_UNIGRAMA_1L_OVER_F1_1.py:74]: setting configurations for autoencoder: 
	 {'discard_decoder_function': True, 'optimizer': <keras.optimizers.SGD object at 0x000000000194D518>, 'loss_function': 'mse', 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu'}
[2017-10-02 10:07:37,957 AE_UNIGRAMA_1L_OVER_F1_1.py:85]: training and evaluate autoencoder
[2017-10-02 10:07:38,674 summary.py:93]: Summary name enc0_105/kernel:0 is illegal; using enc0_105/kernel_0 instead.
[2017-10-02 10:07:38,677 summary.py:93]: Summary name enc0_105/bias:0 is illegal; using enc0_105/bias_0 instead.
[2017-10-02 10:07:38,683 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-10-02 10:07:38,686 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-10-02 10:07:59,012 AE_UNIGRAMA_1L_OVER_F1_1.py:96]: trained and evaluated!
[2017-10-02 10:07:59,012 AE_UNIGRAMA_1L_OVER_F1_1.py:99]: Training history: 
{'val_loss': [0.010063245002748133, 0.010033015071736392, 0.010003562774301462, 0.0099747627142636741, 0.0099466238586322087, 0.0099189780915647629, 0.0098917437336480309, 0.0098648720202780572, 0.0098382949510582313, 0.009812021444527412, 0.0097862527771510159, 0.0097609665937250876, 0.0097361487859243794, 0.0097116889037385749, 0.0096876014813393023, 0.0096639081503378851, 0.0096405468341032377, 0.0096175686445876575, 0.0095948673279256623, 0.0095723635105063043, 0.0095500031513850933, 0.0095277410000562668, 0.0095056544047638393, 0.0094839211304059267, 0.0094625906270952923, 0.0094416025354350369, 0.0094209883645952411, 0.0094006925883623298, 0.0093807914505494566, 0.0093612800833516412, 0.0093421657884763514, 0.0093234564388884038, 0.0093051910012628067, 0.0092873556373232365, 0.0092698894025667888, 0.0092527943500577293, 0.0092361211035829945, 0.0092197296739344702, 0.0092036232428424417, 0.009187791150298703, 0.0091721862589171834, 0.0091567057769981024, 0.0091413640413696446, 0.0091259520860963589, 0.0091104064115970548, 0.0090945436719624961, 0.0090782872875494591, 0.0090608203568977048, 0.0090408072699567649, 0.00901591916980575, 0.0089804949550491286, 0.0089290290586234913, 0.008867096453628133, 0.0087961532127070596, 0.0087148666548019886, 0.0086300479400501368, 0.008545502674069989, 0.008463073577247144, 0.0083829168071035565, 0.0083052420462429739, 0.0082301794911378151, 0.0081577997318846365, 0.008087804464824138, 0.0080201529818119607, 0.007954873906303072, 0.0078919027796963779, 0.0078311480103981541, 0.0077723561453747264, 0.0077155762573627952, 0.0076606483908446309, 0.0076076518363392045, 0.0075564116644621119, 0.0075069216554326636, 0.0074590879135858611, 0.0074128808633711699, 0.0073681889226500869, 0.0073249440841016717, 0.0072830868054001305, 0.0072426025419873377, 0.0072033769142949003, 0.0071654424909156052, 0.0071287407993328618, 0.0070931995512578342, 0.0070587902011342869, 0.0070254282098000378, 0.0069931298702068934, 0.0069618138179986227, 0.0069314741346029546, 0.0069020538639318766, 0.0068735204824007575, 0.0068458629093482593, 0.0068190169527600469, 0.0067929654420253067, 0.0067676830237045826, 0.006743139106101706, 0.0067193067518364095, 0.00669623410232282, 0.0066737504554808579, 0.0066519138441320687, 0.0066306867176272166, 0.0066100407883414106, 0.0065899817082601632], 'loss': [0.010086366196392539, 0.010055238161220019, 0.010024948968920117, 0.009995434913479739, 0.0099665899128500279, 0.0099383442397627201, 0.0099105943170660609, 0.0098833326180479825, 0.0098564020880642818, 0.0098297509651564721, 0.0098035771842787216, 0.0097779372086509216, 0.0097528004540289627, 0.00972810798263396, 0.0097037714275805664, 0.0096798351941230695, 0.0096562592302390088, 0.0096331037822526954, 0.0096103149107311069, 0.0095878132420334997, 0.009565598453889065, 0.0095435577955900637, 0.009521656322791559, 0.0094998933714897493, 0.0094784379352316882, 0.0094573432682671654, 0.0094366277096943028, 0.0094162671264093854, 0.009396267302686917, 0.009376645351507654, 0.0093573896888673267, 0.0093385035248808729, 0.0093200308824279744, 0.0093019910914607044, 0.0092843696612409082, 0.0092671437546171208, 0.0092502812767365841, 0.0092337583572350175, 0.0092175174722036995, 0.0092015673922169923, 0.0091858403528247718, 0.0091702191218660523, 0.0091547347907464643, 0.0091392012100069159, 0.0091233938931273989, 0.0091073627451454201, 0.0090909753350819182, 0.0090737293577983699, 0.0090542680772219466, 0.0090307328093295527, 0.0089986449240328486, 0.008953425417910086, 0.00889524801610783, 0.0088275761802044835, 0.0087483430478192941, 0.0086618482616639021, 0.0085738822897940825, 0.0084876285604880714, 0.0084040486542868633, 0.0083230670178612472, 0.0082446192691735722, 0.0081688790658251895, 0.0080957380366713707, 0.0080251230479898676, 0.007956944648164984, 0.0078911598174779534, 0.0078277002926171735, 0.0077664564577169994, 0.0077072271768669999, 0.0076500064714570756, 0.0075946828612591787, 0.0075413060501062145, 0.0074896900911747347, 0.0074398671949457446, 0.0073916662253150928, 0.0073451077898697538, 0.0073000462250652383, 0.0072564464248487861, 0.0072142331704689667, 0.0071733809063656423, 0.0071337924220959284, 0.0070955231130356688, 0.0070584596394599585, 0.0070225541438671546, 0.0069877778534269729, 0.0069540850589190368, 0.0069214109761827035, 0.0068897495527660731, 0.0068590456308463858, 0.0068292696027230579, 0.0068003795385594267, 0.0067723861611582743, 0.0067452139667044698, 0.0067188170745387243, 0.0066932153712887122, 0.0066683554604590016, 0.0066442007932196057, 0.0066208087117368263, 0.006598000251816857, 0.0065758400144468772, 0.0065543141196577476, 0.0065333579810589243]}
[2017-10-02 10:07:59,013 AE_UNIGRAMA_1L_OVER_F1_1.py:103]: done!
[2017-10-02 10:07:59,013 AE_UNIGRAMA_1L_OVER_F1_1.py:164]: >> Executing classifier part ... 
[2017-10-02 10:07:59,013 AE_UNIGRAMA_1L_OVER_F1_1.py:108]: =======================================
[2017-10-02 10:07:59,013 AE_UNIGRAMA_1L_OVER_F1_1.py:112]: setting configurations for classifier: 
	 {'classifier_dim': 9, 'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x0000000001950390>, 'loss_function': 'categorical_crossentropy', 'use_last_dim_as_classifier': False}
[2017-10-02 10:07:59,099 AE_UNIGRAMA_1L_OVER_F1_1.py:121]: training ... 
[2017-10-02 10:07:59,739 summary.py:93]: Summary name enc0_105/kernel:0 is illegal; using enc0_105/kernel_0 instead.
[2017-10-02 10:07:59,742 summary.py:93]: Summary name enc0_105/bias:0 is illegal; using enc0_105/bias_0 instead.
[2017-10-02 10:07:59,748 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-10-02 10:07:59,751 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-10-02 10:08:41,357 AE_UNIGRAMA_1L_OVER_F1_1.py:133]: trained!
[2017-10-02 10:08:41,358 AE_UNIGRAMA_1L_OVER_F1_1.py:136]: Training history: 
{'val_loss': [0.010063245002748133, 0.010033015071736392, 0.010003562774301462, 0.0099747627142636741, 0.0099466238586322087, 0.0099189780915647629, 0.0098917437336480309, 0.0098648720202780572, 0.0098382949510582313, 0.009812021444527412, 0.0097862527771510159, 0.0097609665937250876, 0.0097361487859243794, 0.0097116889037385749, 0.0096876014813393023, 0.0096639081503378851, 0.0096405468341032377, 0.0096175686445876575, 0.0095948673279256623, 0.0095723635105063043, 0.0095500031513850933, 0.0095277410000562668, 0.0095056544047638393, 0.0094839211304059267, 0.0094625906270952923, 0.0094416025354350369, 0.0094209883645952411, 0.0094006925883623298, 0.0093807914505494566, 0.0093612800833516412, 0.0093421657884763514, 0.0093234564388884038, 0.0093051910012628067, 0.0092873556373232365, 0.0092698894025667888, 0.0092527943500577293, 0.0092361211035829945, 0.0092197296739344702, 0.0092036232428424417, 0.009187791150298703, 0.0091721862589171834, 0.0091567057769981024, 0.0091413640413696446, 0.0091259520860963589, 0.0091104064115970548, 0.0090945436719624961, 0.0090782872875494591, 0.0090608203568977048, 0.0090408072699567649, 0.00901591916980575, 0.0089804949550491286, 0.0089290290586234913, 0.008867096453628133, 0.0087961532127070596, 0.0087148666548019886, 0.0086300479400501368, 0.008545502674069989, 0.008463073577247144, 0.0083829168071035565, 0.0083052420462429739, 0.0082301794911378151, 0.0081577997318846365, 0.008087804464824138, 0.0080201529818119607, 0.007954873906303072, 0.0078919027796963779, 0.0078311480103981541, 0.0077723561453747264, 0.0077155762573627952, 0.0076606483908446309, 0.0076076518363392045, 0.0075564116644621119, 0.0075069216554326636, 0.0074590879135858611, 0.0074128808633711699, 0.0073681889226500869, 0.0073249440841016717, 0.0072830868054001305, 0.0072426025419873377, 0.0072033769142949003, 0.0071654424909156052, 0.0071287407993328618, 0.0070931995512578342, 0.0070587902011342869, 0.0070254282098000378, 0.0069931298702068934, 0.0069618138179986227, 0.0069314741346029546, 0.0069020538639318766, 0.0068735204824007575, 0.0068458629093482593, 0.0068190169527600469, 0.0067929654420253067, 0.0067676830237045826, 0.006743139106101706, 0.0067193067518364095, 0.00669623410232282, 0.0066737504554808579, 0.0066519138441320687, 0.0066306867176272166, 0.0066100407883414106, 0.0065899817082601632], 'loss': [0.010086366196392539, 0.010055238161220019, 0.010024948968920117, 0.009995434913479739, 0.0099665899128500279, 0.0099383442397627201, 0.0099105943170660609, 0.0098833326180479825, 0.0098564020880642818, 0.0098297509651564721, 0.0098035771842787216, 0.0097779372086509216, 0.0097528004540289627, 0.00972810798263396, 0.0097037714275805664, 0.0096798351941230695, 0.0096562592302390088, 0.0096331037822526954, 0.0096103149107311069, 0.0095878132420334997, 0.009565598453889065, 0.0095435577955900637, 0.009521656322791559, 0.0094998933714897493, 0.0094784379352316882, 0.0094573432682671654, 0.0094366277096943028, 0.0094162671264093854, 0.009396267302686917, 0.009376645351507654, 0.0093573896888673267, 0.0093385035248808729, 0.0093200308824279744, 0.0093019910914607044, 0.0092843696612409082, 0.0092671437546171208, 0.0092502812767365841, 0.0092337583572350175, 0.0092175174722036995, 0.0092015673922169923, 0.0091858403528247718, 0.0091702191218660523, 0.0091547347907464643, 0.0091392012100069159, 0.0091233938931273989, 0.0091073627451454201, 0.0090909753350819182, 0.0090737293577983699, 0.0090542680772219466, 0.0090307328093295527, 0.0089986449240328486, 0.008953425417910086, 0.00889524801610783, 0.0088275761802044835, 0.0087483430478192941, 0.0086618482616639021, 0.0085738822897940825, 0.0084876285604880714, 0.0084040486542868633, 0.0083230670178612472, 0.0082446192691735722, 0.0081688790658251895, 0.0080957380366713707, 0.0080251230479898676, 0.007956944648164984, 0.0078911598174779534, 0.0078277002926171735, 0.0077664564577169994, 0.0077072271768669999, 0.0076500064714570756, 0.0075946828612591787, 0.0075413060501062145, 0.0074896900911747347, 0.0074398671949457446, 0.0073916662253150928, 0.0073451077898697538, 0.0073000462250652383, 0.0072564464248487861, 0.0072142331704689667, 0.0071733809063656423, 0.0071337924220959284, 0.0070955231130356688, 0.0070584596394599585, 0.0070225541438671546, 0.0069877778534269729, 0.0069540850589190368, 0.0069214109761827035, 0.0068897495527660731, 0.0068590456308463858, 0.0068292696027230579, 0.0068003795385594267, 0.0067723861611582743, 0.0067452139667044698, 0.0067188170745387243, 0.0066932153712887122, 0.0066683554604590016, 0.0066442007932196057, 0.0066208087117368263, 0.006598000251816857, 0.0065758400144468772, 0.0065543141196577476, 0.0065333579810589243]}
[2017-10-02 10:08:41,358 AE_UNIGRAMA_1L_OVER_F1_1.py:140]: evaluating model ... 
[2017-10-02 10:08:41,398 AE_UNIGRAMA_1L_OVER_F1_1.py:144]: evaluated! 
[2017-10-02 10:08:41,398 AE_UNIGRAMA_1L_OVER_F1_1.py:146]: generating reports ... 
[2017-10-02 10:08:42,174 AE_UNIGRAMA_1L_OVER_F1_1.py:149]: done!
[2017-10-02 10:08:42,174 AE_UNIGRAMA_1L_OVER_F1_1.py:166]: >> experiment AE_UNIGRAMA_1L_OVER_F1_1 finished!

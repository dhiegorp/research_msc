[2017-10-02 10:10:05,348 AE_UNIGRAMA_1L_OVER_F1_3.py:156]: >> Initializing execution of experiment AE_UNIGRAMA_1L_OVER_F1_3
[2017-10-02 10:10:05,348 AE_UNIGRAMA_1L_OVER_F1_3.py:157]: >> Printing header log
[2017-10-02 10:10:05,349 AE_UNIGRAMA_1L_OVER_F1_3.py:48]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_OVER_F1_3
	layers = 96,124
	using GLOBAL obj = 
		{'data_dir': 'E:/research/malware_dataset/malware_selected_1gram_mini.pkl', 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x00000000018F0390>, 'classifier_dim': 9, 'use_last_dim_as_classifier': False}, 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'autoencoder_configs': {'loss_function': 'mse', 'hidden_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x00000000018ED518>, 'discard_decoder_function': True, 'output_layer_activation': 'relu'}, 'epochs': 200, 'batch': 32, 'executed_path': 'E:/research/research_msc/executed/onelayer/unigram/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'shuffle_batches': True, 'numpy_seed': 666, 'store_history': True, 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/'}
	=======================================
	
[2017-10-02 10:10:05,349 AE_UNIGRAMA_1L_OVER_F1_3.py:159]: >> Loading dataset... 
[2017-10-02 10:10:05,354 AE_UNIGRAMA_1L_OVER_F1_3.py:64]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram_mini.pkl	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-02 10:10:05,354 AE_UNIGRAMA_1L_OVER_F1_3.py:161]: >> Executing autoencoder part ... 
[2017-10-02 10:10:05,354 AE_UNIGRAMA_1L_OVER_F1_3.py:69]: =======================================
[2017-10-02 10:10:05,354 AE_UNIGRAMA_1L_OVER_F1_3.py:74]: setting configurations for autoencoder: 
	 {'loss_function': 'mse', 'hidden_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x00000000018ED518>, 'discard_decoder_function': True, 'output_layer_activation': 'relu'}
[2017-10-02 10:10:05,411 AE_UNIGRAMA_1L_OVER_F1_3.py:85]: training and evaluate autoencoder
[2017-10-02 10:10:05,767 summary.py:93]: Summary name enc0_124/kernel:0 is illegal; using enc0_124/kernel_0 instead.
[2017-10-02 10:10:05,769 summary.py:93]: Summary name enc0_124/bias:0 is illegal; using enc0_124/bias_0 instead.
[2017-10-02 10:10:05,772 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-10-02 10:10:05,773 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-10-02 10:10:16,514 AE_UNIGRAMA_1L_OVER_F1_3.py:96]: trained and evaluated!
[2017-10-02 10:10:16,515 AE_UNIGRAMA_1L_OVER_F1_3.py:99]: Training history: 
{'val_loss': [0.0088111525643824653, 0.0087103122606402659, 0.0086138991251255501, 0.0085215879895042309, 0.0084331254405575398, 0.0083483811104358568, 0.008267207188898746, 0.0081893422201165036, 0.0081147826432517028, 0.0080432306358860766, 0.0079746174290222308, 0.0079087894080989204, 0.0078454971846650089, 0.007784750925370087, 0.0077262930572032928, 0.007669970973093603, 0.0076157725710407952, 0.0075635060799553932, 0.0075131889353038878, 0.0074646573333713648, 0.0074177239277161185, 0.0073723955509221685, 0.0073283929724010837, 0.0072859184986125806, 0.0072448166073421118, 0.0072049990618345237, 0.0071664167010678896, 0.0071290132059926882, 0.0070925890762345055, 0.0070571416061108441, 0.0070225068378404172, 0.0069886190248964891, 0.0069554503522397861, 0.0069230759159755306, 0.006891507181065455, 0.0068606918757317453, 0.0068306030504765563, 0.0068010391449368794, 0.0067719304968765675, 0.0067428492103118213, 0.0067140625401998985, 0.0066856728991334319, 0.0066577446920499479, 0.0066301758646909632, 0.0066028583230499224, 0.0065756374623861897, 0.0065484697546214421, 0.006521268626571145, 0.0064941619342836973, 0.0064671184559487718, 0.0064400921759219859, 0.006413419412442078, 0.0063871777976506486, 0.0063614936538566886, 0.0063364584999484426, 0.0063120246117027495, 0.0062881698052928573, 0.0062649073771661543, 0.0062423228220425571, 0.0062204412094639359, 0.0061992361663830327, 0.0061786718593848013, 0.0061588154475595873, 0.0061395966783719877, 0.006120984110164155, 0.0061029850879206309, 0.0060855241243114701, 0.0060686169341068064, 0.0060522255235001942, 0.0060363240733908897, 0.0060208783689263143, 0.006005890338532765, 0.0059913436563678608, 0.0059772115685461178, 0.0059634522953828911, 0.0059500764120633274, 0.0059370534221008147, 0.0059243622357129612, 0.0059120077587885705, 0.0058999754259965237, 0.0058882562460924838, 0.0058768437604063287, 0.0058657153090635201, 0.0058548575938855846, 0.0058442791854637259, 0.0058339614106072144, 0.0058238970074234843, 0.0058140619311717141, 0.005804458837333, 0.0057950686268702315, 0.0057858823379674813, 0.0057768925217752337, 0.0057681096028744288, 0.005759520812797945, 0.0057511048799996928, 0.0057428629192970279, 0.0057347866751558275, 0.0057268670368870395, 0.0057191152132521333, 0.0057115014434747091, 0.0057040297211629083, 0.0056966867360206787], 'loss': [0.0088906965573955395, 0.0087862520649818528, 0.0086860774742060446, 0.0085902396903202154, 0.0084984547183256463, 0.0084105040362882112, 0.0083261750336248736, 0.0082453951484580384, 0.0081679157468535525, 0.0080936959296116894, 0.0080224542512793671, 0.0079541530602651091, 0.0078885618207453038, 0.0078254921428204394, 0.0077649563806819529, 0.0077067143183611403, 0.0076505695269331476, 0.0075965413171740753, 0.0075444268662603854, 0.0074942324850902865, 0.0074457820085894501, 0.0073989088605281098, 0.0073536377621685241, 0.0073098082077639667, 0.0072675157360132664, 0.0072266064050762512, 0.0071869768839405044, 0.00714858109016972, 0.0071112808943728989, 0.0070749470816962945, 0.0070395936199750689, 0.0070050763648596363, 0.0069713033406612291, 0.0069382110296919734, 0.0069059344285042398, 0.0068744581070234604, 0.0068437155561101495, 0.0068136641896514713, 0.006784125778437137, 0.0067549250904326433, 0.0067259557777014003, 0.0066973262465917852, 0.0066692057181866387, 0.0066414884719184809, 0.0066140419213970196, 0.0065867733691155582, 0.0065595942962120186, 0.0065323805935067238, 0.0065051636586484366, 0.0064779896358945063, 0.0064509472335770625, 0.0064240421936117434, 0.0063974672874645283, 0.006371287706570806, 0.0063456701027193941, 0.0063206908323406516, 0.0062962778942395039, 0.0062724459093789894, 0.0062492894645283471, 0.0062268139633047262, 0.0062050148899098559, 0.0061839035155220714, 0.0061634317748523338, 0.0061436672365841284, 0.0061245248896271889, 0.0061059726563012706, 0.0060880217362325765, 0.0060706123003888401, 0.0060537467700942718, 0.0060373785090990497, 0.0060214916637399739, 0.006006057615739367, 0.0059910881027954816, 0.0059765464421327342, 0.0059624125075669063, 0.005948650099728634, 0.0059352830254439017, 0.0059222593556084403, 0.005909561285189254, 0.0058972008970520871, 0.0058851571099348392, 0.005873429076374035, 0.0058619836660144366, 0.0058508278394476289, 0.0058399308272525808, 0.0058293245024704354, 0.0058189770636121844, 0.0058088913693286814, 0.0057990250490221164, 0.0057893801788492074, 0.0057799399741103883, 0.005770706604266357, 0.0057616610464668013, 0.0057528267157182199, 0.0057441995235316835, 0.0057357475316105041, 0.0057274722477012457, 0.0057193621404620131, 0.005711420867351681, 0.0057036454563808171, 0.0056960040422359085, 0.0056885033757176845]}
[2017-10-02 10:10:16,515 AE_UNIGRAMA_1L_OVER_F1_3.py:103]: done!
[2017-10-02 10:10:16,515 AE_UNIGRAMA_1L_OVER_F1_3.py:163]: >> Executing classifier part ... 
[2017-10-02 10:10:16,515 AE_UNIGRAMA_1L_OVER_F1_3.py:108]: =======================================
[2017-10-02 10:10:16,515 AE_UNIGRAMA_1L_OVER_F1_3.py:112]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x00000000018F0390>, 'classifier_dim': 9, 'use_last_dim_as_classifier': False}
[2017-10-02 10:10:16,569 AE_UNIGRAMA_1L_OVER_F1_3.py:121]: training ... 
[2017-10-02 10:10:16,964 summary.py:93]: Summary name enc0_124/kernel:0 is illegal; using enc0_124/kernel_0 instead.
[2017-10-02 10:10:16,966 summary.py:93]: Summary name enc0_124/bias:0 is illegal; using enc0_124/bias_0 instead.
[2017-10-02 10:10:16,969 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-10-02 10:10:16,971 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-10-02 10:10:38,366 AE_UNIGRAMA_1L_OVER_F1_3.py:133]: trained!
[2017-10-02 10:10:38,367 AE_UNIGRAMA_1L_OVER_F1_3.py:136]: Training history: 
{'val_loss': [0.0088111525643824653, 0.0087103122606402659, 0.0086138991251255501, 0.0085215879895042309, 0.0084331254405575398, 0.0083483811104358568, 0.008267207188898746, 0.0081893422201165036, 0.0081147826432517028, 0.0080432306358860766, 0.0079746174290222308, 0.0079087894080989204, 0.0078454971846650089, 0.007784750925370087, 0.0077262930572032928, 0.007669970973093603, 0.0076157725710407952, 0.0075635060799553932, 0.0075131889353038878, 0.0074646573333713648, 0.0074177239277161185, 0.0073723955509221685, 0.0073283929724010837, 0.0072859184986125806, 0.0072448166073421118, 0.0072049990618345237, 0.0071664167010678896, 0.0071290132059926882, 0.0070925890762345055, 0.0070571416061108441, 0.0070225068378404172, 0.0069886190248964891, 0.0069554503522397861, 0.0069230759159755306, 0.006891507181065455, 0.0068606918757317453, 0.0068306030504765563, 0.0068010391449368794, 0.0067719304968765675, 0.0067428492103118213, 0.0067140625401998985, 0.0066856728991334319, 0.0066577446920499479, 0.0066301758646909632, 0.0066028583230499224, 0.0065756374623861897, 0.0065484697546214421, 0.006521268626571145, 0.0064941619342836973, 0.0064671184559487718, 0.0064400921759219859, 0.006413419412442078, 0.0063871777976506486, 0.0063614936538566886, 0.0063364584999484426, 0.0063120246117027495, 0.0062881698052928573, 0.0062649073771661543, 0.0062423228220425571, 0.0062204412094639359, 0.0061992361663830327, 0.0061786718593848013, 0.0061588154475595873, 0.0061395966783719877, 0.006120984110164155, 0.0061029850879206309, 0.0060855241243114701, 0.0060686169341068064, 0.0060522255235001942, 0.0060363240733908897, 0.0060208783689263143, 0.006005890338532765, 0.0059913436563678608, 0.0059772115685461178, 0.0059634522953828911, 0.0059500764120633274, 0.0059370534221008147, 0.0059243622357129612, 0.0059120077587885705, 0.0058999754259965237, 0.0058882562460924838, 0.0058768437604063287, 0.0058657153090635201, 0.0058548575938855846, 0.0058442791854637259, 0.0058339614106072144, 0.0058238970074234843, 0.0058140619311717141, 0.005804458837333, 0.0057950686268702315, 0.0057858823379674813, 0.0057768925217752337, 0.0057681096028744288, 0.005759520812797945, 0.0057511048799996928, 0.0057428629192970279, 0.0057347866751558275, 0.0057268670368870395, 0.0057191152132521333, 0.0057115014434747091, 0.0057040297211629083, 0.0056966867360206787], 'loss': [0.0088906965573955395, 0.0087862520649818528, 0.0086860774742060446, 0.0085902396903202154, 0.0084984547183256463, 0.0084105040362882112, 0.0083261750336248736, 0.0082453951484580384, 0.0081679157468535525, 0.0080936959296116894, 0.0080224542512793671, 0.0079541530602651091, 0.0078885618207453038, 0.0078254921428204394, 0.0077649563806819529, 0.0077067143183611403, 0.0076505695269331476, 0.0075965413171740753, 0.0075444268662603854, 0.0074942324850902865, 0.0074457820085894501, 0.0073989088605281098, 0.0073536377621685241, 0.0073098082077639667, 0.0072675157360132664, 0.0072266064050762512, 0.0071869768839405044, 0.00714858109016972, 0.0071112808943728989, 0.0070749470816962945, 0.0070395936199750689, 0.0070050763648596363, 0.0069713033406612291, 0.0069382110296919734, 0.0069059344285042398, 0.0068744581070234604, 0.0068437155561101495, 0.0068136641896514713, 0.006784125778437137, 0.0067549250904326433, 0.0067259557777014003, 0.0066973262465917852, 0.0066692057181866387, 0.0066414884719184809, 0.0066140419213970196, 0.0065867733691155582, 0.0065595942962120186, 0.0065323805935067238, 0.0065051636586484366, 0.0064779896358945063, 0.0064509472335770625, 0.0064240421936117434, 0.0063974672874645283, 0.006371287706570806, 0.0063456701027193941, 0.0063206908323406516, 0.0062962778942395039, 0.0062724459093789894, 0.0062492894645283471, 0.0062268139633047262, 0.0062050148899098559, 0.0061839035155220714, 0.0061634317748523338, 0.0061436672365841284, 0.0061245248896271889, 0.0061059726563012706, 0.0060880217362325765, 0.0060706123003888401, 0.0060537467700942718, 0.0060373785090990497, 0.0060214916637399739, 0.006006057615739367, 0.0059910881027954816, 0.0059765464421327342, 0.0059624125075669063, 0.005948650099728634, 0.0059352830254439017, 0.0059222593556084403, 0.005909561285189254, 0.0058972008970520871, 0.0058851571099348392, 0.005873429076374035, 0.0058619836660144366, 0.0058508278394476289, 0.0058399308272525808, 0.0058293245024704354, 0.0058189770636121844, 0.0058088913693286814, 0.0057990250490221164, 0.0057893801788492074, 0.0057799399741103883, 0.005770706604266357, 0.0057616610464668013, 0.0057528267157182199, 0.0057441995235316835, 0.0057357475316105041, 0.0057274722477012457, 0.0057193621404620131, 0.005711420867351681, 0.0057036454563808171, 0.0056960040422359085, 0.0056885033757176845]}
[2017-10-02 10:10:38,367 AE_UNIGRAMA_1L_OVER_F1_3.py:140]: evaluating model ... 
[2017-10-02 10:10:38,390 AE_UNIGRAMA_1L_OVER_F1_3.py:144]: evaluated! 
[2017-10-02 10:10:38,390 AE_UNIGRAMA_1L_OVER_F1_3.py:146]: generating reports ... 
[2017-10-02 10:10:38,849 AE_UNIGRAMA_1L_OVER_F1_3.py:149]: done!
[2017-10-02 10:10:38,849 AE_UNIGRAMA_1L_OVER_F1_3.py:165]: >> experiment AE_UNIGRAMA_1L_OVER_F1_3 finished!

[2017-09-18 07:42:52,659 AE_UNIGRAMA_1L_OVER_F1_3.py:154]: >> Initializing execution of experiment AE_UNIGRAMA_1L_OVER_F1_3
[2017-09-18 07:42:52,659 AE_UNIGRAMA_1L_OVER_F1_3.py:155]: >> Printing header log
[2017-09-18 07:42:52,660 AE_UNIGRAMA_1L_OVER_F1_3.py:47]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_OVER_F1_3
	layers = 96,124
	using GLOBAL obj = 
		{'executed_dir': 'E:/research/research_msc/executed/onelayer/unigram/', 'store_history': True, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'shuffle_batches': True, 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'autoencoder_configs': {'loss_function': 'mse', 'discard_decoder_function': True, 'hidden_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x000000000181B5C0>, 'output_layer_activation': 'relu'}, 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'epochs': 1000, 'mlp_configs': {'loss_function': 'categorical_crossentropy', 'use_last_dim_as_classifier': False, 'optimizer': <keras.optimizers.SGD object at 0x000000000181E438>, 'activation': 'sigmoid', 'classifier_dim': 9}, 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram.pkl', 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'numpy_seed': 666, 'batch': 32}
	=======================================
	
[2017-09-18 07:42:52,660 AE_UNIGRAMA_1L_OVER_F1_3.py:157]: >> Loading dataset... 
[2017-09-18 07:42:52,696 AE_UNIGRAMA_1L_OVER_F1_3.py:63]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram.pkl	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-09-18 07:42:52,696 AE_UNIGRAMA_1L_OVER_F1_3.py:159]: >> Executing autoencoder part ... 
[2017-09-18 07:42:52,696 AE_UNIGRAMA_1L_OVER_F1_3.py:68]: =======================================
[2017-09-18 07:42:52,696 AE_UNIGRAMA_1L_OVER_F1_3.py:73]: setting configurations for autoencoder: 
	 {'loss_function': 'mse', 'discard_decoder_function': True, 'hidden_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x000000000181B5C0>, 'output_layer_activation': 'relu'}
[2017-09-18 07:42:52,744 AE_UNIGRAMA_1L_OVER_F1_3.py:84]: training and evaluate autoencoder
[2017-09-18 07:42:53,275 summary.py:93]: Summary name enc0_124/kernel:0 is illegal; using enc0_124/kernel_0 instead.
[2017-09-18 07:42:53,279 summary.py:93]: Summary name enc0_124/bias:0 is illegal; using enc0_124/bias_0 instead.
[2017-09-18 07:42:53,313 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-09-18 07:42:53,313 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-09-18 07:44:03,699 AE_UNIGRAMA_1L_OVER_F1_3.py:95]: trained and evaluated!
[2017-09-18 07:44:03,699 AE_UNIGRAMA_1L_OVER_F1_3.py:98]: Training history: 
{'val_loss': [0.0088828120360788243, 0.0082821333435189846, 0.0077971899695420625, 0.00740458619568972, 0.0070852058871523592, 0.0068234976516945512, 0.0066071327494026787, 0.0064278234733157035, 0.0062784289869999062, 0.0061528107152415941, 0.0060463141542488009, 0.0059551673208680638, 0.0058761652200854152, 0.0058071057081841362, 0.005746007142677487, 0.0056916162780992954, 0.0056427876142088771, 0.0055984852945747642, 0.0055579845561655851, 0.0055205703122409187, 0.0054857222899350995, 0.0054531421169922035, 0.0054225403738838926, 0.0053936231884631662, 0.005366097643693518, 0.0053398354794968366, 0.0053146043767552248, 0.0052897221807018061, 0.0052649655471939576, 0.0052408468751260753, 0.0052175170141116516, 0.0051948457208620532, 0.0051724460539509, 0.0051496874205446373, 0.0051256060137871056, 0.0050996433832613871, 0.0050730305796236521, 0.0050474460907068237, 0.00502335404210855, 0.0050004407573862354, 0.0049784793999376039, 0.0049572954282834742, 0.0049367507759485773, 0.0049166279455690682, 0.0048966595171175513, 0.0048764834242682248, 0.0048561565215089787, 0.0048353949871728147, 0.0048142793076728953, 0.0047936537635034498, 0.0047742075225453342, 0.0047559452974157068, 0.0047387370107851538, 0.0047224531008717178, 0.0047069749630952052, 0.0046922319698500361, 0.0046781439670265396, 0.0046646348654676897, 0.0046516359022239035, 0.0046390952337146468, 0.0046269658918125234, 0.0046151953456116971, 0.0046037650094766314, 0.0045926359156352008, 0.0045817862009391386, 0.0045711944949409647, 0.0045608325355430569, 0.0045506822710544639, 0.0045407297868279546, 0.0045309642403657266, 0.0045213743803258722, 0.0045119592773538797, 0.0045027114275174793, 0.0044936136156389023, 0.0044846664346191167, 0.0044758610934113553, 0.0044671913584692895, 0.0044586515093553583, 0.0044502340281041301, 0.0044419347203412986, 0.0044337511981622849, 0.0044256761745498059, 0.0044176944744821469, 0.0044097936259464895, 0.0044019501116787365, 0.0043940912456912609, 0.0043860809396708009, 0.0043779783207068866, 0.0043698631108761415, 0.0043617558555361959, 0.004353682862239445, 0.0043456660353351703, 0.004337760945319998, 0.0043299948848484144, 0.0043223674357493946, 0.0043148556291644257, 0.004307442652213893, 0.0043001004155192668, 0.0042927842221001369, 0.0042854514878008067, 0.0042781358213096823, 0.004270871281852307], 'loss': [0.009245682087074953, 0.0085827833134372328, 0.0080459056981342317, 0.0076126470385987884, 0.0072611840560138814, 0.0069746128240573023, 0.0067390724309556969, 0.0065441961804656576, 0.0063824086295486745, 0.0062470257096381232, 0.0061327713275676028, 0.0060355145502728053, 0.005951824618362387, 0.0058790517574704559, 0.0058151271953955667, 0.0057583327275521736, 0.0057076297520816588, 0.0056618667622963916, 0.0056201775316059828, 0.005581852636956537, 0.0055462693799219866, 0.0055130659836356193, 0.0054819019237786759, 0.0054525201716104201, 0.0054246384256197121, 0.0053980591702016056, 0.0053726273703265295, 0.0053478955470457196, 0.0053233260931740941, 0.00529913008690879, 0.0052756615550311791, 0.0052528918457972109, 0.0052305770253393826, 0.0052083326458251481, 0.0051853300175821945, 0.0051606725472113256, 0.0051341917396883034, 0.0051077885210410725, 0.0050827043418038278, 0.0050589922383222768, 0.0050363874066782482, 0.0050146715814752768, 0.0049937224314298067, 0.0049733628579580564, 0.0049533187467739768, 0.0049332356551046843, 0.0049129769392265848, 0.004892467272153431, 0.0048714925183390928, 0.0048505852644918071, 0.0048305406043681175, 0.0048116921194353152, 0.0047939472691864377, 0.0047771832255830175, 0.004761276595985851, 0.0047461339865280863, 0.0047316714567757021, 0.0047177994374916956, 0.0047044612931292692, 0.0046915858186647886, 0.004679144581667123, 0.0046670753329903589, 0.004655351070509987, 0.0046439416024331394, 0.0046328294182778583, 0.0046219847171221117, 0.0046113805276206503, 0.0046009965016555422, 0.0045908195979957678, 0.0045808438740156726, 0.004571056350900108, 0.004561440657371134, 0.0045519949274113155, 0.0045427173928566742, 0.0045335924080423841, 0.0045246186522611247, 0.004515784139121579, 0.0045070851275865855, 0.0044985151288630121, 0.0044900718192741728, 0.0044817447532491915, 0.0044735305694188973, 0.0044654227412091203, 0.0044573957587034337, 0.0044494457135364051, 0.004441529823398775, 0.0044335315810024693, 0.0044253962687170398, 0.0044171878494385398, 0.0044089745422311944, 0.004400801361514807, 0.0043926802958240974, 0.0043846456134744192, 0.004376731592555038, 0.0043689611959346012, 0.0043613259006454871, 0.0043537966310644135, 0.0043463534917314315, 0.0043389546948187745, 0.0043315616734321315, 0.0043241580294581649, 0.0043167790151196041]}
[2017-09-18 07:44:03,699 AE_UNIGRAMA_1L_OVER_F1_3.py:102]: done!
[2017-09-18 07:44:03,699 AE_UNIGRAMA_1L_OVER_F1_3.py:161]: >> Executing classifier part ... 
[2017-09-18 07:44:03,699 AE_UNIGRAMA_1L_OVER_F1_3.py:107]: =======================================
[2017-09-18 07:44:03,699 AE_UNIGRAMA_1L_OVER_F1_3.py:111]: setting configurations for classifier: 
	 {'loss_function': 'categorical_crossentropy', 'use_last_dim_as_classifier': False, 'optimizer': <keras.optimizers.SGD object at 0x000000000181E438>, 'activation': 'sigmoid', 'classifier_dim': 9}
[2017-09-18 07:44:03,811 AE_UNIGRAMA_1L_OVER_F1_3.py:120]: training ... 
[2017-09-18 07:44:04,749 summary.py:93]: Summary name enc0_124/kernel:0 is illegal; using enc0_124/kernel_0 instead.
[2017-09-18 07:44:04,749 summary.py:93]: Summary name enc0_124/bias:0 is illegal; using enc0_124/bias_0 instead.
[2017-09-18 07:44:04,765 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-09-18 07:44:04,765 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-09-18 07:47:04,541 AE_UNIGRAMA_1L_OVER_F1_3.py:132]: trained!
[2017-09-18 07:47:04,542 AE_UNIGRAMA_1L_OVER_F1_3.py:135]: Training history: 
{'val_loss': [0.0088828120360788243, 0.0082821333435189846, 0.0077971899695420625, 0.00740458619568972, 0.0070852058871523592, 0.0068234976516945512, 0.0066071327494026787, 0.0064278234733157035, 0.0062784289869999062, 0.0061528107152415941, 0.0060463141542488009, 0.0059551673208680638, 0.0058761652200854152, 0.0058071057081841362, 0.005746007142677487, 0.0056916162780992954, 0.0056427876142088771, 0.0055984852945747642, 0.0055579845561655851, 0.0055205703122409187, 0.0054857222899350995, 0.0054531421169922035, 0.0054225403738838926, 0.0053936231884631662, 0.005366097643693518, 0.0053398354794968366, 0.0053146043767552248, 0.0052897221807018061, 0.0052649655471939576, 0.0052408468751260753, 0.0052175170141116516, 0.0051948457208620532, 0.0051724460539509, 0.0051496874205446373, 0.0051256060137871056, 0.0050996433832613871, 0.0050730305796236521, 0.0050474460907068237, 0.00502335404210855, 0.0050004407573862354, 0.0049784793999376039, 0.0049572954282834742, 0.0049367507759485773, 0.0049166279455690682, 0.0048966595171175513, 0.0048764834242682248, 0.0048561565215089787, 0.0048353949871728147, 0.0048142793076728953, 0.0047936537635034498, 0.0047742075225453342, 0.0047559452974157068, 0.0047387370107851538, 0.0047224531008717178, 0.0047069749630952052, 0.0046922319698500361, 0.0046781439670265396, 0.0046646348654676897, 0.0046516359022239035, 0.0046390952337146468, 0.0046269658918125234, 0.0046151953456116971, 0.0046037650094766314, 0.0045926359156352008, 0.0045817862009391386, 0.0045711944949409647, 0.0045608325355430569, 0.0045506822710544639, 0.0045407297868279546, 0.0045309642403657266, 0.0045213743803258722, 0.0045119592773538797, 0.0045027114275174793, 0.0044936136156389023, 0.0044846664346191167, 0.0044758610934113553, 0.0044671913584692895, 0.0044586515093553583, 0.0044502340281041301, 0.0044419347203412986, 0.0044337511981622849, 0.0044256761745498059, 0.0044176944744821469, 0.0044097936259464895, 0.0044019501116787365, 0.0043940912456912609, 0.0043860809396708009, 0.0043779783207068866, 0.0043698631108761415, 0.0043617558555361959, 0.004353682862239445, 0.0043456660353351703, 0.004337760945319998, 0.0043299948848484144, 0.0043223674357493946, 0.0043148556291644257, 0.004307442652213893, 0.0043001004155192668, 0.0042927842221001369, 0.0042854514878008067, 0.0042781358213096823, 0.004270871281852307], 'loss': [0.009245682087074953, 0.0085827833134372328, 0.0080459056981342317, 0.0076126470385987884, 0.0072611840560138814, 0.0069746128240573023, 0.0067390724309556969, 0.0065441961804656576, 0.0063824086295486745, 0.0062470257096381232, 0.0061327713275676028, 0.0060355145502728053, 0.005951824618362387, 0.0058790517574704559, 0.0058151271953955667, 0.0057583327275521736, 0.0057076297520816588, 0.0056618667622963916, 0.0056201775316059828, 0.005581852636956537, 0.0055462693799219866, 0.0055130659836356193, 0.0054819019237786759, 0.0054525201716104201, 0.0054246384256197121, 0.0053980591702016056, 0.0053726273703265295, 0.0053478955470457196, 0.0053233260931740941, 0.00529913008690879, 0.0052756615550311791, 0.0052528918457972109, 0.0052305770253393826, 0.0052083326458251481, 0.0051853300175821945, 0.0051606725472113256, 0.0051341917396883034, 0.0051077885210410725, 0.0050827043418038278, 0.0050589922383222768, 0.0050363874066782482, 0.0050146715814752768, 0.0049937224314298067, 0.0049733628579580564, 0.0049533187467739768, 0.0049332356551046843, 0.0049129769392265848, 0.004892467272153431, 0.0048714925183390928, 0.0048505852644918071, 0.0048305406043681175, 0.0048116921194353152, 0.0047939472691864377, 0.0047771832255830175, 0.004761276595985851, 0.0047461339865280863, 0.0047316714567757021, 0.0047177994374916956, 0.0047044612931292692, 0.0046915858186647886, 0.004679144581667123, 0.0046670753329903589, 0.004655351070509987, 0.0046439416024331394, 0.0046328294182778583, 0.0046219847171221117, 0.0046113805276206503, 0.0046009965016555422, 0.0045908195979957678, 0.0045808438740156726, 0.004571056350900108, 0.004561440657371134, 0.0045519949274113155, 0.0045427173928566742, 0.0045335924080423841, 0.0045246186522611247, 0.004515784139121579, 0.0045070851275865855, 0.0044985151288630121, 0.0044900718192741728, 0.0044817447532491915, 0.0044735305694188973, 0.0044654227412091203, 0.0044573957587034337, 0.0044494457135364051, 0.004441529823398775, 0.0044335315810024693, 0.0044253962687170398, 0.0044171878494385398, 0.0044089745422311944, 0.004400801361514807, 0.0043926802958240974, 0.0043846456134744192, 0.004376731592555038, 0.0043689611959346012, 0.0043613259006454871, 0.0043537966310644135, 0.0043463534917314315, 0.0043389546948187745, 0.0043315616734321315, 0.0043241580294581649, 0.0043167790151196041]}
[2017-09-18 07:47:04,542 AE_UNIGRAMA_1L_OVER_F1_3.py:139]: evaluating model ... 
[2017-09-18 07:47:04,636 AE_UNIGRAMA_1L_OVER_F1_3.py:143]: evaluated! 
[2017-09-18 07:47:04,636 AE_UNIGRAMA_1L_OVER_F1_3.py:145]: generating reports ... 
[2017-09-18 07:47:06,623 AE_UNIGRAMA_1L_OVER_F1_3.py:148]: done!
[2017-09-18 07:47:06,623 AE_UNIGRAMA_1L_OVER_F1_3.py:163]: >> experiment AE_UNIGRAMA_1L_OVER_F1_3 finished!

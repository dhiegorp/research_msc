[2017-10-07 09:26:40,975 AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX.py:146]: >> Initializing execution of experiment AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX
[2017-10-07 09:26:40,976 AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX.py:147]: >> Printing header log
[2017-10-07 09:26:40,976 AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX
	layers = 96,76
	using GLOBAL obj = 
		{'reports_dir': 'C:/Users/dhieg/research/research_msc/reports/onelayer/unigram/', 'tensorflow_dir': 'C:/Users/dhieg/research/research_msc/tensorflow/onelayer/unigram/', 'epochs': 200, 'mlp_configs': {'use_last_dim_as_classifier': False, 'optimizer': <keras.optimizers.SGD object at 0x0000026AB40E95C0>, 'classifier_dim': 9, 'activation': 'softmax', 'loss_function': 'categorical_crossentropy'}, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'autoencoder_configs': {'discard_decoder_function': True, 'hidden_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x0000026AB40E24E0>, 'output_layer_activation': 'relu', 'loss_function': 'mse'}, 'executed_path': 'C:/Users/dhieg/research/research_msc/executed/onelayer/unigram/', 'data_dir': 'C:/Users/dhieg/research/malware_dataset/malware_selected_1gram_mini.pkl', 'numpy_seed': 666, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'log_dir': 'C:/Users/dhieg/research/research_msc/logs/onelayer/unigram/', 'store_history': True, 'fullds_data_dir': 'C:/Users/dhieg/research/malware_dataset/malware_selected_1gram.pkl', 'shuffle_batches': True, 'batch': 32, 'checkpoints_dir': 'C:/Users/dhieg/research/research_msc/checkpoints/onelayer/unigram/', 'fullds_reports_dir': 'C:/Users/dhieg/research/research_msc/reports/onelayer/unigram/fullds/'}
	=======================================
	
[2017-10-07 09:26:40,976 AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX.py:149]: >> Loading dataset... 
[2017-10-07 09:26:41,017 AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX.py:54]: 
	=======================================
	loading malware dataset on = C:/Users/dhieg/research/malware_dataset/malware_selected_1gram_mini.pkl	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-07 09:26:41,017 AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX.py:151]: >> Executing autoencoder part ... 
[2017-10-07 09:26:41,017 AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX.py:59]: =======================================
[2017-10-07 09:26:41,017 AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX.py:64]: setting configurations for autoencoder: 
	 {'discard_decoder_function': True, 'hidden_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x0000026AB40E24E0>, 'output_layer_activation': 'relu', 'loss_function': 'mse'}
[2017-10-07 09:26:41,059 AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX.py:75]: training and evaluate autoencoder
[2017-10-07 09:26:44,474 summary.py:89]: Summary name enc0_76/kernel:0 is illegal; using enc0_76/kernel_0 instead.
[2017-10-07 09:26:44,476 summary.py:89]: Summary name enc0_76/bias:0 is illegal; using enc0_76/bias_0 instead.
[2017-10-07 09:26:44,479 summary.py:89]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-10-07 09:26:44,481 summary.py:89]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-10-07 09:27:07,230 AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX.py:86]: trained and evaluated!
[2017-10-07 09:27:07,230 AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX.py:89]: Training history: 
{'loss': [0.010264158081183165, 0.010229150545408407, 0.010195655956607914, 0.010163601321301617, 0.010132884331958823, 0.010103434767315339, 0.010075204993684599, 0.010048115496611259, 0.010022109087050583, 0.0099971688042847593, 0.009973203018078719, 0.0099501883938505602, 0.0099280747987407804, 0.0099067816175360136, 0.0098863044134315427, 0.0098666178901721593, 0.0098476819350591955, 0.0098294401524179759, 0.0098118473041273729, 0.009794877384707433, 0.0097785197924215809, 0.0097627048457949242, 0.0097474173162437026, 0.0097326678799187112, 0.009718405934578447, 0.0097046025147742854, 0.0096912583199998837, 0.009678357000878858, 0.0096658757717772801, 0.009653787737106647, 0.0096420920702967091, 0.0096307628362748109, 0.009619765963632048, 0.0096090890606836659, 0.0095986983101739431, 0.0095885967487754371, 0.0095787612903352592, 0.0095691427865512695, 0.0095597268634583961, 0.0095504094252950155, 0.0095410108910879265, 0.0095315771068651828, 0.0095222987201392245, 0.0095132060850424936, 0.0095043031964737283, 0.0094955729735075288, 0.0094870018733284114, 0.0094785870561752868, 0.0094703333704207453, 0.0094621922716626589, 0.009454125125183236, 0.0094461935350800778, 0.0094384072095467109, 0.0094307325723149982, 0.0094231307121897014, 0.0094156184090048393, 0.0094082127717342486, 0.0094008714472388448, 0.0093935809184619093, 0.0093863283060193429, 0.0093791112441113916, 0.0093719501199444593, 0.009364776850804531, 0.0093576477333381265, 0.0093505556083249407, 0.0093434820010040026, 0.0093364153405366395, 0.0093293351000466821, 0.0093222697080555476, 0.0093152603820268551, 0.0093082955562736845, 0.0093013568716633147, 0.0092944326697772597, 0.0092875387487542649, 0.0092806982943477914, 0.0092738997288501629, 0.0092671273783371359, 0.0092604034537359034, 0.0092537199200280404, 0.0092470942262031213, 0.0092405434640624728, 0.0092340561537817348, 0.0092276402405098521, 0.0092212952004852074, 0.0092150242970575197, 0.009208832193708669, 0.0092026933457544403, 0.0091965804162727743, 0.0091904749282130296, 0.0091844335634584211, 0.0091784479544162016, 0.0091725072085619263, 0.0091665917761353678, 0.0091607048002786632, 0.0091548557642254277, 0.009149031665521893, 0.0091432122560590051, 0.0091373685097119236, 0.0091314705548957951, 0.0091255766522201128, 0.009119733919051248, 0.0091139635731727706], 'val_loss': [0.010278016709649873, 0.010243942961096764, 0.010211330769258139, 0.010180065830733253, 0.010150095087832678, 0.010121378195939454, 0.010093833302531987, 0.010067387466703206, 0.010042021314173826, 0.010017640743279989, 0.0099942178905121012, 0.0099716929746549374, 0.0099500063737528923, 0.0099291427781092196, 0.0099090761210783272, 0.0098897619588390606, 0.0098711495533530154, 0.0098532031958431122, 0.0098358735123642311, 0.0098191616038850685, 0.0098030090913675087, 0.0097873952641363039, 0.009772327808199319, 0.0097577608221636383, 0.0097436536532795569, 0.009730015206237265, 0.009716813089014429, 0.0097040403530444796, 0.0096916683350575464, 0.009679677193381973, 0.0096680614370229512, 0.009656791038617326, 0.009645844705846009, 0.0096351993252907549, 0.0096248426131876428, 0.0096147581380982387, 0.0096049220353143366, 0.009595284072273726, 0.0095858528524581828, 0.0095764759367117213, 0.0095670613491402236, 0.0095577633257636786, 0.0095486445871759973, 0.0095397146231733735, 0.0095309710344749759, 0.0095223774371814111, 0.0095139585546179777, 0.0095057085530354628, 0.0094976058458306981, 0.0094896172239102398, 0.0094817326123718872, 0.0094739737363054403, 0.0094663294856211517, 0.0094587764941626764, 0.0094512653222037519, 0.0094438727986635336, 0.0094365852929956407, 0.0094293572292507358, 0.0094221863951049322, 0.0094150567157228644, 0.0094080053747641994, 0.0094009786359550342, 0.0093939717249688602, 0.0093870330948147181, 0.0093801033139561188, 0.0093731712203708288, 0.0093662202995284348, 0.0093592523586794353, 0.0093523406226284893, 0.0093454930682053804, 0.0093387003475627044, 0.0093319675500840495, 0.0093252550201234317, 0.009318589032056384, 0.0093119820185199546, 0.009305428945525206, 0.009298930547051271, 0.009292488246048251, 0.0092861055773873317, 0.0092797933984201629, 0.009273520708915026, 0.0092673010390154926, 0.0092611483066276992, 0.0092550698896267606, 0.0092490559312269141, 0.0092430898372679402, 0.0092371726013913916, 0.0092312805977785017, 0.0092254451451802347, 0.0092196625321549555, 0.0092139172758976332, 0.0092082214247449189, 0.0092025455433639887, 0.0091968940494782866, 0.0091912664445359463, 0.0091856674717039864, 0.0091800632917748062, 0.0091744152531304766, 0.0091687260354872523, 0.0091630659311954417, 0.0091574709363918764, 0.0091519313881720746]}
[2017-10-07 09:27:07,230 AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX.py:93]: done!
[2017-10-07 09:27:07,231 AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX.py:153]: >> Executing classifier part ... 
[2017-10-07 09:27:07,231 AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX.py:98]: =======================================
[2017-10-07 09:27:07,231 AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX.py:102]: setting configurations for classifier: 
	 {'use_last_dim_as_classifier': False, 'optimizer': <keras.optimizers.SGD object at 0x0000026AB40E95C0>, 'classifier_dim': 9, 'activation': 'softmax', 'loss_function': 'categorical_crossentropy'}
[2017-10-07 09:27:07,296 AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX.py:111]: training ... 
[2017-10-07 09:27:07,612 summary.py:89]: Summary name enc0_76/kernel:0 is illegal; using enc0_76/kernel_0 instead.
[2017-10-07 09:27:07,614 summary.py:89]: Summary name enc0_76/bias:0 is illegal; using enc0_76/bias_0 instead.
[2017-10-07 09:27:07,617 summary.py:89]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-10-07 09:27:07,619 summary.py:89]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-10-07 09:27:59,051 AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX.py:123]: trained!
[2017-10-07 09:27:59,052 AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX.py:126]: Training history: 
{'loss': [0.010264158081183165, 0.010229150545408407, 0.010195655956607914, 0.010163601321301617, 0.010132884331958823, 0.010103434767315339, 0.010075204993684599, 0.010048115496611259, 0.010022109087050583, 0.0099971688042847593, 0.009973203018078719, 0.0099501883938505602, 0.0099280747987407804, 0.0099067816175360136, 0.0098863044134315427, 0.0098666178901721593, 0.0098476819350591955, 0.0098294401524179759, 0.0098118473041273729, 0.009794877384707433, 0.0097785197924215809, 0.0097627048457949242, 0.0097474173162437026, 0.0097326678799187112, 0.009718405934578447, 0.0097046025147742854, 0.0096912583199998837, 0.009678357000878858, 0.0096658757717772801, 0.009653787737106647, 0.0096420920702967091, 0.0096307628362748109, 0.009619765963632048, 0.0096090890606836659, 0.0095986983101739431, 0.0095885967487754371, 0.0095787612903352592, 0.0095691427865512695, 0.0095597268634583961, 0.0095504094252950155, 0.0095410108910879265, 0.0095315771068651828, 0.0095222987201392245, 0.0095132060850424936, 0.0095043031964737283, 0.0094955729735075288, 0.0094870018733284114, 0.0094785870561752868, 0.0094703333704207453, 0.0094621922716626589, 0.009454125125183236, 0.0094461935350800778, 0.0094384072095467109, 0.0094307325723149982, 0.0094231307121897014, 0.0094156184090048393, 0.0094082127717342486, 0.0094008714472388448, 0.0093935809184619093, 0.0093863283060193429, 0.0093791112441113916, 0.0093719501199444593, 0.009364776850804531, 0.0093576477333381265, 0.0093505556083249407, 0.0093434820010040026, 0.0093364153405366395, 0.0093293351000466821, 0.0093222697080555476, 0.0093152603820268551, 0.0093082955562736845, 0.0093013568716633147, 0.0092944326697772597, 0.0092875387487542649, 0.0092806982943477914, 0.0092738997288501629, 0.0092671273783371359, 0.0092604034537359034, 0.0092537199200280404, 0.0092470942262031213, 0.0092405434640624728, 0.0092340561537817348, 0.0092276402405098521, 0.0092212952004852074, 0.0092150242970575197, 0.009208832193708669, 0.0092026933457544403, 0.0091965804162727743, 0.0091904749282130296, 0.0091844335634584211, 0.0091784479544162016, 0.0091725072085619263, 0.0091665917761353678, 0.0091607048002786632, 0.0091548557642254277, 0.009149031665521893, 0.0091432122560590051, 0.0091373685097119236, 0.0091314705548957951, 0.0091255766522201128, 0.009119733919051248, 0.0091139635731727706], 'val_loss': [0.010278016709649873, 0.010243942961096764, 0.010211330769258139, 0.010180065830733253, 0.010150095087832678, 0.010121378195939454, 0.010093833302531987, 0.010067387466703206, 0.010042021314173826, 0.010017640743279989, 0.0099942178905121012, 0.0099716929746549374, 0.0099500063737528923, 0.0099291427781092196, 0.0099090761210783272, 0.0098897619588390606, 0.0098711495533530154, 0.0098532031958431122, 0.0098358735123642311, 0.0098191616038850685, 0.0098030090913675087, 0.0097873952641363039, 0.009772327808199319, 0.0097577608221636383, 0.0097436536532795569, 0.009730015206237265, 0.009716813089014429, 0.0097040403530444796, 0.0096916683350575464, 0.009679677193381973, 0.0096680614370229512, 0.009656791038617326, 0.009645844705846009, 0.0096351993252907549, 0.0096248426131876428, 0.0096147581380982387, 0.0096049220353143366, 0.009595284072273726, 0.0095858528524581828, 0.0095764759367117213, 0.0095670613491402236, 0.0095577633257636786, 0.0095486445871759973, 0.0095397146231733735, 0.0095309710344749759, 0.0095223774371814111, 0.0095139585546179777, 0.0095057085530354628, 0.0094976058458306981, 0.0094896172239102398, 0.0094817326123718872, 0.0094739737363054403, 0.0094663294856211517, 0.0094587764941626764, 0.0094512653222037519, 0.0094438727986635336, 0.0094365852929956407, 0.0094293572292507358, 0.0094221863951049322, 0.0094150567157228644, 0.0094080053747641994, 0.0094009786359550342, 0.0093939717249688602, 0.0093870330948147181, 0.0093801033139561188, 0.0093731712203708288, 0.0093662202995284348, 0.0093592523586794353, 0.0093523406226284893, 0.0093454930682053804, 0.0093387003475627044, 0.0093319675500840495, 0.0093252550201234317, 0.009318589032056384, 0.0093119820185199546, 0.009305428945525206, 0.009298930547051271, 0.009292488246048251, 0.0092861055773873317, 0.0092797933984201629, 0.009273520708915026, 0.0092673010390154926, 0.0092611483066276992, 0.0092550698896267606, 0.0092490559312269141, 0.0092430898372679402, 0.0092371726013913916, 0.0092312805977785017, 0.0092254451451802347, 0.0092196625321549555, 0.0092139172758976332, 0.0092082214247449189, 0.0092025455433639887, 0.0091968940494782866, 0.0091912664445359463, 0.0091856674717039864, 0.0091800632917748062, 0.0091744152531304766, 0.0091687260354872523, 0.0091630659311954417, 0.0091574709363918764, 0.0091519313881720746]}
[2017-10-07 09:27:59,052 AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX.py:130]: evaluating model ... 
[2017-10-07 09:27:59,098 AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX.py:134]: evaluated! 
[2017-10-07 09:27:59,098 AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX.py:136]: generating reports ... 
[2017-10-07 09:27:59,612 AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX.py:139]: done!
[2017-10-07 09:27:59,612 AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX.py:155]: >> experiment AE_UNIGRAMA_1L_UNDER_F0_8_SOFTMAX finished!

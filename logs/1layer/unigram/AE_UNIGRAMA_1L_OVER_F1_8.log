[2017-10-02 10:14:57,487 AE_UNIGRAMA_1L_OVER_F1_8.py:156]: >> Initializing execution of experiment AE_UNIGRAMA_1L_OVER_F1_8
[2017-10-02 10:14:57,488 AE_UNIGRAMA_1L_OVER_F1_8.py:157]: >> Printing header log
[2017-10-02 10:14:57,488 AE_UNIGRAMA_1L_OVER_F1_8.py:48]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_OVER_F1_8
	layers = 96,172
	using GLOBAL obj = 
		{'autoencoder_configs': {'hidden_layer_activation': 'relu', 'discard_decoder_function': True, 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x000000000176E518>}, 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'shuffle_batches': True, 'mlp_configs': {'classifier_dim': 9, 'activation': 'sigmoid', 'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x0000000001970390>}, 'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram_mini.pkl', 'store_history': True, 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'executed_path': 'E:/research/research_msc/executed/onelayer/unigram/', 'batch': 32, 'epochs': 200}
	=======================================
	
[2017-10-02 10:14:57,488 AE_UNIGRAMA_1L_OVER_F1_8.py:159]: >> Loading dataset... 
[2017-10-02 10:14:57,499 AE_UNIGRAMA_1L_OVER_F1_8.py:64]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram_mini.pkl	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-02 10:14:57,499 AE_UNIGRAMA_1L_OVER_F1_8.py:161]: >> Executing autoencoder part ... 
[2017-10-02 10:14:57,499 AE_UNIGRAMA_1L_OVER_F1_8.py:69]: =======================================
[2017-10-02 10:14:57,499 AE_UNIGRAMA_1L_OVER_F1_8.py:74]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'discard_decoder_function': True, 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x000000000176E518>}
[2017-10-02 10:14:57,632 AE_UNIGRAMA_1L_OVER_F1_8.py:85]: training and evaluate autoencoder
[2017-10-02 10:14:58,371 summary.py:93]: Summary name enc0_172/kernel:0 is illegal; using enc0_172/kernel_0 instead.
[2017-10-02 10:14:58,374 summary.py:93]: Summary name enc0_172/bias:0 is illegal; using enc0_172/bias_0 instead.
[2017-10-02 10:14:58,380 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-10-02 10:14:58,384 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-10-02 10:15:22,945 AE_UNIGRAMA_1L_OVER_F1_8.py:96]: trained and evaluated!
[2017-10-02 10:15:22,946 AE_UNIGRAMA_1L_OVER_F1_8.py:99]: Training history: 
{'val_loss': [0.0089513033483052777, 0.008840872589360272, 0.0087346387940517804, 0.008632390102073827, 0.0085340319253282698, 0.0084393055223233194, 0.0083482398402264357, 0.0082605498752878724, 0.0081762632850183644, 0.0080952945435385053, 0.0080175084757815943, 0.0079426978417017867, 0.0078708921527995499, 0.0078018432168019966, 0.0077355323310899912, 0.0076717971148987244, 0.0076105076418047056, 0.0075515420002980529, 0.0074948252587264137, 0.0074402504638668328, 0.007387691163579106, 0.0073370741451761539, 0.0072883895968803682, 0.0072414442519466897, 0.0071961689276489179, 0.0071525437615424063, 0.0071104281914306173, 0.0070698196864704219, 0.0070305754963765578, 0.0069927173237347472, 0.0069561883353638602, 0.0069209057612683918, 0.0068867868366460821, 0.0068538062876872859, 0.0068219569130873372, 0.0067911705635765006, 0.0067614145234199483, 0.006732676546937582, 0.0067048462949083863, 0.0066778998905065775, 0.0066517919810925056, 0.0066265008883156073, 0.0066019571299723535, 0.0065781258212811002, 0.0065549890974668104, 0.0065325445852148934, 0.0065107778230591995, 0.0064896020266230888, 0.0064690221519967655, 0.0064490035359771941, 0.0064295438381403577, 0.0064105997814149444, 0.0063921947509992076, 0.0063742842217111009, 0.00635685971297573, 0.0063398808940247978, 0.0063233479102692636, 0.0063072045828773187, 0.0062914983746786097, 0.0062761552161000479, 0.0062611699554390625, 0.0062465455043770124, 0.0062322356499260687, 0.0062182518916696202, 0.0062045792107328383, 0.006191191299849616, 0.0061780796195882405, 0.0061652483106988953, 0.0061526552472803671, 0.006140265186216862, 0.0061280755516570961, 0.006116078906869135, 0.0061042822073438798, 0.0060926780803994621, 0.006081257874083785, 0.0060700444508080811, 0.0060590335417220363, 0.0060481892632092017, 0.0060375461590278989, 0.0060270831272781558, 0.0060167867295637893, 0.0060066676847498213, 0.0059967020692712316, 0.0059868939425173082, 0.0059772274771975322, 0.0059676946514739641, 0.0059582949823744902, 0.0059490044978637675, 0.0059398187248237075, 0.0059307442067474906, 0.0059217834692849988, 0.0059129282949859328, 0.0059041834391348868, 0.00589553747312287, 0.0058869852002391585, 0.0058785451898095108, 0.0058701883665663382, 0.0058619276097660617, 0.0058537551468466741, 0.0058456800486823219, 0.0058376747650894087, 0.0058297449445912832], 'loss': [0.0090035309244608976, 0.0088899276793442707, 0.0087804601767593245, 0.0086750497431313991, 0.008573616337953862, 0.0084761246373692613, 0.0083824299560938797, 0.0082925003234894639, 0.008205828610086412, 0.0081223925545848286, 0.0080422356904478031, 0.0079651616923579714, 0.0078910438941485975, 0.0078198495936324126, 0.0077513742037964659, 0.0076856243724064107, 0.0076224265194234121, 0.0075616440778688634, 0.0075031378473594248, 0.0074468326483542336, 0.0073926383423371118, 0.007340412473016417, 0.0072900907153099978, 0.0072416800472681593, 0.0071950052059458749, 0.0071499835303111643, 0.0071065739763427824, 0.0070646901402597276, 0.0070242963599060565, 0.0069852387275004136, 0.0069475895129876885, 0.0069112398417823396, 0.0068761178683867359, 0.0068421869317771434, 0.0068093861459531738, 0.00677771295593123, 0.0067471036731569442, 0.0067174906754258338, 0.0066889077336278408, 0.0066612222061344243, 0.0066344248403960495, 0.0066084524055057938, 0.0065832821770783539, 0.0065588467644519541, 0.0065351214140227732, 0.0065121283879493305, 0.0064898365058151395, 0.0064682227198192511, 0.006447205969694024, 0.0064267815679160635, 0.0064069327961861827, 0.0063876256314647217, 0.0063688378330588012, 0.0063505937215387271, 0.0063328407498760026, 0.0063155707078925765, 0.0062987277966585712, 0.0062823285824964402, 0.0062663128886305455, 0.0062507110543104866, 0.0062354739853275392, 0.006220572821271606, 0.0062060309582594245, 0.0061918086101562606, 0.0061779052823937664, 0.0061642943965024974, 0.0061509694277864695, 0.006137923371291776, 0.0061251329450988847, 0.0061125790092981915, 0.0061002216564025446, 0.0060880466884651215, 0.0060760698229138585, 0.006064290353386092, 0.0060527235365140158, 0.0060413498580272609, 0.0060301829228485626, 0.0060192242361486103, 0.006008435504370184, 0.0059978449073194839, 0.0059874314315658296, 0.0059771827171936163, 0.0059671114890343328, 0.0059572080823981511, 0.0059474421448698789, 0.0059378060358264506, 0.0059283120007000605, 0.0059189394450693241, 0.0059096675246528086, 0.0059005226224395271, 0.0058914993319502439, 0.0058825595871635243, 0.0058737258279733884, 0.0058649872963734027, 0.0058563499114422908, 0.0058478139802818109, 0.0058393957140296243, 0.0058310701750498208, 0.0058228385159041739, 0.0058146923807344889, 0.0058066193867284755, 0.005798624776654087]}
[2017-10-02 10:15:22,946 AE_UNIGRAMA_1L_OVER_F1_8.py:103]: done!
[2017-10-02 10:15:22,946 AE_UNIGRAMA_1L_OVER_F1_8.py:163]: >> Executing classifier part ... 
[2017-10-02 10:15:22,947 AE_UNIGRAMA_1L_OVER_F1_8.py:108]: =======================================
[2017-10-02 10:15:22,947 AE_UNIGRAMA_1L_OVER_F1_8.py:112]: setting configurations for classifier: 
	 {'classifier_dim': 9, 'activation': 'sigmoid', 'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x0000000001970390>}
[2017-10-02 10:15:23,035 AE_UNIGRAMA_1L_OVER_F1_8.py:121]: training ... 
[2017-10-02 10:15:23,660 summary.py:93]: Summary name enc0_172/kernel:0 is illegal; using enc0_172/kernel_0 instead.
[2017-10-02 10:15:23,663 summary.py:93]: Summary name enc0_172/bias:0 is illegal; using enc0_172/bias_0 instead.
[2017-10-02 10:15:23,668 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-10-02 10:15:23,671 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-10-02 10:16:10,962 AE_UNIGRAMA_1L_OVER_F1_8.py:133]: trained!
[2017-10-02 10:16:10,963 AE_UNIGRAMA_1L_OVER_F1_8.py:136]: Training history: 
{'val_loss': [0.0089513033483052777, 0.008840872589360272, 0.0087346387940517804, 0.008632390102073827, 0.0085340319253282698, 0.0084393055223233194, 0.0083482398402264357, 0.0082605498752878724, 0.0081762632850183644, 0.0080952945435385053, 0.0080175084757815943, 0.0079426978417017867, 0.0078708921527995499, 0.0078018432168019966, 0.0077355323310899912, 0.0076717971148987244, 0.0076105076418047056, 0.0075515420002980529, 0.0074948252587264137, 0.0074402504638668328, 0.007387691163579106, 0.0073370741451761539, 0.0072883895968803682, 0.0072414442519466897, 0.0071961689276489179, 0.0071525437615424063, 0.0071104281914306173, 0.0070698196864704219, 0.0070305754963765578, 0.0069927173237347472, 0.0069561883353638602, 0.0069209057612683918, 0.0068867868366460821, 0.0068538062876872859, 0.0068219569130873372, 0.0067911705635765006, 0.0067614145234199483, 0.006732676546937582, 0.0067048462949083863, 0.0066778998905065775, 0.0066517919810925056, 0.0066265008883156073, 0.0066019571299723535, 0.0065781258212811002, 0.0065549890974668104, 0.0065325445852148934, 0.0065107778230591995, 0.0064896020266230888, 0.0064690221519967655, 0.0064490035359771941, 0.0064295438381403577, 0.0064105997814149444, 0.0063921947509992076, 0.0063742842217111009, 0.00635685971297573, 0.0063398808940247978, 0.0063233479102692636, 0.0063072045828773187, 0.0062914983746786097, 0.0062761552161000479, 0.0062611699554390625, 0.0062465455043770124, 0.0062322356499260687, 0.0062182518916696202, 0.0062045792107328383, 0.006191191299849616, 0.0061780796195882405, 0.0061652483106988953, 0.0061526552472803671, 0.006140265186216862, 0.0061280755516570961, 0.006116078906869135, 0.0061042822073438798, 0.0060926780803994621, 0.006081257874083785, 0.0060700444508080811, 0.0060590335417220363, 0.0060481892632092017, 0.0060375461590278989, 0.0060270831272781558, 0.0060167867295637893, 0.0060066676847498213, 0.0059967020692712316, 0.0059868939425173082, 0.0059772274771975322, 0.0059676946514739641, 0.0059582949823744902, 0.0059490044978637675, 0.0059398187248237075, 0.0059307442067474906, 0.0059217834692849988, 0.0059129282949859328, 0.0059041834391348868, 0.00589553747312287, 0.0058869852002391585, 0.0058785451898095108, 0.0058701883665663382, 0.0058619276097660617, 0.0058537551468466741, 0.0058456800486823219, 0.0058376747650894087, 0.0058297449445912832], 'loss': [0.0090035309244608976, 0.0088899276793442707, 0.0087804601767593245, 0.0086750497431313991, 0.008573616337953862, 0.0084761246373692613, 0.0083824299560938797, 0.0082925003234894639, 0.008205828610086412, 0.0081223925545848286, 0.0080422356904478031, 0.0079651616923579714, 0.0078910438941485975, 0.0078198495936324126, 0.0077513742037964659, 0.0076856243724064107, 0.0076224265194234121, 0.0075616440778688634, 0.0075031378473594248, 0.0074468326483542336, 0.0073926383423371118, 0.007340412473016417, 0.0072900907153099978, 0.0072416800472681593, 0.0071950052059458749, 0.0071499835303111643, 0.0071065739763427824, 0.0070646901402597276, 0.0070242963599060565, 0.0069852387275004136, 0.0069475895129876885, 0.0069112398417823396, 0.0068761178683867359, 0.0068421869317771434, 0.0068093861459531738, 0.00677771295593123, 0.0067471036731569442, 0.0067174906754258338, 0.0066889077336278408, 0.0066612222061344243, 0.0066344248403960495, 0.0066084524055057938, 0.0065832821770783539, 0.0065588467644519541, 0.0065351214140227732, 0.0065121283879493305, 0.0064898365058151395, 0.0064682227198192511, 0.006447205969694024, 0.0064267815679160635, 0.0064069327961861827, 0.0063876256314647217, 0.0063688378330588012, 0.0063505937215387271, 0.0063328407498760026, 0.0063155707078925765, 0.0062987277966585712, 0.0062823285824964402, 0.0062663128886305455, 0.0062507110543104866, 0.0062354739853275392, 0.006220572821271606, 0.0062060309582594245, 0.0061918086101562606, 0.0061779052823937664, 0.0061642943965024974, 0.0061509694277864695, 0.006137923371291776, 0.0061251329450988847, 0.0061125790092981915, 0.0061002216564025446, 0.0060880466884651215, 0.0060760698229138585, 0.006064290353386092, 0.0060527235365140158, 0.0060413498580272609, 0.0060301829228485626, 0.0060192242361486103, 0.006008435504370184, 0.0059978449073194839, 0.0059874314315658296, 0.0059771827171936163, 0.0059671114890343328, 0.0059572080823981511, 0.0059474421448698789, 0.0059378060358264506, 0.0059283120007000605, 0.0059189394450693241, 0.0059096675246528086, 0.0059005226224395271, 0.0058914993319502439, 0.0058825595871635243, 0.0058737258279733884, 0.0058649872963734027, 0.0058563499114422908, 0.0058478139802818109, 0.0058393957140296243, 0.0058310701750498208, 0.0058228385159041739, 0.0058146923807344889, 0.0058066193867284755, 0.005798624776654087]}
[2017-10-02 10:16:10,963 AE_UNIGRAMA_1L_OVER_F1_8.py:140]: evaluating model ... 
[2017-10-02 10:16:11,009 AE_UNIGRAMA_1L_OVER_F1_8.py:144]: evaluated! 
[2017-10-02 10:16:11,009 AE_UNIGRAMA_1L_OVER_F1_8.py:146]: generating reports ... 
[2017-10-02 10:16:12,112 AE_UNIGRAMA_1L_OVER_F1_8.py:149]: done!
[2017-10-02 10:16:12,112 AE_UNIGRAMA_1L_OVER_F1_8.py:165]: >> experiment AE_UNIGRAMA_1L_OVER_F1_8 finished!

[2017-10-02 10:08:52,124 AE_UNIGRAMA_1L_OVER_F1_2.py:156]: >> Initializing execution of experiment AE_UNIGRAMA_1L_OVER_F1_2
[2017-10-02 10:08:52,125 AE_UNIGRAMA_1L_OVER_F1_2.py:157]: >> Printing header log
[2017-10-02 10:08:52,125 AE_UNIGRAMA_1L_OVER_F1_2.py:48]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_OVER_F1_2
	layers = 96,115
	using GLOBAL obj = 
		{'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'batch': 32, 'store_history': True, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'mlp_configs': {'classifier_dim': 9, 'optimizer': <keras.optimizers.SGD object at 0x0000000001950390>, 'loss_function': 'categorical_crossentropy', 'use_last_dim_as_classifier': False, 'activation': 'sigmoid'}, 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'shuffle_batches': True, 'numpy_seed': 666, 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram_mini.pkl', 'epochs': 200, 'autoencoder_configs': {'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x000000000174D518>, 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'discard_decoder_function': True}, 'executed_path': 'E:/research/research_msc/executed/onelayer/unigram/'}
	=======================================
	
[2017-10-02 10:08:52,125 AE_UNIGRAMA_1L_OVER_F1_2.py:159]: >> Loading dataset... 
[2017-10-02 10:08:52,133 AE_UNIGRAMA_1L_OVER_F1_2.py:64]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram_mini.pkl	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-02 10:08:52,134 AE_UNIGRAMA_1L_OVER_F1_2.py:161]: >> Executing autoencoder part ... 
[2017-10-02 10:08:52,134 AE_UNIGRAMA_1L_OVER_F1_2.py:69]: =======================================
[2017-10-02 10:08:52,134 AE_UNIGRAMA_1L_OVER_F1_2.py:74]: setting configurations for autoencoder: 
	 {'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x000000000174D518>, 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'discard_decoder_function': True}
[2017-10-02 10:08:52,230 AE_UNIGRAMA_1L_OVER_F1_2.py:85]: training and evaluate autoencoder
[2017-10-02 10:08:52,919 summary.py:93]: Summary name enc0_115/kernel:0 is illegal; using enc0_115/kernel_0 instead.
[2017-10-02 10:08:52,923 summary.py:93]: Summary name enc0_115/bias:0 is illegal; using enc0_115/bias_0 instead.
[2017-10-02 10:08:52,932 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-10-02 10:08:52,937 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-10-02 10:09:15,215 AE_UNIGRAMA_1L_OVER_F1_2.py:96]: trained and evaluated!
[2017-10-02 10:09:15,216 AE_UNIGRAMA_1L_OVER_F1_2.py:99]: Training history: 
{'val_loss': [0.010212177414183945, 0.010159575217663135, 0.010109287350815911, 0.010061250404077392, 0.010015247545471643, 0.0099711624704661422, 0.0099288690939102475, 0.009888279244829953, 0.0098493277860396862, 0.0098119550436513575, 0.0097760506645952899, 0.0097414853681418983, 0.0097081695776778977, 0.0096760682456998575, 0.0096451486062715495, 0.0096152900098424865, 0.0095864617366163696, 0.0095587125096511672, 0.0095319394126091306, 0.0095061121653890086, 0.0094811747639983561, 0.009457078000676012, 0.0094338177762177799, 0.0094113204226617918, 0.0093895934563697943, 0.0093685730246196898, 0.0093482028152862898, 0.0093284803944671014, 0.0093093644412144405, 0.0092908041309357568, 0.0092727643676573015, 0.0092552521622646256, 0.0092382358740253512, 0.0092216794237106707, 0.0092056091584015957, 0.009189976431207808, 0.0091747581217867299, 0.009159964550854327, 0.0091455404691702814, 0.0091315025920706162, 0.0091178139055417811, 0.0091044745272974101, 0.0090914634731511651, 0.0090787768239314667, 0.0090664079322801648, 0.009054336499519729, 0.0090425329864523667, 0.0090309737430241468, 0.0090196354636666275, 0.009008525697632129, 0.0089976429198366566, 0.0089869588391931522, 0.0089764500687722817, 0.0089661098417711752, 0.0089559449925049311, 0.0089459530057101663, 0.0089361261607573596, 0.0089264932957557504, 0.0089170422342685525, 0.0089077779323859727, 0.0088986816320942245, 0.0088897376272785832, 0.0088809600799278701, 0.0088723529663393939, 0.0088638937945536515, 0.0088555893850370861, 0.0088474354845191252, 0.0088394119431953674, 0.0088315214355888204, 0.0088237721341416289, 0.0088161607428720451, 0.0088086525674175367, 0.0088012576480586517, 0.0087939984438643141, 0.0087868680980153473, 0.0087798637490317938, 0.0087729744218483733, 0.0087661994240319421, 0.0087595524380613653, 0.0087530264911349163, 0.0087466190749135378, 0.0087403136004302589, 0.0087341090255731984, 0.0087280139780592965, 0.0087220350810115442, 0.0087161382528707435, 0.0087103419331314401, 0.0087046306095601902, 0.0086990061707683877, 0.0086934657379652489, 0.0086880027105318575, 0.008682629228552256, 0.0086773424288154096, 0.0086721285838342946, 0.0086669909965149967, 0.0086619221955039245, 0.0086568887587844447, 0.008651776673777728, 0.0086463395779654666, 0.008640501939009556, 0.0086342751959054883, 0.0086280818315409812], 'loss': [0.010279328760948002, 0.010225013680939265, 0.010173110051519055, 0.010123551649756422, 0.01007619767765198, 0.01003087420169935, 0.0099874646720586931, 0.0099458369210628037, 0.0099059443041618137, 0.0098676715417093629, 0.0098309598041133942, 0.0097956047756866428, 0.0097614816305832616, 0.0097285901770435314, 0.0096969570490613478, 0.0096664171031668796, 0.0096369539476248781, 0.0096085257650786338, 0.0095811475494209063, 0.0095547115591657471, 0.0095292327635919816, 0.0095046453490468651, 0.0094809058083984918, 0.0094580231961400949, 0.0094359210722684203, 0.0094145752023619307, 0.009393931187336696, 0.009373978793520317, 0.0093546695692422344, 0.0093359510559123862, 0.0093177823354412825, 0.0093001376044121922, 0.0092830021459822214, 0.0092663437874498881, 0.0092501516935324553, 0.0092344393887280607, 0.0092191699406872808, 0.0092043114789448488, 0.0091898521870951676, 0.009175766731103506, 0.0091620329675878853, 0.0091486531524439859, 0.0091355945960777118, 0.0091228815655383724, 0.0091104884846588182, 0.0090983966806217724, 0.0090865874937755536, 0.0090750512525613284, 0.0090637423301867786, 0.009052652782075378, 0.0090417868864723118, 0.0090311291091231087, 0.0090206499957349601, 0.0090103607759859632, 0.0090002418165430007, 0.0089903077317863133, 0.0089805378437216258, 0.0089709366286504326, 0.0089615267010539606, 0.0089522843725965591, 0.0089432206989415383, 0.0089343158916307501, 0.0089255792696141135, 0.0089170122381755385, 0.0089086050896939138, 0.0089003504668926266, 0.0088922346168791282, 0.008884249390151578, 0.0088764008732206915, 0.008868667567818532, 0.0088610753025481805, 0.0088536020696905037, 0.0088462356658859636, 0.0088389945927991338, 0.0088318839907353102, 0.0088248909591309623, 0.0088180339687401414, 0.0088112891715228306, 0.0088046788167581644, 0.00879818986821977, 0.0087918253980700627, 0.0087855675766621184, 0.00877942157006, 0.0087733823152347148, 0.0087674472489026184, 0.008761621123270235, 0.0087558708486239391, 0.0087502198923463895, 0.0087446506606264941, 0.0087391617075387295, 0.0087337656671864789, 0.008728450338786083, 0.0087232272259172069, 0.0087180848885384816, 0.0087130322128525159, 0.0087080476547980058, 0.0087031293345572903, 0.0086981520524961713, 0.0086929300838890222, 0.0086873009006396048, 0.0086811891222886677, 0.0086748637030039672]}
[2017-10-02 10:09:15,217 AE_UNIGRAMA_1L_OVER_F1_2.py:103]: done!
[2017-10-02 10:09:15,217 AE_UNIGRAMA_1L_OVER_F1_2.py:163]: >> Executing classifier part ... 
[2017-10-02 10:09:15,217 AE_UNIGRAMA_1L_OVER_F1_2.py:108]: =======================================
[2017-10-02 10:09:15,218 AE_UNIGRAMA_1L_OVER_F1_2.py:112]: setting configurations for classifier: 
	 {'classifier_dim': 9, 'optimizer': <keras.optimizers.SGD object at 0x0000000001950390>, 'loss_function': 'categorical_crossentropy', 'use_last_dim_as_classifier': False, 'activation': 'sigmoid'}
[2017-10-02 10:09:15,334 AE_UNIGRAMA_1L_OVER_F1_2.py:121]: training ... 
[2017-10-02 10:09:16,093 summary.py:93]: Summary name enc0_115/kernel:0 is illegal; using enc0_115/kernel_0 instead.
[2017-10-02 10:09:16,097 summary.py:93]: Summary name enc0_115/bias:0 is illegal; using enc0_115/bias_0 instead.
[2017-10-02 10:09:16,103 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-10-02 10:09:16,106 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-10-02 10:09:59,979 AE_UNIGRAMA_1L_OVER_F1_2.py:133]: trained!
[2017-10-02 10:09:59,980 AE_UNIGRAMA_1L_OVER_F1_2.py:136]: Training history: 
{'val_loss': [0.010212177414183945, 0.010159575217663135, 0.010109287350815911, 0.010061250404077392, 0.010015247545471643, 0.0099711624704661422, 0.0099288690939102475, 0.009888279244829953, 0.0098493277860396862, 0.0098119550436513575, 0.0097760506645952899, 0.0097414853681418983, 0.0097081695776778977, 0.0096760682456998575, 0.0096451486062715495, 0.0096152900098424865, 0.0095864617366163696, 0.0095587125096511672, 0.0095319394126091306, 0.0095061121653890086, 0.0094811747639983561, 0.009457078000676012, 0.0094338177762177799, 0.0094113204226617918, 0.0093895934563697943, 0.0093685730246196898, 0.0093482028152862898, 0.0093284803944671014, 0.0093093644412144405, 0.0092908041309357568, 0.0092727643676573015, 0.0092552521622646256, 0.0092382358740253512, 0.0092216794237106707, 0.0092056091584015957, 0.009189976431207808, 0.0091747581217867299, 0.009159964550854327, 0.0091455404691702814, 0.0091315025920706162, 0.0091178139055417811, 0.0091044745272974101, 0.0090914634731511651, 0.0090787768239314667, 0.0090664079322801648, 0.009054336499519729, 0.0090425329864523667, 0.0090309737430241468, 0.0090196354636666275, 0.009008525697632129, 0.0089976429198366566, 0.0089869588391931522, 0.0089764500687722817, 0.0089661098417711752, 0.0089559449925049311, 0.0089459530057101663, 0.0089361261607573596, 0.0089264932957557504, 0.0089170422342685525, 0.0089077779323859727, 0.0088986816320942245, 0.0088897376272785832, 0.0088809600799278701, 0.0088723529663393939, 0.0088638937945536515, 0.0088555893850370861, 0.0088474354845191252, 0.0088394119431953674, 0.0088315214355888204, 0.0088237721341416289, 0.0088161607428720451, 0.0088086525674175367, 0.0088012576480586517, 0.0087939984438643141, 0.0087868680980153473, 0.0087798637490317938, 0.0087729744218483733, 0.0087661994240319421, 0.0087595524380613653, 0.0087530264911349163, 0.0087466190749135378, 0.0087403136004302589, 0.0087341090255731984, 0.0087280139780592965, 0.0087220350810115442, 0.0087161382528707435, 0.0087103419331314401, 0.0087046306095601902, 0.0086990061707683877, 0.0086934657379652489, 0.0086880027105318575, 0.008682629228552256, 0.0086773424288154096, 0.0086721285838342946, 0.0086669909965149967, 0.0086619221955039245, 0.0086568887587844447, 0.008651776673777728, 0.0086463395779654666, 0.008640501939009556, 0.0086342751959054883, 0.0086280818315409812], 'loss': [0.010279328760948002, 0.010225013680939265, 0.010173110051519055, 0.010123551649756422, 0.01007619767765198, 0.01003087420169935, 0.0099874646720586931, 0.0099458369210628037, 0.0099059443041618137, 0.0098676715417093629, 0.0098309598041133942, 0.0097956047756866428, 0.0097614816305832616, 0.0097285901770435314, 0.0096969570490613478, 0.0096664171031668796, 0.0096369539476248781, 0.0096085257650786338, 0.0095811475494209063, 0.0095547115591657471, 0.0095292327635919816, 0.0095046453490468651, 0.0094809058083984918, 0.0094580231961400949, 0.0094359210722684203, 0.0094145752023619307, 0.009393931187336696, 0.009373978793520317, 0.0093546695692422344, 0.0093359510559123862, 0.0093177823354412825, 0.0093001376044121922, 0.0092830021459822214, 0.0092663437874498881, 0.0092501516935324553, 0.0092344393887280607, 0.0092191699406872808, 0.0092043114789448488, 0.0091898521870951676, 0.009175766731103506, 0.0091620329675878853, 0.0091486531524439859, 0.0091355945960777118, 0.0091228815655383724, 0.0091104884846588182, 0.0090983966806217724, 0.0090865874937755536, 0.0090750512525613284, 0.0090637423301867786, 0.009052652782075378, 0.0090417868864723118, 0.0090311291091231087, 0.0090206499957349601, 0.0090103607759859632, 0.0090002418165430007, 0.0089903077317863133, 0.0089805378437216258, 0.0089709366286504326, 0.0089615267010539606, 0.0089522843725965591, 0.0089432206989415383, 0.0089343158916307501, 0.0089255792696141135, 0.0089170122381755385, 0.0089086050896939138, 0.0089003504668926266, 0.0088922346168791282, 0.008884249390151578, 0.0088764008732206915, 0.008868667567818532, 0.0088610753025481805, 0.0088536020696905037, 0.0088462356658859636, 0.0088389945927991338, 0.0088318839907353102, 0.0088248909591309623, 0.0088180339687401414, 0.0088112891715228306, 0.0088046788167581644, 0.00879818986821977, 0.0087918253980700627, 0.0087855675766621184, 0.00877942157006, 0.0087733823152347148, 0.0087674472489026184, 0.008761621123270235, 0.0087558708486239391, 0.0087502198923463895, 0.0087446506606264941, 0.0087391617075387295, 0.0087337656671864789, 0.008728450338786083, 0.0087232272259172069, 0.0087180848885384816, 0.0087130322128525159, 0.0087080476547980058, 0.0087031293345572903, 0.0086981520524961713, 0.0086929300838890222, 0.0086873009006396048, 0.0086811891222886677, 0.0086748637030039672]}
[2017-10-02 10:09:59,981 AE_UNIGRAMA_1L_OVER_F1_2.py:140]: evaluating model ... 
[2017-10-02 10:10:00,029 AE_UNIGRAMA_1L_OVER_F1_2.py:144]: evaluated! 
[2017-10-02 10:10:00,030 AE_UNIGRAMA_1L_OVER_F1_2.py:146]: generating reports ... 
[2017-10-02 10:10:00,943 AE_UNIGRAMA_1L_OVER_F1_2.py:149]: done!
[2017-10-02 10:10:00,943 AE_UNIGRAMA_1L_OVER_F1_2.py:165]: >> experiment AE_UNIGRAMA_1L_OVER_F1_2 finished!

[2017-10-02 10:21:02,559 AE_UNIGRAMA_1L_UNDER_F0_5.py:156]: >> Initializing execution of experiment AE_UNIGRAMA_1L_UNDER_F0_5
[2017-10-02 10:21:02,560 AE_UNIGRAMA_1L_UNDER_F0_5.py:157]: >> Printing header log
[2017-10-02 10:21:02,560 AE_UNIGRAMA_1L_UNDER_F0_5.py:48]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_UNDER_F0_5
	layers = 96,48
	using GLOBAL obj = 
		{'shuffle_batches': True, 'mlp_configs': {'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy', 'classifier_dim': 9, 'optimizer': <keras.optimizers.SGD object at 0x0000000001980358>, 'activation': 'sigmoid'}, 'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'autoencoder_configs': {'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x000000000197E4E0>, 'hidden_layer_activation': 'relu', 'discard_decoder_function': True, 'loss_function': 'mse'}, 'store_history': True, 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'executed_path': 'E:/research/research_msc/executed/onelayer/unigram/', 'epochs': 200, 'batch': 32, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram_mini.pkl', 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/'}
	=======================================
	
[2017-10-02 10:21:02,560 AE_UNIGRAMA_1L_UNDER_F0_5.py:159]: >> Loading dataset... 
[2017-10-02 10:21:02,565 AE_UNIGRAMA_1L_UNDER_F0_5.py:64]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram_mini.pkl	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-02 10:21:02,565 AE_UNIGRAMA_1L_UNDER_F0_5.py:161]: >> Executing autoencoder part ... 
[2017-10-02 10:21:02,565 AE_UNIGRAMA_1L_UNDER_F0_5.py:69]: =======================================
[2017-10-02 10:21:02,565 AE_UNIGRAMA_1L_UNDER_F0_5.py:74]: setting configurations for autoencoder: 
	 {'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x000000000197E4E0>, 'hidden_layer_activation': 'relu', 'discard_decoder_function': True, 'loss_function': 'mse'}
[2017-10-02 10:21:02,621 AE_UNIGRAMA_1L_UNDER_F0_5.py:85]: training and evaluate autoencoder
[2017-10-02 10:21:02,974 summary.py:93]: Summary name enc0_48/kernel:0 is illegal; using enc0_48/kernel_0 instead.
[2017-10-02 10:21:02,976 summary.py:93]: Summary name enc0_48/bias:0 is illegal; using enc0_48/bias_0 instead.
[2017-10-02 10:21:02,979 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-10-02 10:21:02,980 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-10-02 10:21:12,547 AE_UNIGRAMA_1L_UNDER_F0_5.py:96]: trained and evaluated!
[2017-10-02 10:21:12,547 AE_UNIGRAMA_1L_UNDER_F0_5.py:99]: Training history: 
{'val_loss': [0.0097975130971922758, 0.0097772466662758781, 0.0097555372843234952, 0.0097320387555376309, 0.0097061591534477187, 0.009675281804373494, 0.0096360859097601309, 0.0095844293657177879, 0.0095177952539466579, 0.0094366174115068854, 0.0093501935882639269, 0.0092643366184874988, 0.0091794379069348696, 0.0090954932124530513, 0.0090123326846547284, 0.0089302249702877708, 0.0088500836898735471, 0.0087719241773439611, 0.0086957938124366859, 0.0086216567098041895, 0.00854932094255954, 0.008478938922161396, 0.0084104042302914055, 0.0083437265869797834, 0.0082788802441001817, 0.0082158674780265541, 0.0081545471656915194, 0.0080947121899561138, 0.0080365549399063936, 0.0079799402612486508, 0.0079249176525659718, 0.0078714149952156393, 0.007819325588712794, 0.0077686533712709258, 0.0077194025684632775, 0.0076715229788871285, 0.0076250100030553387, 0.0075798065013851154, 0.0075358695672568775, 0.0074931254582721952, 0.0074515043615907099, 0.0074109220704181491, 0.007371313234645749, 0.0073326003242657973, 0.0072947679638003995, 0.0072578132346438652, 0.0072218354784478484, 0.0071867154028308214, 0.0071523853865033188, 0.0071188620582472214, 0.0070861264973269521, 0.0070542717148241721, 0.0070232728748931984, 0.0069931347795578625, 0.0069638368289322216, 0.0069353194131782508, 0.0069075624603902762, 0.0068805789588829401, 0.0068543553594707556, 0.0068288451393020639, 0.006804003414860667, 0.0067798436037697536, 0.0067563388032707136, 0.0067334698398898744, 0.0067112304471073098, 0.0066895770449122089, 0.0066684969721645896, 0.0066479677871063517, 0.0066279796104476577, 0.0066084909931406876, 0.0065895117054170617, 0.0065710156252365348, 0.0065529711655303007, 0.0065353719178296377, 0.0065182141378023369, 0.0065014855191803996, 0.0064851627563953839, 0.0064692480375360155, 0.0064537129970786743, 0.006438568978809291, 0.0064237898000997235, 0.0064093656405169504, 0.0063952794610124541, 0.006381546806710249, 0.006368152094402499, 0.0063550751812091327, 0.0063423046402522401, 0.0063298446001644254, 0.006317661342913887, 0.0063057663611596846, 0.0062941421034527758, 0.0062827786212600071, 0.0062716636619769509, 0.0062608074130261916, 0.0062501881666287614, 0.0062397988218827983, 0.0062296250869682728, 0.0062196891110902824, 0.0062099388302009565, 0.0062003964696730378, 0.0061910480994828128, 0.0061818859314885285], 'loss': [0.0097796893561260066, 0.009759380933774273, 0.0097380833844548358, 0.009715467191701405, 0.0096907365252049196, 0.0096620802453317809, 0.0096261497333957214, 0.0095792113990507462, 0.0095189249603227742, 0.0094432416071482204, 0.0093571154833453594, 0.0092695642139055141, 0.0091828634268670047, 0.0090973109411008161, 0.0090126776976193756, 0.0089289039143286165, 0.0088465446566209222, 0.0087662590507328626, 0.0086878802244950461, 0.0086115176589689011, 0.0085372349657187006, 0.0084648131333937213, 0.0083944091582516256, 0.0083258811312314912, 0.0082593033950004238, 0.0081945298017490915, 0.0081315395790344004, 0.008070212291449436, 0.0080103905698068138, 0.0079521684894211173, 0.0078955016041102402, 0.0078404326124669726, 0.0077868874405740262, 0.0077347545054544864, 0.0076841150187803107, 0.007634929225041079, 0.0075871007243364808, 0.0075406204673250394, 0.0074954488891112196, 0.007451514949302001, 0.007408775943294213, 0.007367154937088673, 0.0073265406940207943, 0.0072868886577181829, 0.0072481169293221884, 0.0072102425957685902, 0.0071732690280215203, 0.0071372692825269245, 0.0071020684546728623, 0.0070676941409725386, 0.0070341781961497495, 0.0070014978119600892, 0.0069696964683456514, 0.0069387533791253333, 0.0069086670852080215, 0.006879416010477056, 0.0068509386627423705, 0.0068231993372029481, 0.0067962088390896309, 0.0067699652994606821, 0.0067444373435640199, 0.0067195768045065739, 0.0066954117109764366, 0.0066718898671229848, 0.0066490062668727234, 0.0066267433104041755, 0.0066050587736583045, 0.006583946846888046, 0.0065633861892401583, 0.0065433589518917399, 0.0065238423423398546, 0.0065048128748844943, 0.0064862642706828063, 0.006468173871463658, 0.0064505342784501986, 0.0064333327857007006, 0.0064165651991152841, 0.0064002085415865101, 0.0063842495567936362, 0.0063686795505799795, 0.0063535052176493956, 0.006338697109719453, 0.0063242274393758569, 0.0063101102960923918, 0.0062963392247217488, 0.0062829013281348991, 0.0062697849006889492, 0.0062569710511895102, 0.0062444660238482027, 0.0062322316742224534, 0.0062202753902131898, 0.0062086029363465261, 0.0061971765150646346, 0.0061860032266288648, 0.0061750926412802278, 0.0061644189890883933, 0.0061539756735190338, 0.0061437507207518574, 0.0061337624235192033, 0.0061239528523548553, 0.0061143541029701955, 0.0061049451530620809]}
[2017-10-02 10:21:12,547 AE_UNIGRAMA_1L_UNDER_F0_5.py:103]: done!
[2017-10-02 10:21:12,547 AE_UNIGRAMA_1L_UNDER_F0_5.py:163]: >> Executing classifier part ... 
[2017-10-02 10:21:12,547 AE_UNIGRAMA_1L_UNDER_F0_5.py:108]: =======================================
[2017-10-02 10:21:12,547 AE_UNIGRAMA_1L_UNDER_F0_5.py:112]: setting configurations for classifier: 
	 {'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy', 'classifier_dim': 9, 'optimizer': <keras.optimizers.SGD object at 0x0000000001980358>, 'activation': 'sigmoid'}
[2017-10-02 10:21:12,601 AE_UNIGRAMA_1L_UNDER_F0_5.py:121]: training ... 
[2017-10-02 10:21:12,996 summary.py:93]: Summary name enc0_48/kernel:0 is illegal; using enc0_48/kernel_0 instead.
[2017-10-02 10:21:12,998 summary.py:93]: Summary name enc0_48/bias:0 is illegal; using enc0_48/bias_0 instead.
[2017-10-02 10:21:13,001 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-10-02 10:21:13,003 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-10-02 10:21:32,231 AE_UNIGRAMA_1L_UNDER_F0_5.py:133]: trained!
[2017-10-02 10:21:32,232 AE_UNIGRAMA_1L_UNDER_F0_5.py:136]: Training history: 
{'val_loss': [0.0097975130971922758, 0.0097772466662758781, 0.0097555372843234952, 0.0097320387555376309, 0.0097061591534477187, 0.009675281804373494, 0.0096360859097601309, 0.0095844293657177879, 0.0095177952539466579, 0.0094366174115068854, 0.0093501935882639269, 0.0092643366184874988, 0.0091794379069348696, 0.0090954932124530513, 0.0090123326846547284, 0.0089302249702877708, 0.0088500836898735471, 0.0087719241773439611, 0.0086957938124366859, 0.0086216567098041895, 0.00854932094255954, 0.008478938922161396, 0.0084104042302914055, 0.0083437265869797834, 0.0082788802441001817, 0.0082158674780265541, 0.0081545471656915194, 0.0080947121899561138, 0.0080365549399063936, 0.0079799402612486508, 0.0079249176525659718, 0.0078714149952156393, 0.007819325588712794, 0.0077686533712709258, 0.0077194025684632775, 0.0076715229788871285, 0.0076250100030553387, 0.0075798065013851154, 0.0075358695672568775, 0.0074931254582721952, 0.0074515043615907099, 0.0074109220704181491, 0.007371313234645749, 0.0073326003242657973, 0.0072947679638003995, 0.0072578132346438652, 0.0072218354784478484, 0.0071867154028308214, 0.0071523853865033188, 0.0071188620582472214, 0.0070861264973269521, 0.0070542717148241721, 0.0070232728748931984, 0.0069931347795578625, 0.0069638368289322216, 0.0069353194131782508, 0.0069075624603902762, 0.0068805789588829401, 0.0068543553594707556, 0.0068288451393020639, 0.006804003414860667, 0.0067798436037697536, 0.0067563388032707136, 0.0067334698398898744, 0.0067112304471073098, 0.0066895770449122089, 0.0066684969721645896, 0.0066479677871063517, 0.0066279796104476577, 0.0066084909931406876, 0.0065895117054170617, 0.0065710156252365348, 0.0065529711655303007, 0.0065353719178296377, 0.0065182141378023369, 0.0065014855191803996, 0.0064851627563953839, 0.0064692480375360155, 0.0064537129970786743, 0.006438568978809291, 0.0064237898000997235, 0.0064093656405169504, 0.0063952794610124541, 0.006381546806710249, 0.006368152094402499, 0.0063550751812091327, 0.0063423046402522401, 0.0063298446001644254, 0.006317661342913887, 0.0063057663611596846, 0.0062941421034527758, 0.0062827786212600071, 0.0062716636619769509, 0.0062608074130261916, 0.0062501881666287614, 0.0062397988218827983, 0.0062296250869682728, 0.0062196891110902824, 0.0062099388302009565, 0.0062003964696730378, 0.0061910480994828128, 0.0061818859314885285], 'loss': [0.0097796893561260066, 0.009759380933774273, 0.0097380833844548358, 0.009715467191701405, 0.0096907365252049196, 0.0096620802453317809, 0.0096261497333957214, 0.0095792113990507462, 0.0095189249603227742, 0.0094432416071482204, 0.0093571154833453594, 0.0092695642139055141, 0.0091828634268670047, 0.0090973109411008161, 0.0090126776976193756, 0.0089289039143286165, 0.0088465446566209222, 0.0087662590507328626, 0.0086878802244950461, 0.0086115176589689011, 0.0085372349657187006, 0.0084648131333937213, 0.0083944091582516256, 0.0083258811312314912, 0.0082593033950004238, 0.0081945298017490915, 0.0081315395790344004, 0.008070212291449436, 0.0080103905698068138, 0.0079521684894211173, 0.0078955016041102402, 0.0078404326124669726, 0.0077868874405740262, 0.0077347545054544864, 0.0076841150187803107, 0.007634929225041079, 0.0075871007243364808, 0.0075406204673250394, 0.0074954488891112196, 0.007451514949302001, 0.007408775943294213, 0.007367154937088673, 0.0073265406940207943, 0.0072868886577181829, 0.0072481169293221884, 0.0072102425957685902, 0.0071732690280215203, 0.0071372692825269245, 0.0071020684546728623, 0.0070676941409725386, 0.0070341781961497495, 0.0070014978119600892, 0.0069696964683456514, 0.0069387533791253333, 0.0069086670852080215, 0.006879416010477056, 0.0068509386627423705, 0.0068231993372029481, 0.0067962088390896309, 0.0067699652994606821, 0.0067444373435640199, 0.0067195768045065739, 0.0066954117109764366, 0.0066718898671229848, 0.0066490062668727234, 0.0066267433104041755, 0.0066050587736583045, 0.006583946846888046, 0.0065633861892401583, 0.0065433589518917399, 0.0065238423423398546, 0.0065048128748844943, 0.0064862642706828063, 0.006468173871463658, 0.0064505342784501986, 0.0064333327857007006, 0.0064165651991152841, 0.0064002085415865101, 0.0063842495567936362, 0.0063686795505799795, 0.0063535052176493956, 0.006338697109719453, 0.0063242274393758569, 0.0063101102960923918, 0.0062963392247217488, 0.0062829013281348991, 0.0062697849006889492, 0.0062569710511895102, 0.0062444660238482027, 0.0062322316742224534, 0.0062202753902131898, 0.0062086029363465261, 0.0061971765150646346, 0.0061860032266288648, 0.0061750926412802278, 0.0061644189890883933, 0.0061539756735190338, 0.0061437507207518574, 0.0061337624235192033, 0.0061239528523548553, 0.0061143541029701955, 0.0061049451530620809]}
[2017-10-02 10:21:32,232 AE_UNIGRAMA_1L_UNDER_F0_5.py:140]: evaluating model ... 
[2017-10-02 10:21:32,253 AE_UNIGRAMA_1L_UNDER_F0_5.py:144]: evaluated! 
[2017-10-02 10:21:32,253 AE_UNIGRAMA_1L_UNDER_F0_5.py:146]: generating reports ... 
[2017-10-02 10:21:32,719 AE_UNIGRAMA_1L_UNDER_F0_5.py:149]: done!
[2017-10-02 10:21:32,719 AE_UNIGRAMA_1L_UNDER_F0_5.py:165]: >> experiment AE_UNIGRAMA_1L_UNDER_F0_5 finished!

[2017-10-02 10:17:02,913 AE_UNIGRAMA_1L_OVER_F2_0.py:156]: >> Initializing execution of experiment AE_UNIGRAMA_1L_OVER_F2_0
[2017-10-02 10:17:02,914 AE_UNIGRAMA_1L_OVER_F2_0.py:157]: >> Printing header log
[2017-10-02 10:17:02,914 AE_UNIGRAMA_1L_OVER_F2_0.py:48]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_OVER_F2_0
	layers = 96,192
	using GLOBAL obj = 
		{'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'numpy_seed': 666, 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'executed_path': 'E:/research/research_msc/executed/onelayer/unigram/', 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram_mini.pkl', 'batch': 32, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'epochs': 200, 'store_history': True, 'autoencoder_configs': {'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x000000000195E518>, 'discard_decoder_function': True, 'hidden_layer_activation': 'relu', 'loss_function': 'mse'}, 'mlp_configs': {'classifier_dim': 9, 'optimizer': <keras.optimizers.SGD object at 0x0000000001960390>, 'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy', 'activation': 'sigmoid'}, 'shuffle_batches': True, 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/'}
	=======================================
	
[2017-10-02 10:17:02,914 AE_UNIGRAMA_1L_OVER_F2_0.py:159]: >> Loading dataset... 
[2017-10-02 10:17:02,925 AE_UNIGRAMA_1L_OVER_F2_0.py:64]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram_mini.pkl	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-02 10:17:02,925 AE_UNIGRAMA_1L_OVER_F2_0.py:161]: >> Executing autoencoder part ... 
[2017-10-02 10:17:02,926 AE_UNIGRAMA_1L_OVER_F2_0.py:69]: =======================================
[2017-10-02 10:17:02,926 AE_UNIGRAMA_1L_OVER_F2_0.py:74]: setting configurations for autoencoder: 
	 {'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x000000000195E518>, 'discard_decoder_function': True, 'hidden_layer_activation': 'relu', 'loss_function': 'mse'}
[2017-10-02 10:17:03,064 AE_UNIGRAMA_1L_OVER_F2_0.py:85]: training and evaluate autoencoder
[2017-10-02 10:17:03,867 summary.py:93]: Summary name enc0_192/kernel:0 is illegal; using enc0_192/kernel_0 instead.
[2017-10-02 10:17:03,871 summary.py:93]: Summary name enc0_192/bias:0 is illegal; using enc0_192/bias_0 instead.
[2017-10-02 10:17:03,877 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-10-02 10:17:03,881 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-10-02 10:17:28,310 AE_UNIGRAMA_1L_OVER_F2_0.py:96]: trained and evaluated!
[2017-10-02 10:17:28,311 AE_UNIGRAMA_1L_OVER_F2_0.py:99]: Training history: 
{'val_loss': [0.0098470269761231754, 0.0096996979213226243, 0.0095574513880958348, 0.0094202287342800978, 0.0092879614436161117, 0.0091608587261220106, 0.0090387262331259512, 0.0089214970530824365, 0.0088086962218649097, 0.0087003303625963653, 0.0085961104969608289, 0.0084958212626717131, 0.0083992897955264528, 0.0083063378009155774, 0.0082168575379734359, 0.0081309322475500712, 0.0080483655642621128, 0.0079690617349926652, 0.0078928820567281711, 0.007819623670793488, 0.0077492447490336508, 0.0076816382412850633, 0.0076166645080183518, 0.0075542161943993385, 0.0074941081351507111, 0.0074362491160548088, 0.0073805074830674547, 0.0073268751416452312, 0.0072753402442570954, 0.0072256392473874264, 0.0071777633623285805, 0.0071316621539816534, 0.0070871560900129353, 0.0070442693900026132, 0.0070028582979062897, 0.0069628886733079489, 0.0069242480252505898, 0.0068868522144521702, 0.0068506996033083105, 0.006815782324047448, 0.0067820783711443604, 0.0067494238647164912, 0.0067178787192724455, 0.0066873362412516952, 0.0066577547773386467, 0.0066290774978143355, 0.0066013389810587395, 0.0065744410781362912, 0.0065483400168859828, 0.006522973945717497, 0.0064983588979202131, 0.0064744443293370058, 0.006451202218929742, 0.0064286075161984644, 0.006406613525183227, 0.0063852682055344587, 0.006364488190033068, 0.0063442618284914572, 0.0063245634801104168, 0.0063054215761947146, 0.0062867371438133455, 0.0062685223022773589, 0.0062507772783586086, 0.0062334625410490766, 0.0062165505522827451, 0.0062000345989203145, 0.0061839028178509951, 0.0061681130485519153, 0.0061526495745218594, 0.006137532936789954, 0.0061227474950226266, 0.0061082489421542688, 0.0060940664192336196, 0.0060801779657436127, 0.0060665443189940708, 0.0060531849657846646, 0.0060400790586846026, 0.006027231496658356, 0.0060146182643935142, 0.0060022359758920164, 0.0059900938422457212, 0.0059781464311851667, 0.0059664247152447477, 0.0059549155987826865, 0.0059436046064841701, 0.0059325005651406637, 0.0059215823174575445, 0.0059108441335505709, 0.0059002832125276882, 0.0058898878107228247, 0.0058796588265679801, 0.005869584680849956, 0.0058596713942749125, 0.005849899689504205, 0.0058402689970115749, 0.0058307746549908996, 0.0058214086675704851, 0.0058121819942358703, 0.0058030713813510973, 0.0057940713829295123, 0.0057851989860871469, 0.005776428124178409], 'loss': [0.0099774772185688004, 0.0098248816581274663, 0.0096773595463876053, 0.0095354043423543332, 0.0093986462955102639, 0.009266756564268834, 0.0091400031233921913, 0.0090182012842296086, 0.0089010333312651308, 0.0087883270837334528, 0.0086799074776044791, 0.0085757210107718276, 0.0084755729887343728, 0.0083792630500619802, 0.0082865622284986444, 0.0081974166641773146, 0.0081118187233439314, 0.0080295433974341152, 0.0079505284423879788, 0.0078746175365413743, 0.0078015761520340348, 0.0077314582054023003, 0.0076640867072912582, 0.0075993190548704972, 0.0075370821685111812, 0.0074771744978729205, 0.0074195061474305836, 0.0073639327802162416, 0.0073104696416999562, 0.007259119792023391, 0.0072095404337855773, 0.0071617695019244414, 0.0071157876716396633, 0.0070713838441016927, 0.0070285892017304752, 0.0069872756859547499, 0.0069474096446611178, 0.0069088359880269713, 0.0068715553909320364, 0.0068354887854062893, 0.0068006454526201195, 0.0067670076751203427, 0.006734440627507293, 0.0067029621680487535, 0.0066725026696494516, 0.0066429979028208861, 0.0066143938582951516, 0.0065867084292574717, 0.0065598385391348185, 0.0065337699384628335, 0.0065084199267127574, 0.0064838046549184599, 0.0064598959115045925, 0.0064366503063985449, 0.0064140769152729767, 0.0063921261874165499, 0.0063708102036915499, 0.006350060045941245, 0.0063298528526864427, 0.0063102029830093718, 0.006291091059733551, 0.0062724325608991011, 0.0062542606557856213, 0.0062365513518177883, 0.00621926532566007, 0.0062023891406803502, 0.0061859208787090223, 0.0061698261031350914, 0.0061540670315697833, 0.0061386428906776347, 0.0061235770840168038, 0.0061088134228413872, 0.0060943420564260088, 0.00608020363296551, 0.0060663515883346199, 0.0060527725148082842, 0.0060394719705562615, 0.0060264404723449358, 0.0060136723764281953, 0.0060011454778892285, 0.0059888599825119711, 0.0059768226273591418, 0.0059649676949440631, 0.0059533464872881031, 0.0059419369400028404, 0.0059307224000446366, 0.0059197062086119344, 0.005908876745924399, 0.0058982284852952113, 0.0058877602464003694, 0.0058774507049867255, 0.0058673081382051269, 0.0058573269566890834, 0.0058475087145509422, 0.0058378329209768116, 0.0058283065485790347, 0.0058189153991245789, 0.005809632214971148, 0.0058004885222751375, 0.0057914599386451977, 0.0057825496787756005, 0.0057737540528659042]}
[2017-10-02 10:17:28,311 AE_UNIGRAMA_1L_OVER_F2_0.py:103]: done!
[2017-10-02 10:17:28,311 AE_UNIGRAMA_1L_OVER_F2_0.py:163]: >> Executing classifier part ... 
[2017-10-02 10:17:28,312 AE_UNIGRAMA_1L_OVER_F2_0.py:108]: =======================================
[2017-10-02 10:17:28,312 AE_UNIGRAMA_1L_OVER_F2_0.py:112]: setting configurations for classifier: 
	 {'classifier_dim': 9, 'optimizer': <keras.optimizers.SGD object at 0x0000000001960390>, 'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy', 'activation': 'sigmoid'}
[2017-10-02 10:17:28,413 AE_UNIGRAMA_1L_OVER_F2_0.py:121]: training ... 
[2017-10-02 10:17:29,310 summary.py:93]: Summary name enc0_192/kernel:0 is illegal; using enc0_192/kernel_0 instead.
[2017-10-02 10:17:29,314 summary.py:93]: Summary name enc0_192/bias:0 is illegal; using enc0_192/bias_0 instead.
[2017-10-02 10:17:29,321 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-10-02 10:17:29,325 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-10-02 10:18:18,281 AE_UNIGRAMA_1L_OVER_F2_0.py:133]: trained!
[2017-10-02 10:18:18,282 AE_UNIGRAMA_1L_OVER_F2_0.py:136]: Training history: 
{'val_loss': [0.0098470269761231754, 0.0096996979213226243, 0.0095574513880958348, 0.0094202287342800978, 0.0092879614436161117, 0.0091608587261220106, 0.0090387262331259512, 0.0089214970530824365, 0.0088086962218649097, 0.0087003303625963653, 0.0085961104969608289, 0.0084958212626717131, 0.0083992897955264528, 0.0083063378009155774, 0.0082168575379734359, 0.0081309322475500712, 0.0080483655642621128, 0.0079690617349926652, 0.0078928820567281711, 0.007819623670793488, 0.0077492447490336508, 0.0076816382412850633, 0.0076166645080183518, 0.0075542161943993385, 0.0074941081351507111, 0.0074362491160548088, 0.0073805074830674547, 0.0073268751416452312, 0.0072753402442570954, 0.0072256392473874264, 0.0071777633623285805, 0.0071316621539816534, 0.0070871560900129353, 0.0070442693900026132, 0.0070028582979062897, 0.0069628886733079489, 0.0069242480252505898, 0.0068868522144521702, 0.0068506996033083105, 0.006815782324047448, 0.0067820783711443604, 0.0067494238647164912, 0.0067178787192724455, 0.0066873362412516952, 0.0066577547773386467, 0.0066290774978143355, 0.0066013389810587395, 0.0065744410781362912, 0.0065483400168859828, 0.006522973945717497, 0.0064983588979202131, 0.0064744443293370058, 0.006451202218929742, 0.0064286075161984644, 0.006406613525183227, 0.0063852682055344587, 0.006364488190033068, 0.0063442618284914572, 0.0063245634801104168, 0.0063054215761947146, 0.0062867371438133455, 0.0062685223022773589, 0.0062507772783586086, 0.0062334625410490766, 0.0062165505522827451, 0.0062000345989203145, 0.0061839028178509951, 0.0061681130485519153, 0.0061526495745218594, 0.006137532936789954, 0.0061227474950226266, 0.0061082489421542688, 0.0060940664192336196, 0.0060801779657436127, 0.0060665443189940708, 0.0060531849657846646, 0.0060400790586846026, 0.006027231496658356, 0.0060146182643935142, 0.0060022359758920164, 0.0059900938422457212, 0.0059781464311851667, 0.0059664247152447477, 0.0059549155987826865, 0.0059436046064841701, 0.0059325005651406637, 0.0059215823174575445, 0.0059108441335505709, 0.0059002832125276882, 0.0058898878107228247, 0.0058796588265679801, 0.005869584680849956, 0.0058596713942749125, 0.005849899689504205, 0.0058402689970115749, 0.0058307746549908996, 0.0058214086675704851, 0.0058121819942358703, 0.0058030713813510973, 0.0057940713829295123, 0.0057851989860871469, 0.005776428124178409], 'loss': [0.0099774772185688004, 0.0098248816581274663, 0.0096773595463876053, 0.0095354043423543332, 0.0093986462955102639, 0.009266756564268834, 0.0091400031233921913, 0.0090182012842296086, 0.0089010333312651308, 0.0087883270837334528, 0.0086799074776044791, 0.0085757210107718276, 0.0084755729887343728, 0.0083792630500619802, 0.0082865622284986444, 0.0081974166641773146, 0.0081118187233439314, 0.0080295433974341152, 0.0079505284423879788, 0.0078746175365413743, 0.0078015761520340348, 0.0077314582054023003, 0.0076640867072912582, 0.0075993190548704972, 0.0075370821685111812, 0.0074771744978729205, 0.0074195061474305836, 0.0073639327802162416, 0.0073104696416999562, 0.007259119792023391, 0.0072095404337855773, 0.0071617695019244414, 0.0071157876716396633, 0.0070713838441016927, 0.0070285892017304752, 0.0069872756859547499, 0.0069474096446611178, 0.0069088359880269713, 0.0068715553909320364, 0.0068354887854062893, 0.0068006454526201195, 0.0067670076751203427, 0.006734440627507293, 0.0067029621680487535, 0.0066725026696494516, 0.0066429979028208861, 0.0066143938582951516, 0.0065867084292574717, 0.0065598385391348185, 0.0065337699384628335, 0.0065084199267127574, 0.0064838046549184599, 0.0064598959115045925, 0.0064366503063985449, 0.0064140769152729767, 0.0063921261874165499, 0.0063708102036915499, 0.006350060045941245, 0.0063298528526864427, 0.0063102029830093718, 0.006291091059733551, 0.0062724325608991011, 0.0062542606557856213, 0.0062365513518177883, 0.00621926532566007, 0.0062023891406803502, 0.0061859208787090223, 0.0061698261031350914, 0.0061540670315697833, 0.0061386428906776347, 0.0061235770840168038, 0.0061088134228413872, 0.0060943420564260088, 0.00608020363296551, 0.0060663515883346199, 0.0060527725148082842, 0.0060394719705562615, 0.0060264404723449358, 0.0060136723764281953, 0.0060011454778892285, 0.0059888599825119711, 0.0059768226273591418, 0.0059649676949440631, 0.0059533464872881031, 0.0059419369400028404, 0.0059307224000446366, 0.0059197062086119344, 0.005908876745924399, 0.0058982284852952113, 0.0058877602464003694, 0.0058774507049867255, 0.0058673081382051269, 0.0058573269566890834, 0.0058475087145509422, 0.0058378329209768116, 0.0058283065485790347, 0.0058189153991245789, 0.005809632214971148, 0.0058004885222751375, 0.0057914599386451977, 0.0057825496787756005, 0.0057737540528659042]}
[2017-10-02 10:18:18,282 AE_UNIGRAMA_1L_OVER_F2_0.py:140]: evaluating model ... 
[2017-10-02 10:18:18,332 AE_UNIGRAMA_1L_OVER_F2_0.py:144]: evaluated! 
[2017-10-02 10:18:18,333 AE_UNIGRAMA_1L_OVER_F2_0.py:146]: generating reports ... 
[2017-10-02 10:18:19,343 AE_UNIGRAMA_1L_OVER_F2_0.py:149]: done!
[2017-10-02 10:18:19,343 AE_UNIGRAMA_1L_OVER_F2_0.py:165]: >> experiment AE_UNIGRAMA_1L_OVER_F2_0 finished!

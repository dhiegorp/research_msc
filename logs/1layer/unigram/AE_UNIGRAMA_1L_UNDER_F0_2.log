[2017-10-02 10:19:14,862 AE_UNIGRAMA_1L_UNDER_F0_2.py:156]: >> Initializing execution of experiment AE_UNIGRAMA_1L_UNDER_F0_2
[2017-10-02 10:19:14,862 AE_UNIGRAMA_1L_UNDER_F0_2.py:157]: >> Printing header log
[2017-10-02 10:19:14,862 AE_UNIGRAMA_1L_UNDER_F0_2.py:48]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_UNDER_F0_2
	layers = 96,19
	using GLOBAL obj = 
		{'executed_path': 'E:/research/research_msc/executed/onelayer/unigram/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram_mini.pkl', 'numpy_seed': 666, 'batch': 32, 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'epochs': 200, 'store_history': True, 'shuffle_batches': True, 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'autoencoder_configs': {'optimizer': <keras.optimizers.SGD object at 0x00000000010DE4E0>, 'discard_decoder_function': True, 'output_layer_activation': 'relu', 'hidden_layer_activation': 'relu', 'loss_function': 'mse'}, 'mlp_configs': {'activation': 'sigmoid', 'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x0000000001960358>, 'classifier_dim': 9}}
	=======================================
	
[2017-10-02 10:19:14,862 AE_UNIGRAMA_1L_UNDER_F0_2.py:159]: >> Loading dataset... 
[2017-10-02 10:19:14,867 AE_UNIGRAMA_1L_UNDER_F0_2.py:64]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram_mini.pkl	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-02 10:19:14,868 AE_UNIGRAMA_1L_UNDER_F0_2.py:161]: >> Executing autoencoder part ... 
[2017-10-02 10:19:14,868 AE_UNIGRAMA_1L_UNDER_F0_2.py:69]: =======================================
[2017-10-02 10:19:14,868 AE_UNIGRAMA_1L_UNDER_F0_2.py:74]: setting configurations for autoencoder: 
	 {'optimizer': <keras.optimizers.SGD object at 0x00000000010DE4E0>, 'discard_decoder_function': True, 'output_layer_activation': 'relu', 'hidden_layer_activation': 'relu', 'loss_function': 'mse'}
[2017-10-02 10:19:14,924 AE_UNIGRAMA_1L_UNDER_F0_2.py:85]: training and evaluate autoencoder
[2017-10-02 10:19:15,279 summary.py:93]: Summary name enc0_19/kernel:0 is illegal; using enc0_19/kernel_0 instead.
[2017-10-02 10:19:15,281 summary.py:93]: Summary name enc0_19/bias:0 is illegal; using enc0_19/bias_0 instead.
[2017-10-02 10:19:15,284 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-10-02 10:19:15,286 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-10-02 10:19:25,905 AE_UNIGRAMA_1L_UNDER_F0_2.py:96]: trained and evaluated!
[2017-10-02 10:19:25,906 AE_UNIGRAMA_1L_UNDER_F0_2.py:99]: Training history: 
{'val_loss': [0.0096906208879830227, 0.0096716076987328134, 0.0096530718278818421, 0.0096349817489491969, 0.0096173291423506894, 0.0096001248931352982, 0.0095833703861693022, 0.0095670429892754909, 0.00955114517097801, 0.0095356726035697309, 0.0095206123731725722, 0.0095059579709150088, 0.0094916952019176524, 0.0094777958426056734, 0.0094642503824098854, 0.0094510361683800767, 0.0094381545334500452, 0.0094255964205943073, 0.0094133611408418888, 0.0094014052613240195, 0.0093897538654312326, 0.0093783764584079998, 0.0093672844861741409, 0.0093564646090051936, 0.009345897542638185, 0.0093355799114615504, 0.0093254958068238764, 0.0093156515367910763, 0.0093060351949752936, 0.0092966418408660639, 0.0092874682788844452, 0.0092785050677045566, 0.0092697483781711311, 0.0092611954509381027, 0.0092528385792246103, 0.0092446649841770364, 0.0092366658857431557, 0.0092288368869725221, 0.009221173760560808, 0.0092136757205964013, 0.009206327921312759, 0.0091991303177017258, 0.0091920846858543088, 0.0091851862895278233, 0.0091784228795800064, 0.0091717873377981686, 0.0091652763093437398, 0.009158901105112081, 0.0091526537378869097, 0.0091465280415511038, 0.0091405144466786582, 0.0091346222768818128, 0.0091288394976725817, 0.0091231577236856234, 0.0091175815319040013, 0.0091121053655517596, 0.0091067221929703509, 0.0091014243316140768, 0.0090962225938264318, 0.0090910978199824077, 0.0090860465132946416, 0.0090810698716724675, 0.0090761619194178779, 0.0090713100403990443, 0.0090665183857526477, 0.0090617562287580566, 0.0090570321936700431, 0.0090523034881204913, 0.009047567515485128, 0.0090428052477012338, 0.0090380245646579562, 0.0090332325222489997, 0.0090284444474819422, 0.0090236707407025593, 0.0090189008526919499, 0.0090141220461424833, 0.0090093365679997043, 0.0090045508301944983, 0.0089997627796625998, 0.0089949710315377299, 0.0089901645345869564, 0.0089853325007019438, 0.0089804975620599043, 0.0089756612073920924, 0.0089708307591789722, 0.0089660219114176837, 0.0089612496933695555, 0.0089565031680531211, 0.0089517860849938433, 0.0089471089449403018, 0.0089424742510383019, 0.0089378749508563036, 0.0089333288468503597, 0.0089288126421074449, 0.0089243189933740953, 0.0089198626771735436, 0.0089154633516826589, 0.0089111053021313086, 0.0089067985480270426, 0.0089025392186686016, 0.0088983231144489847, 0.0088941454402686939], 'loss': [0.0097008794677783238, 0.0096818759422646252, 0.0096633799566435679, 0.009645337019099658, 0.0096277087725373817, 0.0096105245996974103, 0.0095938043022034871, 0.0095775204881815065, 0.0095616666463872891, 0.009546242249624708, 0.0095312380121440402, 0.0095166249244205414, 0.0095024119447813717, 0.009488565436854602, 0.009475086775586037, 0.0094619499703785647, 0.0094491367886036393, 0.0094366490144852707, 0.0094244733713819123, 0.0094125985403184006, 0.0094010068862696115, 0.0093897033251533497, 0.0093786703982489499, 0.0093679239317435905, 0.0093574506701751582, 0.0093472253487713874, 0.0093372339856729013, 0.0093274812724100133, 0.0093179662936878262, 0.0093086699456590115, 0.0092995860765573059, 0.0092907172948873042, 0.0092820562874485028, 0.0092735980862331448, 0.009265333362560222, 0.0092572656940364297, 0.0092493707626673371, 0.0092416437349631952, 0.0092340749719929463, 0.0092266671085923669, 0.009219421293602521, 0.0092123161609838113, 0.0092053530147023273, 0.0091985345880495825, 0.0091918492924419736, 0.0091852917025105011, 0.0091788685762111081, 0.0091725729649729647, 0.0091664046821881093, 0.0091603643512187301, 0.0091544442633241328, 0.0091486357395166844, 0.0091429366984879159, 0.0091373425832255231, 0.0091318431508984384, 0.0091264435063221003, 0.0091211451961674354, 0.0091159361057995512, 0.0091108132506358373, 0.009105777445798208, 0.0091008186047254486, 0.0090959317061750158, 0.009091107732860787, 0.0090863372902737927, 0.0090816205198010497, 0.0090769527963126227, 0.0090723189839563203, 0.0090676968157080758, 0.0090630635854999347, 0.0090584143991659372, 0.0090537442097047682, 0.009049064293160311, 0.0090443753810815816, 0.0090396828095405182, 0.0090349976954490555, 0.0090303111949634456, 0.009025612194606257, 0.009020922128534713, 0.0090162310716092181, 0.0090115357393006201, 0.0090068209791566312, 0.0090020700989230391, 0.0089973073524835662, 0.0089925439294471134, 0.0089877727713387808, 0.0089830201389365354, 0.0089782838330139912, 0.0089735709710050092, 0.0089688869988856033, 0.0089642438893312321, 0.0089596424591810563, 0.0089550815630285163, 0.0089505663486203323, 0.0089460890494016832, 0.00894164037847801, 0.0089372273233444977, 0.0089328595114838653, 0.0089285389852802235, 0.0089242648174179141, 0.0089200428780340027, 0.0089158645173341277, 0.008911735048493543]}
[2017-10-02 10:19:25,906 AE_UNIGRAMA_1L_UNDER_F0_2.py:103]: done!
[2017-10-02 10:19:25,906 AE_UNIGRAMA_1L_UNDER_F0_2.py:163]: >> Executing classifier part ... 
[2017-10-02 10:19:25,906 AE_UNIGRAMA_1L_UNDER_F0_2.py:108]: =======================================
[2017-10-02 10:19:25,906 AE_UNIGRAMA_1L_UNDER_F0_2.py:112]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x0000000001960358>, 'classifier_dim': 9}
[2017-10-02 10:19:25,961 AE_UNIGRAMA_1L_UNDER_F0_2.py:121]: training ... 
[2017-10-02 10:19:26,358 summary.py:93]: Summary name enc0_19/kernel:0 is illegal; using enc0_19/kernel_0 instead.
[2017-10-02 10:19:26,360 summary.py:93]: Summary name enc0_19/bias:0 is illegal; using enc0_19/bias_0 instead.
[2017-10-02 10:19:26,363 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-10-02 10:19:26,364 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-10-02 10:19:45,217 AE_UNIGRAMA_1L_UNDER_F0_2.py:133]: trained!
[2017-10-02 10:19:45,217 AE_UNIGRAMA_1L_UNDER_F0_2.py:136]: Training history: 
{'val_loss': [0.0096906208879830227, 0.0096716076987328134, 0.0096530718278818421, 0.0096349817489491969, 0.0096173291423506894, 0.0096001248931352982, 0.0095833703861693022, 0.0095670429892754909, 0.00955114517097801, 0.0095356726035697309, 0.0095206123731725722, 0.0095059579709150088, 0.0094916952019176524, 0.0094777958426056734, 0.0094642503824098854, 0.0094510361683800767, 0.0094381545334500452, 0.0094255964205943073, 0.0094133611408418888, 0.0094014052613240195, 0.0093897538654312326, 0.0093783764584079998, 0.0093672844861741409, 0.0093564646090051936, 0.009345897542638185, 0.0093355799114615504, 0.0093254958068238764, 0.0093156515367910763, 0.0093060351949752936, 0.0092966418408660639, 0.0092874682788844452, 0.0092785050677045566, 0.0092697483781711311, 0.0092611954509381027, 0.0092528385792246103, 0.0092446649841770364, 0.0092366658857431557, 0.0092288368869725221, 0.009221173760560808, 0.0092136757205964013, 0.009206327921312759, 0.0091991303177017258, 0.0091920846858543088, 0.0091851862895278233, 0.0091784228795800064, 0.0091717873377981686, 0.0091652763093437398, 0.009158901105112081, 0.0091526537378869097, 0.0091465280415511038, 0.0091405144466786582, 0.0091346222768818128, 0.0091288394976725817, 0.0091231577236856234, 0.0091175815319040013, 0.0091121053655517596, 0.0091067221929703509, 0.0091014243316140768, 0.0090962225938264318, 0.0090910978199824077, 0.0090860465132946416, 0.0090810698716724675, 0.0090761619194178779, 0.0090713100403990443, 0.0090665183857526477, 0.0090617562287580566, 0.0090570321936700431, 0.0090523034881204913, 0.009047567515485128, 0.0090428052477012338, 0.0090380245646579562, 0.0090332325222489997, 0.0090284444474819422, 0.0090236707407025593, 0.0090189008526919499, 0.0090141220461424833, 0.0090093365679997043, 0.0090045508301944983, 0.0089997627796625998, 0.0089949710315377299, 0.0089901645345869564, 0.0089853325007019438, 0.0089804975620599043, 0.0089756612073920924, 0.0089708307591789722, 0.0089660219114176837, 0.0089612496933695555, 0.0089565031680531211, 0.0089517860849938433, 0.0089471089449403018, 0.0089424742510383019, 0.0089378749508563036, 0.0089333288468503597, 0.0089288126421074449, 0.0089243189933740953, 0.0089198626771735436, 0.0089154633516826589, 0.0089111053021313086, 0.0089067985480270426, 0.0089025392186686016, 0.0088983231144489847, 0.0088941454402686939], 'loss': [0.0097008794677783238, 0.0096818759422646252, 0.0096633799566435679, 0.009645337019099658, 0.0096277087725373817, 0.0096105245996974103, 0.0095938043022034871, 0.0095775204881815065, 0.0095616666463872891, 0.009546242249624708, 0.0095312380121440402, 0.0095166249244205414, 0.0095024119447813717, 0.009488565436854602, 0.009475086775586037, 0.0094619499703785647, 0.0094491367886036393, 0.0094366490144852707, 0.0094244733713819123, 0.0094125985403184006, 0.0094010068862696115, 0.0093897033251533497, 0.0093786703982489499, 0.0093679239317435905, 0.0093574506701751582, 0.0093472253487713874, 0.0093372339856729013, 0.0093274812724100133, 0.0093179662936878262, 0.0093086699456590115, 0.0092995860765573059, 0.0092907172948873042, 0.0092820562874485028, 0.0092735980862331448, 0.009265333362560222, 0.0092572656940364297, 0.0092493707626673371, 0.0092416437349631952, 0.0092340749719929463, 0.0092266671085923669, 0.009219421293602521, 0.0092123161609838113, 0.0092053530147023273, 0.0091985345880495825, 0.0091918492924419736, 0.0091852917025105011, 0.0091788685762111081, 0.0091725729649729647, 0.0091664046821881093, 0.0091603643512187301, 0.0091544442633241328, 0.0091486357395166844, 0.0091429366984879159, 0.0091373425832255231, 0.0091318431508984384, 0.0091264435063221003, 0.0091211451961674354, 0.0091159361057995512, 0.0091108132506358373, 0.009105777445798208, 0.0091008186047254486, 0.0090959317061750158, 0.009091107732860787, 0.0090863372902737927, 0.0090816205198010497, 0.0090769527963126227, 0.0090723189839563203, 0.0090676968157080758, 0.0090630635854999347, 0.0090584143991659372, 0.0090537442097047682, 0.009049064293160311, 0.0090443753810815816, 0.0090396828095405182, 0.0090349976954490555, 0.0090303111949634456, 0.009025612194606257, 0.009020922128534713, 0.0090162310716092181, 0.0090115357393006201, 0.0090068209791566312, 0.0090020700989230391, 0.0089973073524835662, 0.0089925439294471134, 0.0089877727713387808, 0.0089830201389365354, 0.0089782838330139912, 0.0089735709710050092, 0.0089688869988856033, 0.0089642438893312321, 0.0089596424591810563, 0.0089550815630285163, 0.0089505663486203323, 0.0089460890494016832, 0.00894164037847801, 0.0089372273233444977, 0.0089328595114838653, 0.0089285389852802235, 0.0089242648174179141, 0.0089200428780340027, 0.0089158645173341277, 0.008911735048493543]}
[2017-10-02 10:19:45,217 AE_UNIGRAMA_1L_UNDER_F0_2.py:140]: evaluating model ... 
[2017-10-02 10:19:45,238 AE_UNIGRAMA_1L_UNDER_F0_2.py:144]: evaluated! 
[2017-10-02 10:19:45,239 AE_UNIGRAMA_1L_UNDER_F0_2.py:146]: generating reports ... 
[2017-10-02 10:19:45,713 AE_UNIGRAMA_1L_UNDER_F0_2.py:149]: done!
[2017-10-02 10:19:45,713 AE_UNIGRAMA_1L_UNDER_F0_2.py:165]: >> experiment AE_UNIGRAMA_1L_UNDER_F0_2 finished!

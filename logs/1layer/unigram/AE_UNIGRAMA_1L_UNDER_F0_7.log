[2017-10-02 10:22:12,640 AE_UNIGRAMA_1L_UNDER_F0_7.py:156]: >> Initializing execution of experiment AE_UNIGRAMA_1L_UNDER_F0_7
[2017-10-02 10:22:12,640 AE_UNIGRAMA_1L_UNDER_F0_7.py:157]: >> Printing header log
[2017-10-02 10:22:12,640 AE_UNIGRAMA_1L_UNDER_F0_7.py:48]: 
	=======================================
	network_name = AE_UNIGRAMA_1L_UNDER_F0_7
	layers = 96,67
	using GLOBAL obj = 
		{'mlp_configs': {'loss_function': 'categorical_crossentropy', 'classifier_dim': 9, 'use_last_dim_as_classifier': False, 'optimizer': <keras.optimizers.SGD object at 0x0000000001910358>, 'activation': 'sigmoid'}, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'reports_dir': 'E:/research/research_msc/reports/onelayer/unigram/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'store_history': True, 'batch': 32, 'log_dir': 'E:/research/research_msc/logs/onelayer/unigram/', 'epochs': 200, 'numpy_seed': 666, 'shuffle_batches': True, 'executed_path': 'E:/research/research_msc/executed/onelayer/unigram/', 'data_dir': 'E:/research/malware_dataset/malware_selected_1gram_mini.pkl', 'tensorflow_dir': 'E:/research/research_msc/tensorflow/onelayer/unigram/', 'autoencoder_configs': {'output_layer_activation': 'relu', 'loss_function': 'mse', 'discard_decoder_function': True, 'optimizer': <keras.optimizers.SGD object at 0x00000000010AE4E0>, 'hidden_layer_activation': 'relu'}, 'checkpoints_dir': 'E:/research/research_msc/checkpoints/onelayer/unigram/'}
	=======================================
	
[2017-10-02 10:22:12,641 AE_UNIGRAMA_1L_UNDER_F0_7.py:159]: >> Loading dataset... 
[2017-10-02 10:22:12,646 AE_UNIGRAMA_1L_UNDER_F0_7.py:64]: 
	=======================================
	loading malware dataset on = E:/research/malware_dataset/malware_selected_1gram_mini.pkl	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-02 10:22:12,646 AE_UNIGRAMA_1L_UNDER_F0_7.py:161]: >> Executing autoencoder part ... 
[2017-10-02 10:22:12,646 AE_UNIGRAMA_1L_UNDER_F0_7.py:69]: =======================================
[2017-10-02 10:22:12,646 AE_UNIGRAMA_1L_UNDER_F0_7.py:74]: setting configurations for autoencoder: 
	 {'output_layer_activation': 'relu', 'loss_function': 'mse', 'discard_decoder_function': True, 'optimizer': <keras.optimizers.SGD object at 0x00000000010AE4E0>, 'hidden_layer_activation': 'relu'}
[2017-10-02 10:22:12,701 AE_UNIGRAMA_1L_UNDER_F0_7.py:85]: training and evaluate autoencoder
[2017-10-02 10:22:13,053 summary.py:93]: Summary name enc0_67/kernel:0 is illegal; using enc0_67/kernel_0 instead.
[2017-10-02 10:22:13,055 summary.py:93]: Summary name enc0_67/bias:0 is illegal; using enc0_67/bias_0 instead.
[2017-10-02 10:22:13,058 summary.py:93]: Summary name dec0_96/kernel:0 is illegal; using dec0_96/kernel_0 instead.
[2017-10-02 10:22:13,059 summary.py:93]: Summary name dec0_96/bias:0 is illegal; using dec0_96/bias_0 instead.
[2017-10-02 10:22:23,256 AE_UNIGRAMA_1L_UNDER_F0_7.py:96]: trained and evaluated!
[2017-10-02 10:22:23,256 AE_UNIGRAMA_1L_UNDER_F0_7.py:99]: Training history: 
{'loss': [0.0094551724932982507, 0.0093592476808381873, 0.009259976724823267, 0.0091619796446480491, 0.0090660152426785164, 0.0089727714079642258, 0.0088822676805343156, 0.0087945155819995902, 0.008709441472621109, 0.0086267551901786331, 0.0085464149980262593, 0.0084684334011873221, 0.0083927500749163709, 0.0083193903160410278, 0.0082483962286989537, 0.0081795781648179178, 0.0081129056363198823, 0.0080482547990542719, 0.0079856557343967981, 0.0079250171166382732, 0.0078661019851458749, 0.0078089855995988585, 0.0077535146380847374, 0.0076995684161951699, 0.0076471952699724705, 0.007596350719461924, 0.007546892333844449, 0.00749880506770975, 0.0074520085966323299, 0.0074064227115287319, 0.0073619490416666706, 0.0073185649754270027, 0.0072763644338579136, 0.0072353724001024715, 0.0071955378171338139, 0.0071569130353551736, 0.0071194954445447083, 0.0070832553934981361, 0.0070481081166921143, 0.0070140362604445084, 0.0069810965532905202, 0.0069491835700298795, 0.0069182997743456589, 0.0068884527928367049, 0.0068595313891246408, 0.0068315524649683254, 0.0068044810914780806, 0.0067782638787412721, 0.006752887936784086, 0.0067283166867246379, 0.0067044811442920271, 0.0066813955326194257, 0.0066590246065567262, 0.0066373314512132246, 0.0066162755574914267, 0.0065958767822533208, 0.0065760830587283303, 0.0065568558683993267, 0.0065382235802563518, 0.0065201364398075898, 0.0065025538867242178, 0.006485474171699669, 0.0064689025389329377, 0.0064528150078694583, 0.0064371623314651485, 0.0064219472782151713, 0.0064071511343744315, 0.0063927677810906485, 0.0063787458030038734, 0.006365101633635799, 0.0063518103805714652, 0.0063388761995588081, 0.0063262743235422041, 0.0063139991428343588, 0.0063020075902058877, 0.0062902987311859214, 0.0062788731960056561, 0.0062677436751515572, 0.006256854520811852, 0.0062461959666926838, 0.0062357799972040601, 0.006225595814270353, 0.0062156118382141684, 0.0062058424398522844, 0.0061962885067173689, 0.0061869279566760726, 0.0061777719850614711, 0.00616880746921221, 0.0061600354400514349, 0.0061514472761194294, 0.0061430230667470021, 0.0061347717161679017, 0.0061266956877789949, 0.0061187824705465667, 0.0061110101709486919, 0.0061033833548701389, 0.0060959197844126217, 0.0060885922102338896, 0.0060814202001253084, 0.0060743822698431579, 0.0060674576601099407, 0.0060606588785248657], 'val_loss': [0.00940373546848953, 0.0093066094747872603, 0.0092095745602781883, 0.0091144741170080621, 0.009021917269755585, 0.008932068211729309, 0.008844726646256712, 0.008760035771973514, 0.0086777819438273139, 0.0085978660071234052, 0.0085201892814837869, 0.0084448954312054646, 0.0083718430043153158, 0.0083010665168743378, 0.0082324417809986929, 0.0081659649900371924, 0.0081014759080366792, 0.0080390001584855382, 0.007978542726902382, 0.0079198539634425628, 0.0078629549146114006, 0.0078077781910845341, 0.0077541187201318465, 0.0077020134292127476, 0.0076514146702717232, 0.0076022884465726335, 0.0075544616913762238, 0.0075079674216257377, 0.0074627939265456784, 0.0074187593074120772, 0.0073757983906866231, 0.0073339997576099564, 0.0072933590025762197, 0.0072538401052134188, 0.0072154749416811978, 0.0071782293144378078, 0.0071421561305684668, 0.0071071791791505971, 0.0070732945669788631, 0.0070405555110023147, 0.0070088380864617109, 0.0069781561385577054, 0.0069485239227575881, 0.0069198291696829645, 0.0068920554911724701, 0.0068651963506572529, 0.0068391548126908262, 0.0068139820705863845, 0.0067896154383716755, 0.0067659921019743146, 0.006743119716242676, 0.0067209734920703123, 0.0066995112395059446, 0.0066786888176679172, 0.006658521910166873, 0.0066389641222512853, 0.0066199644631446519, 0.0066015440866794284, 0.0065836808817343415, 0.0065663076944122972, 0.0065494411534951745, 0.0065330660808485238, 0.0065171786421238265, 0.0065017344333148357, 0.0064867075401112495, 0.0064721079820206171, 0.006457910575249603, 0.0064440833692019977, 0.0064306304544265828, 0.0064175223211539725, 0.0064047751255804277, 0.0063923557676707279, 0.006380255766849979, 0.0063684373958984939, 0.006356908873997656, 0.0063456715115771858, 0.0063347058616523184, 0.0063240001892123964, 0.0063135127682363455, 0.0063032681385546815, 0.0062932483107544009, 0.006283422852398959, 0.0062738179738138248, 0.0062644214916378815, 0.0062552159600181428, 0.0062462109778090259, 0.0062373977563028888, 0.0062287704392464411, 0.0062203166580527026, 0.0062120284116567292, 0.0062039122643246973, 0.0061959606893083642, 0.0061881617663712089, 0.006180514733836775, 0.0061730006848181489, 0.0061656425388522968, 0.0061584202465376223, 0.0061513460985623773, 0.0061444030714577899, 0.0061375769011011577, 0.0061308758741860942, 0.0061243003784751584]}
[2017-10-02 10:22:23,256 AE_UNIGRAMA_1L_UNDER_F0_7.py:103]: done!
[2017-10-02 10:22:23,257 AE_UNIGRAMA_1L_UNDER_F0_7.py:163]: >> Executing classifier part ... 
[2017-10-02 10:22:23,257 AE_UNIGRAMA_1L_UNDER_F0_7.py:108]: =======================================
[2017-10-02 10:22:23,257 AE_UNIGRAMA_1L_UNDER_F0_7.py:112]: setting configurations for classifier: 
	 {'loss_function': 'categorical_crossentropy', 'classifier_dim': 9, 'use_last_dim_as_classifier': False, 'optimizer': <keras.optimizers.SGD object at 0x0000000001910358>, 'activation': 'sigmoid'}
[2017-10-02 10:22:23,311 AE_UNIGRAMA_1L_UNDER_F0_7.py:121]: training ... 
[2017-10-02 10:22:23,704 summary.py:93]: Summary name enc0_67/kernel:0 is illegal; using enc0_67/kernel_0 instead.
[2017-10-02 10:22:23,706 summary.py:93]: Summary name enc0_67/bias:0 is illegal; using enc0_67/bias_0 instead.
[2017-10-02 10:22:23,709 summary.py:93]: Summary name classifier/kernel:0 is illegal; using classifier/kernel_0 instead.
[2017-10-02 10:22:23,711 summary.py:93]: Summary name classifier/bias:0 is illegal; using classifier/bias_0 instead.
[2017-10-02 10:22:45,028 AE_UNIGRAMA_1L_UNDER_F0_7.py:133]: trained!
[2017-10-02 10:22:45,028 AE_UNIGRAMA_1L_UNDER_F0_7.py:136]: Training history: 
{'loss': [0.0094551724932982507, 0.0093592476808381873, 0.009259976724823267, 0.0091619796446480491, 0.0090660152426785164, 0.0089727714079642258, 0.0088822676805343156, 0.0087945155819995902, 0.008709441472621109, 0.0086267551901786331, 0.0085464149980262593, 0.0084684334011873221, 0.0083927500749163709, 0.0083193903160410278, 0.0082483962286989537, 0.0081795781648179178, 0.0081129056363198823, 0.0080482547990542719, 0.0079856557343967981, 0.0079250171166382732, 0.0078661019851458749, 0.0078089855995988585, 0.0077535146380847374, 0.0076995684161951699, 0.0076471952699724705, 0.007596350719461924, 0.007546892333844449, 0.00749880506770975, 0.0074520085966323299, 0.0074064227115287319, 0.0073619490416666706, 0.0073185649754270027, 0.0072763644338579136, 0.0072353724001024715, 0.0071955378171338139, 0.0071569130353551736, 0.0071194954445447083, 0.0070832553934981361, 0.0070481081166921143, 0.0070140362604445084, 0.0069810965532905202, 0.0069491835700298795, 0.0069182997743456589, 0.0068884527928367049, 0.0068595313891246408, 0.0068315524649683254, 0.0068044810914780806, 0.0067782638787412721, 0.006752887936784086, 0.0067283166867246379, 0.0067044811442920271, 0.0066813955326194257, 0.0066590246065567262, 0.0066373314512132246, 0.0066162755574914267, 0.0065958767822533208, 0.0065760830587283303, 0.0065568558683993267, 0.0065382235802563518, 0.0065201364398075898, 0.0065025538867242178, 0.006485474171699669, 0.0064689025389329377, 0.0064528150078694583, 0.0064371623314651485, 0.0064219472782151713, 0.0064071511343744315, 0.0063927677810906485, 0.0063787458030038734, 0.006365101633635799, 0.0063518103805714652, 0.0063388761995588081, 0.0063262743235422041, 0.0063139991428343588, 0.0063020075902058877, 0.0062902987311859214, 0.0062788731960056561, 0.0062677436751515572, 0.006256854520811852, 0.0062461959666926838, 0.0062357799972040601, 0.006225595814270353, 0.0062156118382141684, 0.0062058424398522844, 0.0061962885067173689, 0.0061869279566760726, 0.0061777719850614711, 0.00616880746921221, 0.0061600354400514349, 0.0061514472761194294, 0.0061430230667470021, 0.0061347717161679017, 0.0061266956877789949, 0.0061187824705465667, 0.0061110101709486919, 0.0061033833548701389, 0.0060959197844126217, 0.0060885922102338896, 0.0060814202001253084, 0.0060743822698431579, 0.0060674576601099407, 0.0060606588785248657], 'val_loss': [0.00940373546848953, 0.0093066094747872603, 0.0092095745602781883, 0.0091144741170080621, 0.009021917269755585, 0.008932068211729309, 0.008844726646256712, 0.008760035771973514, 0.0086777819438273139, 0.0085978660071234052, 0.0085201892814837869, 0.0084448954312054646, 0.0083718430043153158, 0.0083010665168743378, 0.0082324417809986929, 0.0081659649900371924, 0.0081014759080366792, 0.0080390001584855382, 0.007978542726902382, 0.0079198539634425628, 0.0078629549146114006, 0.0078077781910845341, 0.0077541187201318465, 0.0077020134292127476, 0.0076514146702717232, 0.0076022884465726335, 0.0075544616913762238, 0.0075079674216257377, 0.0074627939265456784, 0.0074187593074120772, 0.0073757983906866231, 0.0073339997576099564, 0.0072933590025762197, 0.0072538401052134188, 0.0072154749416811978, 0.0071782293144378078, 0.0071421561305684668, 0.0071071791791505971, 0.0070732945669788631, 0.0070405555110023147, 0.0070088380864617109, 0.0069781561385577054, 0.0069485239227575881, 0.0069198291696829645, 0.0068920554911724701, 0.0068651963506572529, 0.0068391548126908262, 0.0068139820705863845, 0.0067896154383716755, 0.0067659921019743146, 0.006743119716242676, 0.0067209734920703123, 0.0066995112395059446, 0.0066786888176679172, 0.006658521910166873, 0.0066389641222512853, 0.0066199644631446519, 0.0066015440866794284, 0.0065836808817343415, 0.0065663076944122972, 0.0065494411534951745, 0.0065330660808485238, 0.0065171786421238265, 0.0065017344333148357, 0.0064867075401112495, 0.0064721079820206171, 0.006457910575249603, 0.0064440833692019977, 0.0064306304544265828, 0.0064175223211539725, 0.0064047751255804277, 0.0063923557676707279, 0.006380255766849979, 0.0063684373958984939, 0.006356908873997656, 0.0063456715115771858, 0.0063347058616523184, 0.0063240001892123964, 0.0063135127682363455, 0.0063032681385546815, 0.0062932483107544009, 0.006283422852398959, 0.0062738179738138248, 0.0062644214916378815, 0.0062552159600181428, 0.0062462109778090259, 0.0062373977563028888, 0.0062287704392464411, 0.0062203166580527026, 0.0062120284116567292, 0.0062039122643246973, 0.0061959606893083642, 0.0061881617663712089, 0.006180514733836775, 0.0061730006848181489, 0.0061656425388522968, 0.0061584202465376223, 0.0061513460985623773, 0.0061444030714577899, 0.0061375769011011577, 0.0061308758741860942, 0.0061243003784751584]}
[2017-10-02 10:22:45,028 AE_UNIGRAMA_1L_UNDER_F0_7.py:140]: evaluating model ... 
[2017-10-02 10:22:45,051 AE_UNIGRAMA_1L_UNDER_F0_7.py:144]: evaluated! 
[2017-10-02 10:22:45,051 AE_UNIGRAMA_1L_UNDER_F0_7.py:146]: generating reports ... 
[2017-10-02 10:22:45,524 AE_UNIGRAMA_1L_UNDER_F0_7.py:149]: done!
[2017-10-02 10:22:45,524 AE_UNIGRAMA_1L_UNDER_F0_7.py:165]: >> experiment AE_UNIGRAMA_1L_UNDER_F0_7 finished!
